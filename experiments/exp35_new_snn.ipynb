{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda:0\n",
      "[CropTime(min=0, max=1000000.0), ToFrame(sensor_size=(700, 1, 1), time_window=None, event_count=None, n_time_bins=50, n_event_bins=None, overlap=0, include_incomplete=False)]\n",
      "1000.0\n",
      "Delta t: 20.0 ms\n",
      "mean of normal: -0.541324854612918\n",
      "1000.0\n",
      "Delta t: 20.0 ms\n",
      "mean of normal: -0.541324854612918\n",
      "1000.0\n",
      "Delta t: 20.0 ms\n",
      "mean of normal: -0.541324854612918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SNN(\n",
       "  (criterion): CrossEntropyLoss()\n",
       "  (layers): ModuleList(\n",
       "    (0): FeedforwardSNNLayer(\n",
       "      (linear): Linear(in_features=700, out_features=256, bias=False)\n",
       "    )\n",
       "    (1): FeedforwardSNNLayer(\n",
       "      (linear): Linear(in_features=256, out_features=256, bias=False)\n",
       "    )\n",
       "    (2): FeedforwardSNNLayer(\n",
       "      (linear): Linear(in_features=2304, out_features=20, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "from snn_delays.snn_refactoring_minimal_v4 import SNN\n",
    "from snn_delays.utils.dataset_loader import DatasetLoader\n",
    "from snn_delays.utils.train_utils_refact_minimal import train, get_device, propagate_batch_simple\n",
    "from snn_delays.utils.test_behavior import tb_minimal\n",
    "\n",
    "'''\n",
    "SHD dataset as in ablation study\n",
    "'''\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "# for reproducibility\n",
    "torch.manual_seed(10)\n",
    "\n",
    "dataset = 'shd'\n",
    "total_time = 50\n",
    "batch_size = 1024\n",
    "\n",
    "# DATASET\n",
    "DL = DatasetLoader(dataset=dataset,\n",
    "                  caching='memory',\n",
    "                  num_workers=0,\n",
    "                  batch_size=batch_size,\n",
    "                  total_time=total_time,\n",
    "                  crop_to=1e6)\n",
    "train_loader, test_loader, dataset_dict = DL.get_dataloaders()\n",
    "          \n",
    "num_epochs = 50\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "snn = SNN(dataset_dict=dataset_dict, num_hidden=256, tau_m='normal', win=50, loss_fn='mem_sum', batch_size=batch_size, device=device)\n",
    "\n",
    "snn.set_layers()\n",
    "snn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# propagate_batch_simple(snn, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], learning_rates 0.001000, 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [2/7], Loss: 3.67084\n",
      "Step [4/7], Loss: 3.52687\n",
      "Step [6/7], Loss: 3.40434\n",
      "Step [8/7], Loss: 3.20521\n",
      "Time elasped: 40.37721228599548\n",
      "Test Loss: 3.142098903656006\n",
      "Test Accuracy of the model on the test samples: 11.175\n",
      "\n",
      "max acc: 11.174911660777385\n",
      "Epoch [2/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 3.10322\n",
      "Step [4/7], Loss: 3.09094\n",
      "Step [6/7], Loss: 2.97988\n",
      "Step [8/7], Loss: 2.96554\n",
      "Time elasped: 3.757774829864502\n",
      "Test Loss: 2.9298582077026367\n",
      "Test Accuracy of the model on the test samples: 5.963\n",
      "\n",
      "max acc: 11.174911660777385\n",
      "Epoch [3/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 2.92330\n",
      "Step [4/7], Loss: 2.80213\n",
      "Step [6/7], Loss: 2.77507\n",
      "Step [8/7], Loss: 2.68330\n",
      "Time elasped: 3.7571768760681152\n",
      "Test Loss: 2.5215138594309487\n",
      "Test Accuracy of the model on the test samples: 28.180\n",
      "\n",
      "max acc: 28.180212014134277\n",
      "Epoch [4/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 2.54284\n",
      "Step [4/7], Loss: 2.40965\n",
      "Step [6/7], Loss: 2.23302\n",
      "Step [8/7], Loss: 2.15747\n",
      "Time elasped: 3.7953479290008545\n",
      "Test Loss: 1.9045053720474243\n",
      "Test Accuracy of the model on the test samples: 46.290\n",
      "\n",
      "max acc: 46.28975265017668\n",
      "Epoch [5/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 1.98509\n",
      "Step [4/7], Loss: 1.74754\n",
      "Step [6/7], Loss: 1.68836\n",
      "Step [8/7], Loss: 1.58102\n",
      "Time elasped: 3.9353749752044678\n",
      "Test Loss: 1.3475415706634521\n",
      "Test Accuracy of the model on the test samples: 61.661\n",
      "\n",
      "max acc: 61.66077738515901\n",
      "Epoch [6/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 1.42843\n",
      "Step [4/7], Loss: 1.26035\n",
      "Step [6/7], Loss: 1.23331\n",
      "Step [8/7], Loss: 1.07486\n",
      "Time elasped: 3.9403414726257324\n",
      "Test Loss: 1.1110200881958008\n",
      "Test Accuracy of the model on the test samples: 65.945\n",
      "\n",
      "max acc: 65.9452296819788\n",
      "Epoch [7/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 1.03673\n",
      "Step [4/7], Loss: 0.90122\n",
      "Step [6/7], Loss: 0.83436\n",
      "Step [8/7], Loss: 0.77507\n",
      "Time elasped: 4.318495035171509\n",
      "Test Loss: 0.9403214057286581\n",
      "Test Accuracy of the model on the test samples: 70.981\n",
      "\n",
      "max acc: 70.98056537102474\n",
      "Epoch [8/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.74614\n",
      "Step [4/7], Loss: 0.72862\n",
      "Step [6/7], Loss: 0.66726\n",
      "Step [8/7], Loss: 0.56168\n",
      "Time elasped: 4.242195129394531\n",
      "Test Loss: 0.7496629158655802\n",
      "Test Accuracy of the model on the test samples: 75.795\n",
      "\n",
      "max acc: 75.79505300353357\n",
      "Epoch [9/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.56057\n",
      "Step [4/7], Loss: 0.48798\n",
      "Step [6/7], Loss: 0.49524\n",
      "Step [8/7], Loss: 0.44370\n",
      "Time elasped: 4.2932868003845215\n",
      "Test Loss: 0.6916513244311014\n",
      "Test Accuracy of the model on the test samples: 76.237\n",
      "\n",
      "max acc: 76.23674911660777\n",
      "Epoch [10/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.43805\n",
      "Step [4/7], Loss: 0.38301\n",
      "Step [6/7], Loss: 0.38647\n",
      "Step [8/7], Loss: 0.40112\n",
      "Time elasped: 4.408167839050293\n",
      "Test Loss: 0.5791829427083334\n",
      "Test Accuracy of the model on the test samples: 81.007\n",
      "\n",
      "max acc: 81.00706713780919\n",
      "Epoch [11/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.34298\n",
      "Step [4/7], Loss: 0.30704\n",
      "Step [6/7], Loss: 0.36691\n",
      "Step [8/7], Loss: 0.24381\n",
      "Time elasped: 4.289992809295654\n",
      "Test Loss: 0.7103201548258463\n",
      "Test Accuracy of the model on the test samples: 77.783\n",
      "\n",
      "max acc: 81.00706713780919\n",
      "Epoch [12/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.28010\n",
      "Step [4/7], Loss: 0.27527\n",
      "Step [6/7], Loss: 0.24985\n",
      "Step [8/7], Loss: 0.23311\n",
      "Time elasped: 4.270772933959961\n",
      "Test Loss: 0.6418301860491434\n",
      "Test Accuracy of the model on the test samples: 80.786\n",
      "\n",
      "max acc: 81.00706713780919\n",
      "Epoch [13/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.25521\n",
      "Step [4/7], Loss: 0.24748\n",
      "Step [6/7], Loss: 0.19725\n",
      "Step [8/7], Loss: 0.16199\n",
      "Time elasped: 4.275620937347412\n",
      "Test Loss: 0.7648592392603556\n",
      "Test Accuracy of the model on the test samples: 77.164\n",
      "\n",
      "max acc: 81.00706713780919\n",
      "Epoch [14/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.17605\n",
      "Step [4/7], Loss: 0.15149\n",
      "Step [6/7], Loss: 0.15230\n",
      "Step [8/7], Loss: 0.14748\n",
      "Time elasped: 4.273818731307983\n",
      "Test Loss: 0.6434207260608673\n",
      "Test Accuracy of the model on the test samples: 78.931\n",
      "\n",
      "max acc: 81.00706713780919\n",
      "Epoch [15/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.17428\n",
      "Step [4/7], Loss: 0.11867\n",
      "Step [6/7], Loss: 0.14190\n",
      "Step [8/7], Loss: 0.15761\n",
      "Time elasped: 4.335139274597168\n",
      "Test Loss: 0.6657428542772929\n",
      "Test Accuracy of the model on the test samples: 79.726\n",
      "\n",
      "max acc: 81.00706713780919\n",
      "Epoch [16/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.15756\n",
      "Step [4/7], Loss: 0.16503\n",
      "Step [6/7], Loss: 0.12843\n",
      "Step [8/7], Loss: 0.12630\n",
      "Time elasped: 4.288211107254028\n",
      "Test Loss: 0.6853830019632975\n",
      "Test Accuracy of the model on the test samples: 80.433\n",
      "\n",
      "max acc: 81.00706713780919\n",
      "Epoch [17/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.12996\n",
      "Step [4/7], Loss: 0.11493\n",
      "Step [6/7], Loss: 0.16578\n",
      "Step [8/7], Loss: 0.16045\n",
      "Time elasped: 4.337212800979614\n",
      "Test Loss: 0.7175507744153341\n",
      "Test Accuracy of the model on the test samples: 81.051\n",
      "\n",
      "max acc: 81.05123674911661\n",
      "Epoch [18/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.14027\n",
      "Step [4/7], Loss: 0.12923\n",
      "Step [6/7], Loss: 0.10530\n",
      "Step [8/7], Loss: 0.09041\n",
      "Time elasped: 4.32535195350647\n",
      "Test Loss: 0.6579271157582601\n",
      "Test Accuracy of the model on the test samples: 81.449\n",
      "\n",
      "max acc: 81.44876325088339\n",
      "Epoch [19/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.12721\n",
      "Step [4/7], Loss: 0.07700\n",
      "Step [6/7], Loss: 0.10955\n",
      "Step [8/7], Loss: 0.08506\n",
      "Time elasped: 6.923585653305054\n",
      "Test Loss: 0.8809821605682373\n",
      "Test Accuracy of the model on the test samples: 77.562\n",
      "\n",
      "max acc: 81.44876325088339\n",
      "Epoch [20/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.06503\n",
      "Step [4/7], Loss: 0.06687\n",
      "Step [6/7], Loss: 0.08218\n",
      "Step [8/7], Loss: 0.07132\n",
      "Time elasped: 7.087182998657227\n",
      "Test Loss: 0.5012095967928568\n",
      "Test Accuracy of the model on the test samples: 83.966\n",
      "\n",
      "max acc: 83.96643109540636\n",
      "Epoch [21/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.06808\n",
      "Step [4/7], Loss: 0.06747\n",
      "Step [6/7], Loss: 0.06304\n",
      "Step [8/7], Loss: 0.05111\n",
      "Time elasped: 7.069520711898804\n",
      "Test Loss: 0.7280762990315756\n",
      "Test Accuracy of the model on the test samples: 80.080\n",
      "\n",
      "max acc: 83.96643109540636\n",
      "Epoch [22/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.05047\n",
      "Step [4/7], Loss: 0.04435\n",
      "Step [6/7], Loss: 0.03694\n",
      "Step [8/7], Loss: 0.05992\n",
      "Time elasped: 6.208906412124634\n",
      "Test Loss: 0.6751665274302164\n",
      "Test Accuracy of the model on the test samples: 81.140\n",
      "\n",
      "max acc: 83.96643109540636\n",
      "Epoch [23/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.05078\n",
      "Step [4/7], Loss: 0.05082\n",
      "Step [6/7], Loss: 0.05960\n",
      "Step [8/7], Loss: 0.05628\n",
      "Time elasped: 6.415481805801392\n",
      "Test Loss: 0.8365010221799215\n",
      "Test Accuracy of the model on the test samples: 79.329\n",
      "\n",
      "max acc: 83.96643109540636\n",
      "Epoch [24/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.04678\n",
      "Step [4/7], Loss: 0.04635\n",
      "Step [6/7], Loss: 0.03355\n",
      "Step [8/7], Loss: 0.04805\n",
      "Time elasped: 6.026419162750244\n",
      "Test Loss: 0.6871088345845541\n",
      "Test Accuracy of the model on the test samples: 80.477\n",
      "\n",
      "max acc: 83.96643109540636\n",
      "Epoch [25/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.04063\n",
      "Step [4/7], Loss: 0.03339\n",
      "Step [6/7], Loss: 0.03232\n",
      "Step [8/7], Loss: 0.06108\n",
      "Time elasped: 9.56982707977295\n",
      "Test Loss: 0.7929197351137797\n",
      "Test Accuracy of the model on the test samples: 80.433\n",
      "\n",
      "max acc: 83.96643109540636\n",
      "Epoch [26/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.04739\n",
      "Step [4/7], Loss: 0.03113\n",
      "Step [6/7], Loss: 0.03610\n",
      "Step [8/7], Loss: 0.04011\n",
      "Time elasped: 5.26845645904541\n",
      "Test Loss: 0.7093466718991598\n",
      "Test Accuracy of the model on the test samples: 82.023\n",
      "\n",
      "max acc: 83.96643109540636\n",
      "Epoch [27/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.01990\n",
      "Step [4/7], Loss: 0.02933\n",
      "Step [6/7], Loss: 0.02779\n",
      "Step [8/7], Loss: 0.02855\n",
      "Time elasped: 9.164103031158447\n",
      "Test Loss: 0.6431333422660828\n",
      "Test Accuracy of the model on the test samples: 82.244\n",
      "\n",
      "max acc: 83.96643109540636\n",
      "Epoch [28/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.01775\n",
      "Step [4/7], Loss: 0.01973\n",
      "Step [6/7], Loss: 0.03388\n",
      "Step [8/7], Loss: 0.01957\n",
      "Time elasped: 5.1307597160339355\n",
      "Test Loss: 0.6440105239550272\n",
      "Test Accuracy of the model on the test samples: 82.730\n",
      "\n",
      "max acc: 83.96643109540636\n",
      "Epoch [29/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.02033\n",
      "Step [4/7], Loss: 0.01346\n",
      "Step [6/7], Loss: 0.01991\n",
      "Step [8/7], Loss: 0.01898\n",
      "Time elasped: 9.572585582733154\n",
      "Test Loss: 0.6406570672988892\n",
      "Test Accuracy of the model on the test samples: 81.405\n",
      "\n",
      "max acc: 83.96643109540636\n",
      "Epoch [30/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.02546\n",
      "Step [4/7], Loss: 0.01732\n",
      "Step [6/7], Loss: 0.01321\n",
      "Step [8/7], Loss: 0.01362\n",
      "Time elasped: 5.458802223205566\n",
      "Test Loss: 0.7061932484308878\n",
      "Test Accuracy of the model on the test samples: 81.625\n",
      "\n",
      "max acc: 83.96643109540636\n",
      "Epoch [31/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.01633\n",
      "Step [4/7], Loss: 0.01043\n",
      "Step [6/7], Loss: 0.01098\n",
      "Step [8/7], Loss: 0.02162\n",
      "Time elasped: 9.575864553451538\n",
      "Test Loss: 0.6803264816602071\n",
      "Test Accuracy of the model on the test samples: 81.581\n",
      "\n",
      "max acc: 83.96643109540636\n",
      "Epoch [32/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.00906\n",
      "Step [4/7], Loss: 0.00744\n",
      "Step [6/7], Loss: 0.01953\n",
      "Step [8/7], Loss: 0.01124\n",
      "Time elasped: 9.569052457809448\n",
      "Test Loss: 0.5715941488742828\n",
      "Test Accuracy of the model on the test samples: 84.099\n",
      "\n",
      "max acc: 84.09893992932862\n",
      "Epoch [33/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.01039\n",
      "Step [4/7], Loss: 0.01310\n",
      "Step [6/7], Loss: 0.00657\n",
      "Step [8/7], Loss: 0.00872\n",
      "Time elasped: 7.1049964427948\n",
      "Test Loss: 0.6395850976308187\n",
      "Test Accuracy of the model on the test samples: 83.171\n",
      "\n",
      "max acc: 84.09893992932862\n",
      "Epoch [34/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.00813\n",
      "Step [4/7], Loss: 0.00604\n",
      "Step [6/7], Loss: 0.00583\n",
      "Step [8/7], Loss: 0.00765\n",
      "Time elasped: 7.280339479446411\n",
      "Test Loss: 0.7455087304115295\n",
      "Test Accuracy of the model on the test samples: 82.111\n",
      "\n",
      "max acc: 84.09893992932862\n",
      "Epoch [35/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.01082\n",
      "Step [4/7], Loss: 0.00457\n",
      "Step [6/7], Loss: 0.00536\n",
      "Step [8/7], Loss: 0.00645\n",
      "Time elasped: 9.572433948516846\n",
      "Test Loss: 0.7432306607564291\n",
      "Test Accuracy of the model on the test samples: 80.963\n",
      "\n",
      "max acc: 84.09893992932862\n",
      "Epoch [36/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.00506\n",
      "Step [4/7], Loss: 0.00427\n",
      "Step [6/7], Loss: 0.00502\n",
      "Step [8/7], Loss: 0.00456\n",
      "Time elasped: 7.798694849014282\n",
      "Test Loss: 0.756301204363505\n",
      "Test Accuracy of the model on the test samples: 80.477\n",
      "\n",
      "max acc: 84.09893992932862\n",
      "Epoch [37/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.00448\n",
      "Step [4/7], Loss: 0.00444\n",
      "Step [6/7], Loss: 0.00499\n",
      "Step [8/7], Loss: 0.00402\n",
      "Time elasped: 9.566960334777832\n",
      "Test Loss: 0.7448763251304626\n",
      "Test Accuracy of the model on the test samples: 80.919\n",
      "\n",
      "max acc: 84.09893992932862\n",
      "Epoch [38/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.00400\n",
      "Step [4/7], Loss: 0.00323\n",
      "Step [6/7], Loss: 0.00514\n",
      "Step [8/7], Loss: 0.00349\n",
      "Time elasped: 6.476278781890869\n",
      "Test Loss: 0.7566910187403361\n",
      "Test Accuracy of the model on the test samples: 82.023\n",
      "\n",
      "max acc: 84.09893992932862\n",
      "Epoch [39/50], learning_rates 0.001000, 0.100000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#torch.autograd.set_detect_anomaly(True)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train(snn, train_loader, test_loader, lr, num_epochs, test_behavior\u001b[38;5;241m=\u001b[39mtb_minimal, scheduler\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m0.95\u001b[39m), test_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\Python\\SNNdelays\\snn_delays\\utils\\train_utils_refact_minimal.py:57\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(snn, train_loader, test_loader, learning_rate, num_epochs, lr_tau, scheduler, ckpt_dir, test_behavior, test_every, verbose, clear)\u001b[0m\n\u001b[0;32m     52\u001b[0m current_lr_tau \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m], learning_rates \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, num_epochs,\n\u001b[0;32m     54\u001b[0m                                                  current_lr, current_lr_tau), flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 57\u001b[0m snn\u001b[38;5;241m.\u001b[39mtrain_step(train_loader, optimizer\u001b[38;5;241m=\u001b[39moptimizer, scheduler \u001b[38;5;241m=\u001b[39m scheduler)        \n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[0;32m     60\u001b[0m     t \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\Python\\SNNdelays\\snn_delays\\snn_refactoring_minimal_v4.py:156\u001b[0m, in \u001b[0;36mTraining.train_step\u001b[1;34m(self, train_loader, optimizer, scheduler)\u001b[0m\n\u001b[0;32m    152\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# Calculate gradients and optimize to update weights\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m#loss.backward(retain_graph=True)\u001b[39;00m\n\u001b[1;32m--> 156\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    157\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    158\u001b[0m \u001b[38;5;66;03m#scheduler.step()\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    523\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    524\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    267\u001b[0m     tensors,\n\u001b[0;32m    268\u001b[0m     grad_tensors_,\n\u001b[0;32m    269\u001b[0m     retain_graph,\n\u001b[0;32m    270\u001b[0m     create_graph,\n\u001b[0;32m    271\u001b[0m     inputs,\n\u001b[0;32m    272\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    273\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    274\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#torch.autograd.set_detect_anomaly(True)\n",
    "train(snn, train_loader, test_loader, lr, num_epochs, test_behavior=tb_minimal, scheduler=(100, 0.95), test_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda:0\n",
      "[CropTime(min=0, max=1000000.0), ToFrame(sensor_size=(700, 1, 1), time_window=None, event_count=None, n_time_bins=50, n_event_bins=None, overlap=0, include_incomplete=False)]\n",
      "\n",
      "[INFO] Delays: tensor([ 0, 16, 32])\n",
      "\n",
      "[INFO] Delays i: tensor([0])\n",
      "\n",
      "[INFO] Delays h: tensor([ 0, 16, 32])\n",
      "\n",
      "[INFO] Delays o: tensor([0])\n",
      "1000.0\n",
      "Delta t: 20.0 ms\n",
      "mean of normal: -0.541324854612918\n",
      "training shd50_l2_48d16.t7 for 50 epochs...\n",
      "Epoch [1/50], learning_rates 0.001000, 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [2/7], Loss: 3.32567\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 3.24455\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 3.22454\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 3.16965\n",
      "l1_score: 0\n",
      "Time elasped: 66.01844072341919\n",
      "Test Loss: 3.108332951863607\n",
      "Avg spk_count per neuron for all 50 time-steps 3.688900947570801\n",
      "Avg spk per neuron per layer [8.617567082597173, 6.138036936837456]\n",
      "Test Accuracy of the model on the test samples: 5.698\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "saving max acc: 5.6978798586572434\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [2/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 3.07441\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 3.05801\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 3.01410\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 2.98190\n",
      "l1_score: 0\n",
      "Time elasped: 2.936033010482788\n",
      "Test Loss: 2.9225052197774253\n",
      "Avg spk_count per neuron for all 50 time-steps 3.4812538623809814\n",
      "Avg spk per neuron per layer [8.174290525618375, 5.750724657685512]\n",
      "Test Accuracy of the model on the test samples: 13.383\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "saving max acc: 13.383392226148409\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [3/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 2.91043\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 2.89610\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 2.87136\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 2.83235\n",
      "l1_score: 0\n",
      "Time elasped: 3.124152183532715\n",
      "Test Loss: 2.7837637265523276\n",
      "Avg spk_count per neuron for all 50 time-steps 3.4581475257873535\n",
      "Avg spk per neuron per layer [8.13373730123675, 5.69885297040636]\n",
      "Test Accuracy of the model on the test samples: 20.760\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "saving max acc: 20.75971731448763\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [4/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 2.75175\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 2.70825\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 2.71843\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 2.59854\n",
      "l1_score: 0\n",
      "Time elasped: 2.835277557373047\n",
      "Test Loss: 2.511395295461019\n",
      "Avg spk_count per neuron for all 50 time-steps 3.613131284713745\n",
      "Avg spk per neuron per layer [8.25854405918728, 6.193980510159011]\n",
      "Test Accuracy of the model on the test samples: 25.265\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "saving max acc: 25.26501766784452\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [5/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 2.50123\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 2.43272\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 2.37991\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 2.37533\n",
      "l1_score: 0\n",
      "Time elasped: 2.8049111366271973\n",
      "Test Loss: 2.3626155058542886\n",
      "Avg spk_count per neuron for all 50 time-steps 3.6591193675994873\n",
      "Avg spk per neuron per layer [8.281215492491166, 6.355261704946996]\n",
      "Test Accuracy of the model on the test samples: 29.991\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "saving max acc: 29.991166077738516\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [6/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 2.27161\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 2.22849\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 2.16576\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 2.01892\n",
      "l1_score: 0\n",
      "Time elasped: 2.883899450302124\n",
      "Test Loss: 1.987551212310791\n",
      "Avg spk_count per neuron for all 50 time-steps 3.8937737941741943\n",
      "Avg spk per neuron per layer [8.726037985865725, 6.849057254858657]\n",
      "Test Accuracy of the model on the test samples: 43.640\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "saving max acc: 43.639575971731446\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [7/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 1.94852\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 1.79014\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 1.80991\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 1.68994\n",
      "l1_score: 0\n",
      "Time elasped: 2.817892551422119\n",
      "Test Loss: 1.7554419835408528\n",
      "Avg spk_count per neuron for all 50 time-steps 4.141115188598633\n",
      "Avg spk per neuron per layer [9.10368816254417, 7.460771863957597]\n",
      "Test Accuracy of the model on the test samples: 52.606\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "saving max acc: 52.60600706713781\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [8/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 1.48365\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 1.45720\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 1.35340\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 1.32829\n",
      "l1_score: 0\n",
      "Time elasped: 2.8857223987579346\n",
      "Test Loss: 1.2301402886708577\n",
      "Avg spk_count per neuron for all 50 time-steps 4.174699306488037\n",
      "Avg spk per neuron per layer [9.056820064045937, 7.64197769434629]\n",
      "Test Accuracy of the model on the test samples: 61.352\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "saving max acc: 61.351590106007066\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [9/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 1.18534\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 1.14150\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 1.06908\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 1.10147\n",
      "l1_score: 0\n",
      "Time elasped: 2.8952081203460693\n",
      "Test Loss: 1.1844100952148438\n",
      "Avg spk_count per neuron for all 50 time-steps 4.238036155700684\n",
      "Avg spk per neuron per layer [9.334398465106007, 7.6177465216431095]\n",
      "Test Accuracy of the model on the test samples: 63.339\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "saving max acc: 63.33922261484099\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [10/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.97184\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.96148\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.83653\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.83271\n",
      "l1_score: 0\n",
      "Time elasped: 2.9120941162109375\n",
      "Test Loss: 1.1205466985702515\n",
      "Avg spk_count per neuron for all 50 time-steps 4.263858318328857\n",
      "Avg spk per neuron per layer [9.448611417844523, 7.60682144434629]\n",
      "Test Accuracy of the model on the test samples: 68.110\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "saving max acc: 68.1095406360424\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [11/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.76397\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.73272\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.77063\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.72810\n",
      "l1_score: 0\n",
      "Time elasped: 2.8445653915405273\n",
      "Test Loss: 0.9002285599708557\n",
      "Avg spk_count per neuron for all 50 time-steps 4.308096885681152\n",
      "Avg spk per neuron per layer [9.362501380300353, 7.869885987190813]\n",
      "Test Accuracy of the model on the test samples: 68.375\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "saving max acc: 68.37455830388693\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [12/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.60023\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.59733\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.57424\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.58373\n",
      "l1_score: 0\n",
      "Time elasped: 2.8403093814849854\n",
      "Test Loss: 0.9282569487889608\n",
      "Avg spk_count per neuron for all 50 time-steps 4.391656875610352\n",
      "Avg spk per neuron per layer [9.48529980123675, 8.081327296819788]\n",
      "Test Accuracy of the model on the test samples: 70.053\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "saving max acc: 70.0530035335689\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [13/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.51685\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.54427\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.48795\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.49137\n",
      "l1_score: 0\n",
      "Time elasped: 3.007567882537842\n",
      "Test Loss: 0.8475287556648254\n",
      "Avg spk_count per neuron for all 50 time-steps 4.458142280578613\n",
      "Avg spk per neuron per layer [9.47731476369258, 8.355254803445229]\n",
      "Test Accuracy of the model on the test samples: 71.246\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "saving max acc: 71.24558303886926\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [14/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.43571\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.39498\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.50026\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.41519\n",
      "l1_score: 0\n",
      "Time elasped: 3.0159966945648193\n",
      "Test Loss: 0.7656809091567993\n",
      "Avg spk_count per neuron for all 50 time-steps 4.502041339874268\n",
      "Avg spk per neuron per layer [9.541691972173146, 8.466472504416961]\n",
      "Test Accuracy of the model on the test samples: 74.117\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "saving max acc: 74.11660777385158\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [15/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.42944\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.41897\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.37364\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.36492\n",
      "l1_score: 0\n",
      "Time elasped: 2.9701640605926514\n",
      "Test Loss: 0.8057926297187805\n",
      "Avg spk_count per neuron for all 50 time-steps 4.579189777374268\n",
      "Avg spk per neuron per layer [9.847297371908127, 8.469460854681978]\n",
      "Test Accuracy of the model on the test samples: 74.382\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "saving max acc: 74.38162544169612\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [16/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.39183\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.35159\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.37884\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.32238\n",
      "l1_score: 0\n",
      "Time elasped: 3.135751962661743\n",
      "Test Loss: 0.7296324570973715\n",
      "Avg spk_count per neuron for all 50 time-steps 4.55780029296875\n",
      "Avg spk per neuron per layer [9.766556702738516, 8.464643606448764]\n",
      "Test Accuracy of the model on the test samples: 76.016\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "saving max acc: 76.01590106007068\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [17/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.30495\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.28130\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.32472\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.26771\n",
      "l1_score: 0\n",
      "Time elasped: 3.260718822479248\n",
      "Test Loss: 0.7215158144632975\n",
      "Avg spk_count per neuron for all 50 time-steps 4.554029941558838\n",
      "Avg spk per neuron per layer [9.624848166961131, 8.591272360865725]\n",
      "Test Accuracy of the model on the test samples: 77.032\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "saving max acc: 77.03180212014134\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [18/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.26276\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.22407\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.26191\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.22638\n",
      "l1_score: 0\n",
      "Time elasped: 2.8635122776031494\n",
      "Test Loss: 0.7354279557863871\n",
      "Avg spk_count per neuron for all 50 time-steps 4.586339473724365\n",
      "Avg spk per neuron per layer [9.769317303445229, 8.57604074646643]\n",
      "Test Accuracy of the model on the test samples: 76.723\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [19/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.21806\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.19672\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.20707\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.20356\n",
      "l1_score: 0\n",
      "Time elasped: 2.905487060546875\n",
      "Test Loss: 0.7371305624643961\n",
      "Avg spk_count per neuron for all 50 time-steps 4.612918853759766\n",
      "Avg spk per neuron per layer [9.772574812279151, 8.679100872349823]\n",
      "Test Accuracy of the model on the test samples: 75.883\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [20/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.19943\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.20713\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.19159\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.20878\n",
      "l1_score: 0\n",
      "Time elasped: 3.0551512241363525\n",
      "Test Loss: 0.6837127606074015\n",
      "Avg spk_count per neuron for all 50 time-steps 4.6364617347717285\n",
      "Avg spk per neuron per layer [9.80108491607774, 8.74476176015901]\n",
      "Test Accuracy of the model on the test samples: 79.859\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "saving max acc: 79.85865724381625\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [21/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.15923\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.16646\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.14337\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.21719\n",
      "l1_score: 0\n",
      "Time elasped: 2.8915255069732666\n",
      "Test Loss: 0.6468846201896667\n",
      "Avg spk_count per neuron for all 50 time-steps 4.662751197814941\n",
      "Avg spk per neuron per layer [9.905035335689046, 8.745969522968197]\n",
      "Test Accuracy of the model on the test samples: 80.742\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "saving max acc: 80.74204946996467\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [22/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.17264\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.16612\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.15328\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.17290\n",
      "l1_score: 0\n",
      "Time elasped: 2.829685688018799\n",
      "Test Loss: 0.7278558810551962\n",
      "Avg spk_count per neuron for all 50 time-steps 4.692608833312988\n",
      "Avg spk per neuron per layer [9.919873564487633, 8.850561782243815]\n",
      "Test Accuracy of the model on the test samples: 79.417\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [23/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.14738\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.19474\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.14565\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.13822\n",
      "l1_score: 0\n",
      "Time elasped: 2.8394479751586914\n",
      "Test Loss: 0.6769383351008097\n",
      "Avg spk_count per neuron for all 50 time-steps 4.64728307723999\n",
      "Avg spk per neuron per layer [9.761456492932862, 8.827676402385158]\n",
      "Test Accuracy of the model on the test samples: 79.196\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [24/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.11977\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.14963\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.15436\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.12862\n",
      "l1_score: 0\n",
      "Time elasped: 2.8657617568969727\n",
      "Test Loss: 0.8962862491607666\n",
      "Avg spk_count per neuron for all 50 time-steps 4.696078777313232\n",
      "Avg spk per neuron per layer [9.931550905477032, 8.85276336130742]\n",
      "Test Accuracy of the model on the test samples: 74.602\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [25/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.15043\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.09713\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.15801\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.19532\n",
      "l1_score: 0\n",
      "Time elasped: 3.044215679168701\n",
      "Test Loss: 0.6883555849393209\n",
      "Avg spk_count per neuron for all 50 time-steps 4.604007244110107\n",
      "Avg spk per neuron per layer [9.80260324646643, 8.613426181537102]\n",
      "Test Accuracy of the model on the test samples: 78.710\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [26/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.16171\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.13524\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.15797\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.14070\n",
      "l1_score: 0\n",
      "Time elasped: 2.91005802154541\n",
      "Test Loss: 0.8811304569244385\n",
      "Avg spk_count per neuron for all 50 time-steps 4.699650287628174\n",
      "Avg spk per neuron per layer [9.960288758833922, 8.838311616607774]\n",
      "Test Accuracy of the model on the test samples: 75.574\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [27/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.12731\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.14866\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.10649\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.13302\n",
      "l1_score: 0\n",
      "Time elasped: 2.889645576477051\n",
      "Test Loss: 0.7146268089612325\n",
      "Avg spk_count per neuron for all 50 time-steps 4.6934285163879395\n",
      "Avg spk per neuron per layer [9.953766839664311, 8.81994672040636]\n",
      "Test Accuracy of the model on the test samples: 80.786\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "saving max acc: 80.78621908127208\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [28/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.09461\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.11978\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.07089\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.08643\n",
      "l1_score: 0\n",
      "Time elasped: 2.8449149131774902\n",
      "Test Loss: 0.6837929685910543\n",
      "Avg spk_count per neuron for all 50 time-steps 4.678452014923096\n",
      "Avg spk per neuron per layer [9.900507950530036, 8.813300574204947]\n",
      "Test Accuracy of the model on the test samples: 80.035\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [29/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.09907\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.09978\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.07483\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.09574\n",
      "l1_score: 0\n",
      "Time elasped: 3.022984027862549\n",
      "Test Loss: 0.7393456896146139\n",
      "Avg spk_count per neuron for all 50 time-steps 4.657281875610352\n",
      "Avg spk per neuron per layer [9.80994644434629, 8.819180653710248]\n",
      "Test Accuracy of the model on the test samples: 78.666\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [30/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.08728\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.08734\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.07035\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.06871\n",
      "l1_score: 0\n",
      "Time elasped: 3.1006860733032227\n",
      "Test Loss: 0.7488299409548441\n",
      "Avg spk_count per neuron for all 50 time-steps 4.68243932723999\n",
      "Avg spk per neuron per layer [9.913303334805654, 8.816454560512367]\n",
      "Test Accuracy of the model on the test samples: 81.007\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "saving max acc: 81.00706713780919\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [31/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.07922\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.07001\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.05105\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.09010\n",
      "l1_score: 0\n",
      "Time elasped: 2.881892204284668\n",
      "Test Loss: 0.7105611562728882\n",
      "Avg spk_count per neuron for all 50 time-steps 4.69451379776001\n",
      "Avg spk per neuron per layer [9.895028158127209, 8.883026446554771]\n",
      "Test Accuracy of the model on the test samples: 79.549\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [32/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.09694\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.06148\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.06442\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.08248\n",
      "l1_score: 0\n",
      "Time elasped: 3.2141125202178955\n",
      "Test Loss: 0.679727832476298\n",
      "Avg spk_count per neuron for all 50 time-steps 4.7009992599487305\n",
      "Avg spk per neuron per layer [9.907623398851591, 8.896373950971732]\n",
      "Test Accuracy of the model on the test samples: 81.537\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "saving max acc: 81.53710247349824\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [33/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.07810\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.06299\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.05674\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.04328\n",
      "l1_score: 0\n",
      "Time elasped: 2.9046409130096436\n",
      "Test Loss: 0.6780394315719604\n",
      "Avg spk_count per neuron for all 50 time-steps 4.6941237449646\n",
      "Avg spk per neuron per layer [9.887298476148409, 8.889196389134275]\n",
      "Test Accuracy of the model on the test samples: 80.345\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [34/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.05265\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.04997\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.05484\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.05007\n",
      "l1_score: 0\n",
      "Time elasped: 2.8902833461761475\n",
      "Test Loss: 0.7687377532323202\n",
      "Avg spk_count per neuron for all 50 time-steps 4.717030048370361\n",
      "Avg spk per neuron per layer [9.992891453180212, 8.875227749558304]\n",
      "Test Accuracy of the model on the test samples: 80.080\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [35/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.04556\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.04087\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.03738\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.04570\n",
      "l1_score: 0\n",
      "Time elasped: 2.922330856323242\n",
      "Test Loss: 0.657589336236318\n",
      "Avg spk_count per neuron for all 50 time-steps 4.725515365600586\n",
      "Avg spk per neuron per layer [9.977839277826854, 8.924221510600706]\n",
      "Test Accuracy of the model on the test samples: 81.007\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [36/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.03937\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.03565\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.03276\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.03967\n",
      "l1_score: 0\n",
      "Time elasped: 2.871389389038086\n",
      "Test Loss: 0.7025326093037924\n",
      "Avg spk_count per neuron for all 50 time-steps 4.7002058029174805\n",
      "Avg spk per neuron per layer [9.905663372349823, 8.895159286660778]\n",
      "Test Accuracy of the model on the test samples: 80.610\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [37/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.03945\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.02257\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.02202\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.03735\n",
      "l1_score: 0\n",
      "Time elasped: 3.109186887741089\n",
      "Test Loss: 0.740741233030955\n",
      "Avg spk_count per neuron for all 50 time-steps 4.761701583862305\n",
      "Avg spk per neuron per layer [10.014306813162545, 9.032499171819788]\n",
      "Test Accuracy of the model on the test samples: 80.212\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [38/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.03236\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.02803\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.04591\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.04450\n",
      "l1_score: 0\n",
      "Time elasped: 3.410179853439331\n",
      "Test Loss: 0.8491162459055582\n",
      "Avg spk_count per neuron for all 50 time-steps 4.735158443450928\n",
      "Avg spk per neuron per layer [9.947058579946997, 8.993574701855124]\n",
      "Test Accuracy of the model on the test samples: 78.224\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [39/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.02666\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.03336\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.04325\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.03549\n",
      "l1_score: 0\n",
      "Time elasped: 2.9945180416107178\n",
      "Test Loss: 0.8044131398200989\n",
      "Avg spk_count per neuron for all 50 time-steps 4.762655735015869\n",
      "Avg spk per neuron per layer [10.027012477915195, 9.02361003754417]\n",
      "Test Accuracy of the model on the test samples: 79.329\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [40/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.03626\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.03797\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.03140\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.03412\n",
      "l1_score: 0\n",
      "Time elasped: 2.9388558864593506\n",
      "Test Loss: 0.8361161152521769\n",
      "Avg spk_count per neuron for all 50 time-steps 4.729430198669434\n",
      "Avg spk per neuron per layer [9.92707183083039, 8.990648465106007]\n",
      "Test Accuracy of the model on the test samples: 78.799\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [41/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.02468\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.04770\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.02418\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.03602\n",
      "l1_score: 0\n",
      "Time elasped: 2.9632883071899414\n",
      "Test Loss: 0.7624576489130656\n",
      "Avg spk_count per neuron for all 50 time-steps 4.77616024017334\n",
      "Avg spk per neuron per layer [10.024583149293287, 9.0800574204947]\n",
      "Test Accuracy of the model on the test samples: 81.537\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "saving max acc: 81.53710247349824\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [42/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.03329\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.02381\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.02202\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.02567\n",
      "l1_score: 0\n",
      "Time elasped: 2.92447829246521\n",
      "Test Loss: 0.7929741938908895\n",
      "Avg spk_count per neuron for all 50 time-steps 4.774534702301025\n",
      "Avg spk per neuron per layer [10.006294169611307, 9.091845185512367]\n",
      "Test Accuracy of the model on the test samples: 79.814\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [43/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.01488\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.01931\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.02122\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.03079\n",
      "l1_score: 0\n",
      "Time elasped: 2.8400323390960693\n",
      "Test Loss: 0.7711538871129354\n",
      "Avg spk_count per neuron for all 50 time-steps 4.7530364990234375\n",
      "Avg spk per neuron per layer [9.958666905918728, 9.053479737190813]\n",
      "Test Accuracy of the model on the test samples: 80.919\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [44/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.02061\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.01334\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.03099\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.02381\n",
      "l1_score: 0\n",
      "Time elasped: 2.979200839996338\n",
      "Test Loss: 0.9623566269874573\n",
      "Avg spk_count per neuron for all 50 time-steps 4.749739646911621\n",
      "Avg spk per neuron per layer [9.94709308745583, 9.051864785777385]\n",
      "Test Accuracy of the model on the test samples: 78.622\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [45/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.01517\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.01256\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.02216\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.01285\n",
      "l1_score: 0\n",
      "Time elasped: 2.9475717544555664\n",
      "Test Loss: 0.7432950337727865\n",
      "Avg spk_count per neuron for all 50 time-steps 4.764907360076904\n",
      "Avg spk per neuron per layer [9.975313328180212, 9.084315647084805]\n",
      "Test Accuracy of the model on the test samples: 81.449\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [46/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.01592\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.01191\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.01557\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.01585\n",
      "l1_score: 0\n",
      "Time elasped: 3.1061789989471436\n",
      "Test Loss: 0.7907739082972208\n",
      "Avg spk_count per neuron for all 50 time-steps 4.774686813354492\n",
      "Avg spk per neuron per layer [9.96329781360424, 9.135448873674912]\n",
      "Test Accuracy of the model on the test samples: 80.963\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [47/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.00998\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.01287\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.01880\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.01067\n",
      "l1_score: 0\n",
      "Time elasped: 3.1013522148132324\n",
      "Test Loss: 0.8332257668177286\n",
      "Avg spk_count per neuron for all 50 time-steps 4.805494785308838\n",
      "Avg spk per neuron per layer [10.029545329063604, 9.19243457376325]\n",
      "Test Accuracy of the model on the test samples: 79.947\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [48/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.02007\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.00943\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.00837\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.01065\n",
      "l1_score: 0\n",
      "Time elasped: 3.232696533203125\n",
      "Test Loss: 0.8976746797561646\n",
      "Avg spk_count per neuron for all 50 time-steps 4.772648811340332\n",
      "Avg spk per neuron per layer [9.97484402606007, 9.115751987632509]\n",
      "Test Accuracy of the model on the test samples: 80.256\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [49/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.01215\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.00752\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.00756\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.00840\n",
      "l1_score: 0\n",
      "Time elasped: 2.9713573455810547\n",
      "Test Loss: 0.8805637359619141\n",
      "Avg spk_count per neuron for all 50 time-steps 4.789618015289307\n",
      "Avg spk per neuron per layer [9.974830223056538, 9.183642060512367]\n",
      "Test Accuracy of the model on the test samples: 80.035\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [50/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.00779\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.00961\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.00876\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.01258\n",
      "l1_score: 0\n",
      "Time elasped: 3.6653032302856445\n",
      "Test Loss: 0.7773708899815878\n",
      "Avg spk_count per neuron for all 50 time-steps 4.7960124015808105\n",
      "Avg spk per neuron per layer [10.011277053886927, 9.172772195229681]\n",
      "Test Accuracy of the model on the test samples: 80.786\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "from snn_delays.snn import SNN\n",
    "from snn_delays.utils.dataset_loader import DatasetLoader\n",
    "from snn_delays.utils.train_utils import train, get_device\n",
    "from snn_delays.utils.test_behavior import tb_save_max_last_acc\n",
    "\n",
    "'''\n",
    "SHD dataset as in ablation study\n",
    "'''\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "# for reproducibility\n",
    "torch.manual_seed(10)\n",
    "\n",
    "dataset = 'shd'\n",
    "total_time = 50\n",
    "batch_size = 1024\n",
    "\n",
    "# DATASET\n",
    "DL = DatasetLoader(dataset=dataset,\n",
    "                  caching='memory',\n",
    "                  num_workers=0,\n",
    "                  batch_size=batch_size,\n",
    "                  total_time=total_time,\n",
    "                  crop_to=1e6)\n",
    "train_loader, test_loader, dataset_dict = DL.get_dataloaders()\n",
    "          \n",
    "num_epochs = 50\n",
    "\n",
    "lr = 1e-3\n",
    "# SNN CON DELAYS\n",
    "taimu1 = time.time()\n",
    "\n",
    "tau_m = 'normal'\n",
    "ckpt_dir = 'exp3_shd50_rnn' \n",
    "\n",
    "delay = (48, 16)\n",
    "\n",
    "snn = SNN(dataset_dict=dataset_dict, structure=(64, 2), connection_type='f',\n",
    "    delay=delay, delay_type='h', tau_m = tau_m,\n",
    "    win=total_time, loss_fn='mem_sum', batch_size=batch_size, device=device,\n",
    "    debug=False)\n",
    "\n",
    "snn.set_network()\n",
    "\n",
    "snn.to(device)\n",
    "train(snn, train_loader, test_loader, lr, num_epochs, dropout=0.0, \n",
    "    test_behavior=tb_save_max_last_acc, ckpt_dir=ckpt_dir, scheduler=(100, 0.95), test_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda:0\n",
      "[CropTime(min=0, max=1000000.0), ToFrame(sensor_size=(700, 1, 1), time_window=None, event_count=None, n_time_bins=50, n_event_bins=None, overlap=0, include_incomplete=False)]\n",
      "1000.0\n",
      "Delta t: 20.0 ms\n",
      "mean of normal: -0.541324854612918\n",
      "Epoch [1/50], learning_rates 0.001000, 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [2/7], Loss: 3.14698\n",
      "Step [4/7], Loss: 3.05751\n",
      "Step [6/7], Loss: 3.00923\n",
      "Step [8/7], Loss: 2.97544\n",
      "Time elasped: 41.14631748199463\n",
      "Test Loss: 3.0036439100901284\n",
      "Test Accuracy of the model on the test samples: 7.818\n",
      "\n",
      "max acc: 7.818021201413427\n",
      "Epoch [2/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 2.97846\n",
      "Step [4/7], Loss: 2.96581\n",
      "Step [6/7], Loss: 2.95501\n",
      "Step [8/7], Loss: 2.91964\n",
      "Time elasped: 1.9507837295532227\n",
      "Test Loss: 2.93595290184021\n",
      "Test Accuracy of the model on the test samples: 9.320\n",
      "\n",
      "max acc: 9.319787985865725\n",
      "Epoch [3/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 2.89774\n",
      "Step [4/7], Loss: 2.86694\n",
      "Step [6/7], Loss: 2.87383\n",
      "Step [8/7], Loss: 2.83299\n",
      "Time elasped: 1.8823692798614502\n",
      "Test Loss: 2.9124337832132974\n",
      "Test Accuracy of the model on the test samples: 10.247\n",
      "\n",
      "max acc: 10.247349823321555\n",
      "Epoch [4/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 2.84203\n",
      "Step [4/7], Loss: 2.83172\n",
      "Step [6/7], Loss: 2.78780\n",
      "Step [8/7], Loss: 2.79797\n",
      "Time elasped: 1.8879191875457764\n",
      "Test Loss: 2.748133977254232\n",
      "Test Accuracy of the model on the test samples: 17.580\n",
      "\n",
      "max acc: 17.579505300353357\n",
      "Epoch [5/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 2.71195\n",
      "Step [4/7], Loss: 2.69478\n",
      "Step [6/7], Loss: 2.68296\n",
      "Step [8/7], Loss: 2.59913\n",
      "Time elasped: 1.8265736103057861\n",
      "Test Loss: 2.5874928633371987\n",
      "Test Accuracy of the model on the test samples: 20.892\n",
      "\n",
      "max acc: 20.892226148409893\n",
      "Epoch [6/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 2.48297\n",
      "Step [4/7], Loss: 2.45787\n",
      "Step [6/7], Loss: 2.39301\n",
      "Step [8/7], Loss: 2.25561\n",
      "Time elasped: 2.030989646911621\n",
      "Test Loss: 2.3437509536743164\n",
      "Test Accuracy of the model on the test samples: 27.076\n",
      "\n",
      "max acc: 27.075971731448764\n",
      "Epoch [7/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 2.21331\n",
      "Step [4/7], Loss: 2.16593\n",
      "Step [6/7], Loss: 2.13721\n",
      "Step [8/7], Loss: 2.08601\n",
      "Time elasped: 1.9669928550720215\n",
      "Test Loss: 2.134233236312866\n",
      "Test Accuracy of the model on the test samples: 33.746\n",
      "\n",
      "max acc: 33.745583038869256\n",
      "Epoch [8/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 2.05661\n",
      "Step [4/7], Loss: 2.02324\n",
      "Step [6/7], Loss: 1.97442\n",
      "Step [8/7], Loss: 1.87673\n",
      "Time elasped: 1.91245698928833\n",
      "Test Loss: 2.3345356782277427\n",
      "Test Accuracy of the model on the test samples: 33.127\n",
      "\n",
      "max acc: 33.745583038869256\n",
      "Epoch [9/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 1.93552\n",
      "Step [4/7], Loss: 1.85658\n",
      "Step [6/7], Loss: 1.75170\n",
      "Step [8/7], Loss: 1.69767\n",
      "Time elasped: 1.8699061870574951\n",
      "Test Loss: 2.025254249572754\n",
      "Test Accuracy of the model on the test samples: 37.058\n",
      "\n",
      "max acc: 37.05830388692579\n",
      "Epoch [10/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 1.63977\n",
      "Step [4/7], Loss: 1.70995\n",
      "Step [6/7], Loss: 1.56137\n",
      "Step [8/7], Loss: 1.52979\n",
      "Time elasped: 2.0171306133270264\n",
      "Test Loss: 1.8511188824971516\n",
      "Test Accuracy of the model on the test samples: 43.684\n",
      "\n",
      "max acc: 43.68374558303887\n",
      "Epoch [11/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 1.52708\n",
      "Step [4/7], Loss: 1.46265\n",
      "Step [6/7], Loss: 1.47825\n",
      "Step [8/7], Loss: 1.35882\n",
      "Time elasped: 1.9507238864898682\n",
      "Test Loss: 1.6927775541941326\n",
      "Test Accuracy of the model on the test samples: 48.587\n",
      "\n",
      "max acc: 48.58657243816254\n",
      "Epoch [12/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 1.41722\n",
      "Step [4/7], Loss: 1.28300\n",
      "Step [6/7], Loss: 1.28975\n",
      "Step [8/7], Loss: 1.24747\n",
      "Time elasped: 1.8904602527618408\n",
      "Test Loss: 1.8529611031214397\n",
      "Test Accuracy of the model on the test samples: 49.072\n",
      "\n",
      "max acc: 49.07243816254417\n",
      "Epoch [13/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 1.27145\n",
      "Step [4/7], Loss: 1.18559\n",
      "Step [6/7], Loss: 1.13327\n",
      "Step [8/7], Loss: 1.09206\n",
      "Time elasped: 2.0064916610717773\n",
      "Test Loss: 1.717301368713379\n",
      "Test Accuracy of the model on the test samples: 50.928\n",
      "\n",
      "max acc: 50.92756183745583\n",
      "Epoch [14/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 1.12737\n",
      "Step [4/7], Loss: 0.92417\n",
      "Step [6/7], Loss: 1.06041\n",
      "Step [8/7], Loss: 0.98299\n",
      "Time elasped: 2.0344526767730713\n",
      "Test Loss: 1.6149070262908936\n",
      "Test Accuracy of the model on the test samples: 50.530\n",
      "\n",
      "max acc: 50.92756183745583\n",
      "Epoch [15/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 1.04656\n",
      "Step [4/7], Loss: 1.00189\n",
      "Step [6/7], Loss: 0.95502\n",
      "Step [8/7], Loss: 0.90814\n",
      "Time elasped: 2.0542869567871094\n",
      "Test Loss: 1.4770385026931763\n",
      "Test Accuracy of the model on the test samples: 55.830\n",
      "\n",
      "max acc: 55.830388692579504\n",
      "Epoch [16/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.82256\n",
      "Step [4/7], Loss: 0.85822\n",
      "Step [6/7], Loss: 0.78029\n",
      "Step [8/7], Loss: 0.85357\n",
      "Time elasped: 1.921769618988037\n",
      "Test Loss: 1.370574156443278\n",
      "Test Accuracy of the model on the test samples: 60.071\n",
      "\n",
      "max acc: 60.07067137809187\n",
      "Epoch [17/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.79311\n",
      "Step [4/7], Loss: 0.72867\n",
      "Step [6/7], Loss: 0.77520\n",
      "Step [8/7], Loss: 0.68312\n",
      "Time elasped: 1.8546350002288818\n",
      "Test Loss: 1.4298506180445354\n",
      "Test Accuracy of the model on the test samples: 60.954\n",
      "\n",
      "max acc: 60.95406360424028\n",
      "Epoch [18/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.63787\n",
      "Step [4/7], Loss: 0.68688\n",
      "Step [6/7], Loss: 0.57944\n",
      "Step [8/7], Loss: 0.64777\n",
      "Time elasped: 1.9400537014007568\n",
      "Test Loss: 1.5141316652297974\n",
      "Test Accuracy of the model on the test samples: 63.030\n",
      "\n",
      "max acc: 63.03003533568904\n",
      "Epoch [19/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.61092\n",
      "Step [4/7], Loss: 0.57183\n",
      "Step [6/7], Loss: 0.46775\n",
      "Step [8/7], Loss: 0.60983\n",
      "Time elasped: 1.958076000213623\n",
      "Test Loss: 1.3021306991577148\n",
      "Test Accuracy of the model on the test samples: 64.929\n",
      "\n",
      "max acc: 64.92932862190813\n",
      "Epoch [20/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.57148\n",
      "Step [4/7], Loss: 0.57966\n",
      "Step [6/7], Loss: 0.52277\n",
      "Step [8/7], Loss: 0.54043\n",
      "Time elasped: 1.92985200881958\n",
      "Test Loss: 1.2108478546142578\n",
      "Test Accuracy of the model on the test samples: 67.314\n",
      "\n",
      "max acc: 67.31448763250883\n",
      "Epoch [21/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.49615\n",
      "Step [4/7], Loss: 0.51344\n",
      "Step [6/7], Loss: 0.49930\n",
      "Step [8/7], Loss: 0.48667\n",
      "Time elasped: 2.018584728240967\n",
      "Test Loss: 1.312312642733256\n",
      "Test Accuracy of the model on the test samples: 66.122\n",
      "\n",
      "max acc: 67.31448763250883\n",
      "Epoch [22/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.43963\n",
      "Step [4/7], Loss: 0.39618\n",
      "Step [6/7], Loss: 0.41729\n",
      "Step [8/7], Loss: 0.47538\n",
      "Time elasped: 2.063462972640991\n",
      "Test Loss: 1.3148279190063477\n",
      "Test Accuracy of the model on the test samples: 67.359\n",
      "\n",
      "max acc: 67.35865724381625\n",
      "Epoch [23/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.35789\n",
      "Step [4/7], Loss: 0.42172\n",
      "Step [6/7], Loss: 0.39309\n",
      "Step [8/7], Loss: 0.35776\n",
      "Time elasped: 2.132521390914917\n",
      "Test Loss: 1.2528391281763713\n",
      "Test Accuracy of the model on the test samples: 67.580\n",
      "\n",
      "max acc: 67.57950530035336\n",
      "Epoch [24/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.41695\n",
      "Step [4/7], Loss: 0.34959\n",
      "Step [6/7], Loss: 0.42504\n",
      "Step [8/7], Loss: 0.37166\n",
      "Time elasped: 1.933053970336914\n",
      "Test Loss: 1.1629387537638347\n",
      "Test Accuracy of the model on the test samples: 68.375\n",
      "\n",
      "max acc: 68.37455830388693\n",
      "Epoch [25/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.32953\n",
      "Step [4/7], Loss: 0.30482\n",
      "Step [6/7], Loss: 0.33635\n",
      "Step [8/7], Loss: 0.27569\n",
      "Time elasped: 1.887312889099121\n",
      "Test Loss: 1.0543994506200154\n",
      "Test Accuracy of the model on the test samples: 69.965\n",
      "\n",
      "max acc: 69.96466431095406\n",
      "Epoch [26/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.27189\n",
      "Step [4/7], Loss: 0.24448\n",
      "Step [6/7], Loss: 0.28211\n",
      "Step [8/7], Loss: 0.39198\n",
      "Time elasped: 1.8802459239959717\n",
      "Test Loss: 1.2204659779866536\n",
      "Test Accuracy of the model on the test samples: 69.170\n",
      "\n",
      "max acc: 69.96466431095406\n",
      "Epoch [27/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.31309\n",
      "Step [4/7], Loss: 0.35638\n",
      "Step [6/7], Loss: 0.26597\n",
      "Step [8/7], Loss: 0.34286\n",
      "Time elasped: 1.9245779514312744\n",
      "Test Loss: 1.3666852712631226\n",
      "Test Accuracy of the model on the test samples: 66.343\n",
      "\n",
      "max acc: 69.96466431095406\n",
      "Epoch [28/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.32398\n",
      "Step [4/7], Loss: 0.24984\n",
      "Step [6/7], Loss: 0.29915\n",
      "Step [8/7], Loss: 0.26517\n",
      "Time elasped: 2.0710086822509766\n",
      "Test Loss: 1.274540901184082\n",
      "Test Accuracy of the model on the test samples: 69.611\n",
      "\n",
      "max acc: 69.96466431095406\n",
      "Epoch [29/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.23631\n",
      "Step [4/7], Loss: 0.23239\n",
      "Step [6/7], Loss: 0.22318\n",
      "Step [8/7], Loss: 0.19812\n",
      "Time elasped: 1.932892084121704\n",
      "Test Loss: 1.3393797477086384\n",
      "Test Accuracy of the model on the test samples: 68.286\n",
      "\n",
      "max acc: 69.96466431095406\n",
      "Epoch [30/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.22943\n",
      "Step [4/7], Loss: 0.19980\n",
      "Step [6/7], Loss: 0.19365\n",
      "Step [8/7], Loss: 0.19492\n",
      "Time elasped: 1.894033670425415\n",
      "Test Loss: 1.4581074714660645\n",
      "Test Accuracy of the model on the test samples: 68.110\n",
      "\n",
      "max acc: 69.96466431095406\n",
      "Epoch [31/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.18857\n",
      "Step [4/7], Loss: 0.18333\n",
      "Step [6/7], Loss: 0.23714\n",
      "Step [8/7], Loss: 0.19198\n",
      "Time elasped: 1.943751335144043\n",
      "Test Loss: 1.651272137959798\n",
      "Test Accuracy of the model on the test samples: 64.620\n",
      "\n",
      "max acc: 69.96466431095406\n",
      "Epoch [32/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.20778\n",
      "Step [4/7], Loss: 0.20746\n",
      "Step [6/7], Loss: 0.16754\n",
      "Step [8/7], Loss: 0.24028\n",
      "Time elasped: 1.8740465641021729\n",
      "Test Loss: 1.4749056895573933\n",
      "Test Accuracy of the model on the test samples: 68.242\n",
      "\n",
      "max acc: 69.96466431095406\n",
      "Epoch [33/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.28035\n",
      "Step [4/7], Loss: 0.21348\n",
      "Step [6/7], Loss: 0.22947\n",
      "Step [8/7], Loss: 0.20787\n",
      "Time elasped: 1.939927339553833\n",
      "Test Loss: 1.4373411337534587\n",
      "Test Accuracy of the model on the test samples: 65.724\n",
      "\n",
      "max acc: 69.96466431095406\n",
      "Epoch [34/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.19405\n",
      "Step [4/7], Loss: 0.21243\n",
      "Step [6/7], Loss: 0.16861\n",
      "Step [8/7], Loss: 0.19078\n",
      "Time elasped: 1.9046213626861572\n",
      "Test Loss: 1.299810806910197\n",
      "Test Accuracy of the model on the test samples: 69.655\n",
      "\n",
      "max acc: 69.96466431095406\n",
      "Epoch [35/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.17259\n",
      "Step [4/7], Loss: 0.15673\n",
      "Step [6/7], Loss: 0.13752\n",
      "Step [8/7], Loss: 0.14366\n",
      "Time elasped: 2.0245299339294434\n",
      "Test Loss: 1.2160205046335857\n",
      "Test Accuracy of the model on the test samples: 70.583\n",
      "\n",
      "max acc: 70.58303886925795\n",
      "Epoch [36/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.12318\n",
      "Step [4/7], Loss: 0.13471\n",
      "Step [6/7], Loss: 0.13816\n",
      "Step [8/7], Loss: 0.12170\n",
      "Time elasped: 1.9686853885650635\n",
      "Test Loss: 1.1948186953862507\n",
      "Test Accuracy of the model on the test samples: 71.290\n",
      "\n",
      "max acc: 71.28975265017668\n",
      "Epoch [37/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.09390\n",
      "Step [4/7], Loss: 0.14891\n",
      "Step [6/7], Loss: 0.11303\n",
      "Step [8/7], Loss: 0.11068\n",
      "Time elasped: 1.888866901397705\n",
      "Test Loss: 1.3768027226130168\n",
      "Test Accuracy of the model on the test samples: 68.330\n",
      "\n",
      "max acc: 71.28975265017668\n",
      "Epoch [38/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.13931\n",
      "Step [4/7], Loss: 0.13944\n",
      "Step [6/7], Loss: 0.14066\n",
      "Step [8/7], Loss: 0.13477\n",
      "Time elasped: 1.8846330642700195\n",
      "Test Loss: 1.5512875318527222\n",
      "Test Accuracy of the model on the test samples: 65.415\n",
      "\n",
      "max acc: 71.28975265017668\n",
      "Epoch [39/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.15881\n",
      "Step [4/7], Loss: 0.12681\n",
      "Step [6/7], Loss: 0.12555\n",
      "Step [8/7], Loss: 0.10844\n",
      "Time elasped: 1.9845235347747803\n",
      "Test Loss: 1.5655912558237712\n",
      "Test Accuracy of the model on the test samples: 67.403\n",
      "\n",
      "max acc: 71.28975265017668\n",
      "Epoch [40/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.13501\n",
      "Step [4/7], Loss: 0.12015\n",
      "Step [6/7], Loss: 0.09375\n",
      "Step [8/7], Loss: 0.11543\n",
      "Time elasped: 1.936976671218872\n",
      "Test Loss: 1.4519594113032024\n",
      "Test Accuracy of the model on the test samples: 69.479\n",
      "\n",
      "max acc: 71.28975265017668\n",
      "Epoch [41/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.09448\n",
      "Step [4/7], Loss: 0.10933\n",
      "Step [6/7], Loss: 0.09836\n",
      "Step [8/7], Loss: 0.12350\n",
      "Time elasped: 2.0958738327026367\n",
      "Test Loss: 1.3717296123504639\n",
      "Test Accuracy of the model on the test samples: 71.864\n",
      "\n",
      "max acc: 71.86395759717314\n",
      "Epoch [42/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.09091\n",
      "Step [4/7], Loss: 0.11848\n",
      "Step [6/7], Loss: 0.10240\n",
      "Step [8/7], Loss: 0.10172\n",
      "Time elasped: 1.959446668624878\n",
      "Test Loss: 1.4541816711425781\n",
      "Test Accuracy of the model on the test samples: 70.009\n",
      "\n",
      "max acc: 71.86395759717314\n",
      "Epoch [43/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.06278\n",
      "Step [4/7], Loss: 0.10070\n",
      "Step [6/7], Loss: 0.07583\n",
      "Step [8/7], Loss: 0.11166\n",
      "Time elasped: 2.09136700630188\n",
      "Test Loss: 1.5346802870432537\n",
      "Test Accuracy of the model on the test samples: 68.728\n",
      "\n",
      "max acc: 71.86395759717314\n",
      "Epoch [44/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.07487\n",
      "Step [4/7], Loss: 0.06805\n",
      "Step [6/7], Loss: 0.08363\n",
      "Step [8/7], Loss: 0.06223\n",
      "Time elasped: 1.9518074989318848\n",
      "Test Loss: 1.4652986526489258\n",
      "Test Accuracy of the model on the test samples: 69.832\n",
      "\n",
      "max acc: 71.86395759717314\n",
      "Epoch [45/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.06305\n",
      "Step [4/7], Loss: 0.05682\n",
      "Step [6/7], Loss: 0.05814\n",
      "Step [8/7], Loss: 0.06912\n",
      "Time elasped: 2.1123688220977783\n",
      "Test Loss: 1.498104413350423\n",
      "Test Accuracy of the model on the test samples: 70.318\n",
      "\n",
      "max acc: 71.86395759717314\n",
      "Epoch [46/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.08061\n",
      "Step [4/7], Loss: 0.07881\n",
      "Step [6/7], Loss: 0.03327\n",
      "Step [8/7], Loss: 0.05644\n",
      "Time elasped: 2.042126178741455\n",
      "Test Loss: 1.2772003014882405\n",
      "Test Accuracy of the model on the test samples: 72.041\n",
      "\n",
      "max acc: 72.04063604240282\n",
      "Epoch [47/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.05785\n",
      "Step [4/7], Loss: 0.05170\n",
      "Step [6/7], Loss: 0.05474\n",
      "Step [8/7], Loss: 0.03923\n",
      "Time elasped: 1.8429315090179443\n",
      "Test Loss: 1.2657338380813599\n",
      "Test Accuracy of the model on the test samples: 71.687\n",
      "\n",
      "max acc: 72.04063604240282\n",
      "Epoch [48/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.05447\n",
      "Step [4/7], Loss: 0.03525\n",
      "Step [6/7], Loss: 0.05089\n",
      "Step [8/7], Loss: 0.05835\n",
      "Time elasped: 1.9221692085266113\n",
      "Test Loss: 1.3815371195475261\n",
      "Test Accuracy of the model on the test samples: 71.422\n",
      "\n",
      "max acc: 72.04063604240282\n",
      "Epoch [49/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.03363\n",
      "Step [4/7], Loss: 0.03087\n",
      "Step [6/7], Loss: 0.07545\n",
      "Step [8/7], Loss: 0.08695\n",
      "Time elasped: 1.883204698562622\n",
      "Test Loss: 1.4105003674825032\n",
      "Test Accuracy of the model on the test samples: 70.583\n",
      "\n",
      "max acc: 72.04063604240282\n",
      "Epoch [50/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.04212\n",
      "Step [4/7], Loss: 0.06764\n",
      "Step [6/7], Loss: 0.07483\n",
      "Step [8/7], Loss: 0.04909\n",
      "Time elasped: 1.9381897449493408\n",
      "Test Loss: 1.4160467386245728\n",
      "Test Accuracy of the model on the test samples: 71.334\n",
      "\n",
      "max acc: 72.04063604240282\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "from snn_delays.snn_ffw_minimal import SNN\n",
    "from snn_delays.utils.dataset_loader import DatasetLoader\n",
    "from snn_delays.utils.train_utils_refact_minimal import train, get_device\n",
    "from snn_delays.utils.test_behavior import tb_minimal\n",
    "\n",
    "'''\n",
    "SHD dataset as in ablation study\n",
    "'''\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "# for reproducibility\n",
    "torch.manual_seed(10)\n",
    "\n",
    "dataset = 'shd'\n",
    "total_time = 50\n",
    "batch_size = 1024\n",
    "\n",
    "# DATASET\n",
    "DL = DatasetLoader(dataset=dataset,\n",
    "                  caching='memory',\n",
    "                  num_workers=0,\n",
    "                  batch_size=batch_size,\n",
    "                  total_time=total_time,\n",
    "                  crop_to=1e6)\n",
    "train_loader, test_loader, dataset_dict = DL.get_dataloaders()\n",
    "          \n",
    "num_epochs = 50\n",
    "\n",
    "lr = 1e-3\n",
    "# SNN CON DELAYS\n",
    "taimu1 = time.time()\n",
    "\n",
    "tau_m = 'normal'\n",
    "ckpt_dir = 'exp3_shd50_rnn' \n",
    "\n",
    "snn = SNN(dataset_dict=dataset_dict, num_neurons_list=[64, 64], tau_m = tau_m,\n",
    "    win=total_time, loss_fn='mem_sum', batch_size=batch_size, device=device)\n",
    "\n",
    "snn.set_network()\n",
    "\n",
    "snn.to(device)\n",
    "train(snn, train_loader, test_loader, lr, num_epochs, test_behavior=tb_minimal, scheduler=(100, 0.95), test_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepsnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
