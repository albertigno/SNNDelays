{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "from snn_delays.snn import SNN\n",
    "from snn_delays.utils.dataset_loader import DatasetLoader\n",
    "from snn_delays.utils.train_utils import get_device, print_spike_info, propagate_batch, set_seed\n",
    "from snn_delays.utils.visualization_utils import plot_raster\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from collections import OrderedDict\n",
    "device = get_device()\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tonic import MemoryCachedDataset\n",
    "# for reproducibility\n",
    "set_seed(42)\n",
    "\n",
    "# Custom dataset for digit concatenation from a filtered dataset\n",
    "class SequentialMemoryRetrievalDataset(Dataset):\n",
    "    def __init__(self, base_dataset, sequence_length, target_classes):\n",
    "        self.base_dataset = base_dataset\n",
    "        indices = [i for i, (img, label) in enumerate(base_dataset) if np.argmax(label) in target_classes]\n",
    "        zero_indices = [i for i, (img, label) in enumerate(base_dataset) if np.argmax(label) == 0]\n",
    "        \n",
    "        self.filtered_dataset = Subset(base_dataset, indices)\n",
    "        self.zeros_dataset = Subset(base_dataset, zero_indices)\n",
    "\n",
    "        self.indices = list(range(len(self.filtered_dataset)))  # Indices of the base dataset\n",
    "        self.zeros_indices = list(range(len(self.zeros_dataset)))\n",
    "\n",
    "        self.target_classes = target_classes\n",
    "        #self.pairs = [(i, j) for i in self.indices for j in self.indices]  # All possible pairs of indices\n",
    "        self.sequence_length = sequence_length\n",
    "        #self.pairs = list(product(self.indices, repeat=sequence_length))\n",
    "        self.num_classes = len(target_classes) # 0 is not a class \n",
    "        self.total_combinations = self.num_classes ** 2\n",
    "\n",
    "    def __len__(self):\n",
    "        # Number of pairs\n",
    "        #return len(self.pairs)\n",
    "        return len(self.base_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the indices for the current pair\n",
    "        #indices = self.pairs[idx]\n",
    "        # Retrieve the images and labels from the base dataset\n",
    "\n",
    "        images = []\n",
    "        all_labels = []\n",
    "        retrieval_labels = []\n",
    "\n",
    "        for i in range(self.sequence_length-2):\n",
    "            img, label = self.filtered_dataset[np.random.choice(self.indices)]\n",
    "            images.append(img)\n",
    "            all_labels.append(self.target_classes.index(np.argmax(label)))\n",
    "\n",
    "        # inserts zeroes randomly ()\n",
    "        idx_frst_zero = np.random.randint(self.sequence_length//2)\n",
    "        img, _ = self.zeros_dataset[np.random.choice(self.zeros_indices)]\n",
    "        images.insert(idx_frst_zero, img)\n",
    "        retrieval_labels.append(all_labels[idx_frst_zero])\n",
    "\n",
    "        idx_scnd_zero = np.random.randint(idx_frst_zero+2, self.sequence_length-1)\n",
    "        img, _ = self.zeros_dataset[np.random.choice(self.zeros_indices)]\n",
    "        images.insert(idx_scnd_zero, img)\n",
    "        retrieval_labels.append(all_labels[idx_scnd_zero-1])\n",
    "\n",
    "        # Concatenate the images along the width (you can adjust as needed)\n",
    "        concatenated_img = np.concatenate(images, axis=0)\n",
    "        \n",
    "        # Concatenate the labels one-hot\n",
    "        encoded_label = sum(l * (self.num_classes ** i) for i, l in enumerate(reversed(retrieval_labels)))\n",
    "        concatenated_label = np.zeros(self.total_combinations)\n",
    "        concatenated_label[encoded_label] = 1.0\n",
    "\n",
    "        return concatenated_img, concatenated_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_input': 10, 'num_training_samples': 10000, 'num_output': 9, 'time_ms': 0.0001, 'dataset_name': 'memorytask'}\n"
     ]
    }
   ],
   "source": [
    "from snn_delays.datasets.custom_datasets import CustomDataset\n",
    "\n",
    "lbl = [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], \n",
    "         [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]]\n",
    "\n",
    "imgs = [[1, 0, 1, 0, 1, 0, 1, 0, 1, 0],\n",
    "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 1, 1, 1, 1, 1], \n",
    "         [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]]\n",
    "\n",
    "num_samples = 15000\n",
    "\n",
    "data = np.zeros((num_samples, 1, 10))\n",
    "labels = np.zeros((num_samples, 10))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    cl = np.random.randint(4)\n",
    "    data[i] = 0.2*np.random.rand(10) + imgs[cl]\n",
    "    labels[i] = lbl[cl]\n",
    "\n",
    "train_dataset = CustomDataset(data[:10000], labels[:10000])\n",
    "test_dataset = CustomDataset(data[10000:], labels[10000:])\n",
    "\n",
    "dataset_dict = train_dataset.get_train_attributes()\n",
    "\n",
    "target_classes = [1, 3, 8]\n",
    "sequence_length = 10\n",
    "\n",
    "conc_test_dataset = SequentialMemoryRetrievalDataset(test_dataset, sequence_length, target_classes)\n",
    "conc_train_dataset = SequentialMemoryRetrievalDataset(train_dataset, sequence_length, target_classes)\n",
    "\n",
    "train_dataset = MemoryCachedDataset(conc_train_dataset)\n",
    "test_dataset = MemoryCachedDataset(conc_test_dataset)\n",
    "\n",
    "total_time = 1\n",
    "batch_size = 128\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            drop_last=False,\n",
    "                            pin_memory=True,\n",
    "                            num_workers=0)\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            drop_last=False,\n",
    "                            pin_memory=True,\n",
    "                            num_workers=0)\n",
    "\n",
    "dataset_dict[\"num_output\"] = conc_train_dataset.total_combinations\n",
    "dataset_dict[\"num_training_samples\"] = len(conc_train_dataset)\n",
    "dataset_dict[\"time_ms\"] = 1e-4\n",
    "dataset_dict[\"dataset_name\"] = \"memorytask\"\n",
    "\n",
    "print(dataset_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training without delays (50%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Delays: tensor([0])\n",
      "\n",
      "[INFO] Delays i: tensor([0])\n",
      "\n",
      "[INFO] Delays h: tensor([0])\n",
      "\n",
      "[INFO] Delays o: tensor([0])\n",
      "0.0001\n",
      "Delta t: 1e-05 ms\n",
      "mean of normal: 14.508657488628742\n",
      "training dvs5_seq10_Nonememorytask10_l4_1d1.t7 for 100 epochs...\n",
      "Epoch [1/100], learning_rates 0.001000, 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [26/78], Loss: 2.16212\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.13114\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.99931\n",
      "l1_score: 0\n",
      "Time elasped: 31.330262899398804\n",
      "Test Loss: 1.9969338327646255\n",
      "Avg spk_count per neuron for all 10 time-steps 0.3763216733932495\n",
      "Avg spk per neuron per layer [2.021659375, 1.65419375, 1.35134375, 0.99395]\n",
      "Test Accuracy of the model on the test samples: 24.340\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_3': 0.0000\n",
      "Gradient norm for 'tau_m_4': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0299\n",
      "Gradient norm for 'f0_f1.weight': 0.0048\n",
      "Gradient norm for 'f1_f2.weight': 0.0382\n",
      "Gradient norm for 'f2_f3.weight': 0.0918\n",
      "Gradient norm for 'f3_f4.weight': 0.3605\n",
      "Gradient norm for 'f4_o.weight': 1.5827\n",
      "saving max acc: 24.34\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [2/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.90094\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.81139\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.89562\n",
      "l1_score: 0\n",
      "Time elasped: 5.983015537261963\n",
      "Test Loss: 1.818446969985962\n",
      "Avg spk_count per neuron for all 10 time-steps 0.3940027356147766\n",
      "Avg spk per neuron per layer [2.0249, 1.6271625, 1.502821875, 1.149159375]\n",
      "Test Accuracy of the model on the test samples: 28.800\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_3': 0.0000\n",
      "Gradient norm for 'tau_m_4': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0131\n",
      "Gradient norm for 'f0_f1.weight': 0.0043\n",
      "Gradient norm for 'f1_f2.weight': 0.0391\n",
      "Gradient norm for 'f2_f3.weight': 0.1156\n",
      "Gradient norm for 'f3_f4.weight': 0.4419\n",
      "Gradient norm for 'f4_o.weight': 2.1908\n",
      "saving max acc: 28.8\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [3/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.79889\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.75345\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.73614\n",
      "l1_score: 0\n",
      "Time elasped: 5.692727327346802\n",
      "Test Loss: 1.7497848927974702\n",
      "Avg spk_count per neuron for all 10 time-steps 0.37835779786109924\n",
      "Avg spk per neuron per layer [1.969971875, 1.505634375, 1.40029375, 1.177825]\n",
      "Test Accuracy of the model on the test samples: 31.960\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_3': 0.0000\n",
      "Gradient norm for 'tau_m_4': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0361\n",
      "Gradient norm for 'f0_f1.weight': 0.0074\n",
      "Gradient norm for 'f1_f2.weight': 0.0696\n",
      "Gradient norm for 'f2_f3.weight': 0.1496\n",
      "Gradient norm for 'f3_f4.weight': 0.5087\n",
      "Gradient norm for 'f4_o.weight': 3.4086\n",
      "saving max acc: 31.96\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [4/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.69765\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.67709\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.65753\n",
      "l1_score: 0\n",
      "Time elasped: 5.761755704879761\n",
      "Test Loss: 1.646505779027939\n",
      "Avg spk_count per neuron for all 10 time-steps 0.38471540808677673\n",
      "Avg spk per neuron per layer [2.009425, 1.482125, 1.4591375, 1.204759375]\n",
      "Test Accuracy of the model on the test samples: 37.120\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_3': 0.0000\n",
      "Gradient norm for 'tau_m_4': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0554\n",
      "Gradient norm for 'f0_f1.weight': 0.0042\n",
      "Gradient norm for 'f1_f2.weight': 0.0429\n",
      "Gradient norm for 'f2_f3.weight': 0.0873\n",
      "Gradient norm for 'f3_f4.weight': 0.3211\n",
      "Gradient norm for 'f4_o.weight': 2.1368\n",
      "saving max acc: 37.12\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [5/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.62856\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.60864\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.56244\n",
      "l1_score: 0\n",
      "Time elasped: 5.9884679317474365\n",
      "Test Loss: 1.6042781621217728\n",
      "Avg spk_count per neuron for all 10 time-steps 0.3725355267524719\n",
      "Avg spk per neuron per layer [1.97888125, 1.46493125, 1.3624375, 1.15431875]\n",
      "Test Accuracy of the model on the test samples: 39.040\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_3': 0.0000\n",
      "Gradient norm for 'tau_m_4': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0557\n",
      "Gradient norm for 'f0_f1.weight': 0.0060\n",
      "Gradient norm for 'f1_f2.weight': 0.0621\n",
      "Gradient norm for 'f2_f3.weight': 0.1271\n",
      "Gradient norm for 'f3_f4.weight': 0.4374\n",
      "Gradient norm for 'f4_o.weight': 3.1623\n",
      "saving max acc: 39.04\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [6/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.59988\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.64442\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.70246\n",
      "l1_score: 0\n",
      "Time elasped: 5.936195611953735\n",
      "Test Loss: 1.5844858080148696\n",
      "Avg spk_count per neuron for all 10 time-steps 0.38745078444480896\n",
      "Avg spk per neuron per layer [2.003834375, 1.52095, 1.433796875, 1.24063125]\n",
      "Test Accuracy of the model on the test samples: 40.520\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_3': 0.0000\n",
      "Gradient norm for 'tau_m_4': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0466\n",
      "Gradient norm for 'f0_f1.weight': 0.0115\n",
      "Gradient norm for 'f1_f2.weight': 0.1008\n",
      "Gradient norm for 'f2_f3.weight': 0.1862\n",
      "Gradient norm for 'f3_f4.weight': 0.4101\n",
      "Gradient norm for 'f4_o.weight': 2.7526\n",
      "saving max acc: 40.52\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [7/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.59931\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.56633\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.55968\n",
      "l1_score: 0\n",
      "Time elasped: 6.258516788482666\n",
      "Test Loss: 1.5517043620347977\n",
      "Avg spk_count per neuron for all 10 time-steps 0.38305604457855225\n",
      "Avg spk per neuron per layer [2.02519375, 1.4857625, 1.36600625, 1.251934375]\n",
      "Test Accuracy of the model on the test samples: 42.640\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_3': 0.0000\n",
      "Gradient norm for 'tau_m_4': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0544\n",
      "Gradient norm for 'f0_f1.weight': 0.0044\n",
      "Gradient norm for 'f1_f2.weight': 0.0420\n",
      "Gradient norm for 'f2_f3.weight': 0.0978\n",
      "Gradient norm for 'f3_f4.weight': 0.5215\n",
      "Gradient norm for 'f4_o.weight': 3.9598\n",
      "saving max acc: 42.64\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [8/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.52983\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.54146\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.53289\n",
      "l1_score: 0\n",
      "Time elasped: 8.161639928817749\n",
      "Test Loss: 1.5427056580781937\n",
      "Avg spk_count per neuron for all 10 time-steps 0.388479083776474\n",
      "Avg spk per neuron per layer [2.03596875, 1.522609375, 1.388815625, 1.268271875]\n",
      "Test Accuracy of the model on the test samples: 42.920\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_3': 0.0000\n",
      "Gradient norm for 'tau_m_4': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0471\n",
      "Gradient norm for 'f0_f1.weight': 0.0050\n",
      "Gradient norm for 'f1_f2.weight': 0.0462\n",
      "Gradient norm for 'f2_f3.weight': 0.1130\n",
      "Gradient norm for 'f3_f4.weight': 0.4563\n",
      "Gradient norm for 'f4_o.weight': 3.4754\n",
      "saving max acc: 42.92\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [9/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.43710\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.54349\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.54446\n",
      "l1_score: 0\n",
      "Time elasped: 8.269232511520386\n",
      "Test Loss: 1.5208365976810456\n",
      "Avg spk_count per neuron for all 10 time-steps 0.3839949071407318\n",
      "Avg spk per neuron per layer [2.007878125, 1.491646875, 1.353509375, 1.290884375]\n",
      "Test Accuracy of the model on the test samples: 43.420\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_3': 0.0000\n",
      "Gradient norm for 'tau_m_4': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0454\n",
      "Gradient norm for 'f0_f1.weight': 0.0036\n",
      "Gradient norm for 'f1_f2.weight': 0.0360\n",
      "Gradient norm for 'f2_f3.weight': 0.0902\n",
      "Gradient norm for 'f3_f4.weight': 0.4416\n",
      "Gradient norm for 'f4_o.weight': 2.7134\n",
      "saving max acc: 43.42\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [10/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.50018\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.49874\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.50509\n",
      "l1_score: 0\n",
      "Time elasped: 7.68349814414978\n",
      "Test Loss: 1.5029577225446702\n",
      "Avg spk_count per neuron for all 10 time-steps 0.39104530215263367\n",
      "Avg spk per neuron per layer [2.024240625, 1.506503125, 1.38614375, 1.3398375]\n",
      "Test Accuracy of the model on the test samples: 44.520\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_3': 0.0000\n",
      "Gradient norm for 'tau_m_4': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0256\n",
      "Gradient norm for 'f0_f1.weight': 0.0066\n",
      "Gradient norm for 'f1_f2.weight': 0.0425\n",
      "Gradient norm for 'f2_f3.weight': 0.0994\n",
      "Gradient norm for 'f3_f4.weight': 0.4144\n",
      "Gradient norm for 'f4_o.weight': 3.4872\n",
      "saving max acc: 44.52\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [11/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.45889\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.52023\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.53603\n",
      "l1_score: 0\n",
      "Time elasped: 8.91263484954834\n",
      "Test Loss: 1.5091936796903611\n",
      "Avg spk_count per neuron for all 10 time-steps 0.37689530849456787\n",
      "Avg spk per neuron per layer [2.012484375, 1.4405375, 1.301903125, 1.2754]\n",
      "Test Accuracy of the model on the test samples: 43.620\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_3': 0.0000\n",
      "Gradient norm for 'tau_m_4': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0115\n",
      "Gradient norm for 'f0_f1.weight': 0.0039\n",
      "Gradient norm for 'f1_f2.weight': 0.0266\n",
      "Gradient norm for 'f2_f3.weight': 0.0850\n",
      "Gradient norm for 'f3_f4.weight': 0.3278\n",
      "Gradient norm for 'f4_o.weight': 1.7465\n",
      "Epoch [12/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.51152\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.53534\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.51006\n",
      "l1_score: 0\n",
      "Time elasped: 8.464211702346802\n",
      "Test Loss: 1.4890279412269591\n",
      "Avg spk_count per neuron for all 10 time-steps 0.38024216890335083\n",
      "Avg spk per neuron per layer [2.03050625, 1.44614375, 1.32123125, 1.28599375]\n",
      "Test Accuracy of the model on the test samples: 44.200\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_3': 0.0000\n",
      "Gradient norm for 'tau_m_4': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0386\n",
      "Gradient norm for 'f0_f1.weight': 0.0083\n",
      "Gradient norm for 'f1_f2.weight': 0.0885\n",
      "Gradient norm for 'f2_f3.weight': 0.1557\n",
      "Gradient norm for 'f3_f4.weight': 0.4847\n",
      "Gradient norm for 'f4_o.weight': 3.4591\n",
      "Epoch [13/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.52182\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.52587\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.45069\n",
      "l1_score: 0\n",
      "Time elasped: 8.540653467178345\n",
      "Test Loss: 1.4709287017583847\n",
      "Avg spk_count per neuron for all 10 time-steps 0.38262850046157837\n",
      "Avg spk per neuron per layer [2.0314, 1.45724375, 1.331475, 1.3019375]\n",
      "Test Accuracy of the model on the test samples: 45.740\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_3': 0.0000\n",
      "Gradient norm for 'tau_m_4': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0123\n",
      "Gradient norm for 'f0_f1.weight': 0.0076\n",
      "Gradient norm for 'f1_f2.weight': 0.0455\n",
      "Gradient norm for 'f2_f3.weight': 0.1219\n",
      "Gradient norm for 'f3_f4.weight': 0.4752\n",
      "Gradient norm for 'f4_o.weight': 3.6911\n",
      "saving max acc: 45.74\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [14/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.49811\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.44988\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.37792\n",
      "l1_score: 0\n",
      "Time elasped: 8.941062688827515\n",
      "Test Loss: 1.4736565977334977\n",
      "Avg spk_count per neuron for all 10 time-steps 0.38206717371940613\n",
      "Avg spk per neuron per layer [2.01386875, 1.50424375, 1.323009375, 1.271953125]\n",
      "Test Accuracy of the model on the test samples: 46.200\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_3': 0.0000\n",
      "Gradient norm for 'tau_m_4': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0680\n",
      "Gradient norm for 'f0_f1.weight': 0.0072\n",
      "Gradient norm for 'f1_f2.weight': 0.0515\n",
      "Gradient norm for 'f2_f3.weight': 0.1199\n",
      "Gradient norm for 'f3_f4.weight': 0.4340\n",
      "Gradient norm for 'f4_o.weight': inf\n",
      "saving max acc: 46.2\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [15/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.44529\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.52946\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.38360\n",
      "l1_score: 0\n",
      "Time elasped: 8.866756916046143\n",
      "Test Loss: 1.467127725481987\n",
      "Avg spk_count per neuron for all 10 time-steps 0.3850207030773163\n",
      "Avg spk per neuron per layer [2.022878125, 1.514034375, 1.3119125, 1.31150625]\n",
      "Test Accuracy of the model on the test samples: 45.960\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_3': 0.0000\n",
      "Gradient norm for 'tau_m_4': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0229\n",
      "Gradient norm for 'f0_f1.weight': 0.0057\n",
      "Gradient norm for 'f1_f2.weight': 0.0591\n",
      "Gradient norm for 'f2_f3.weight': 0.1522\n",
      "Gradient norm for 'f3_f4.weight': 0.6417\n",
      "Gradient norm for 'f4_o.weight': 4.0850\n",
      "Epoch [16/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.45409\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.51107\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.49669\n",
      "l1_score: 0\n",
      "Time elasped: 8.020488500595093\n",
      "Test Loss: 1.46017844080925\n",
      "Avg spk_count per neuron for all 10 time-steps 0.3804718554019928\n",
      "Avg spk per neuron per layer [2.005415625, 1.449815625, 1.307975, 1.32434375]\n",
      "Test Accuracy of the model on the test samples: 46.700\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_3': 0.0000\n",
      "Gradient norm for 'tau_m_4': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0424\n",
      "Gradient norm for 'f0_f1.weight': 0.0047\n",
      "Gradient norm for 'f1_f2.weight': 0.0463\n",
      "Gradient norm for 'f2_f3.weight': 0.1146\n",
      "Gradient norm for 'f3_f4.weight': 0.4441\n",
      "Gradient norm for 'f4_o.weight': 3.0480\n",
      "saving max acc: 46.7\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [17/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.47202\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.44953\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.49292\n",
      "l1_score: 0\n",
      "Time elasped: 8.676722526550293\n",
      "Test Loss: 1.4672400295734405\n",
      "Avg spk_count per neuron for all 10 time-steps 0.3741847574710846\n",
      "Avg spk per neuron per layer [2.006828125, 1.447396875, 1.234175, 1.29855625]\n",
      "Test Accuracy of the model on the test samples: 45.080\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_3': 0.0000\n",
      "Gradient norm for 'tau_m_4': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0106\n",
      "Gradient norm for 'f0_f1.weight': 0.0055\n",
      "Gradient norm for 'f1_f2.weight': 0.0510\n",
      "Gradient norm for 'f2_f3.weight': 0.1057\n",
      "Gradient norm for 'f3_f4.weight': 0.4218\n",
      "Gradient norm for 'f4_o.weight': 3.0412\n",
      "Epoch [18/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.38728\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.32949\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.56168\n",
      "l1_score: 0\n",
      "Time elasped: 8.49047064781189\n",
      "Test Loss: 1.468403360247612\n",
      "Avg spk_count per neuron for all 10 time-steps 0.37582850456237793\n",
      "Avg spk per neuron per layer [1.99056875, 1.485071875, 1.251125, 1.286490625]\n",
      "Test Accuracy of the model on the test samples: 45.300\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_3': 0.0000\n",
      "Gradient norm for 'tau_m_4': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0225\n",
      "Gradient norm for 'f0_f1.weight': 0.0067\n",
      "Gradient norm for 'f1_f2.weight': 0.0683\n",
      "Gradient norm for 'f2_f3.weight': 0.1121\n",
      "Gradient norm for 'f3_f4.weight': 0.4929\n",
      "Gradient norm for 'f4_o.weight': 3.5667\n",
      "Epoch [19/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.45248\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.37188\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.41061\n",
      "l1_score: 0\n",
      "Time elasped: 8.989895343780518\n",
      "Test Loss: 1.4308469206094743\n",
      "Avg spk_count per neuron for all 10 time-steps 0.38619881868362427\n",
      "Avg spk per neuron per layer [2.026584375, 1.54503125, 1.28861875, 1.318946875]\n",
      "Test Accuracy of the model on the test samples: 49.300\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_3': 0.0000\n",
      "Gradient norm for 'tau_m_4': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0234\n",
      "Gradient norm for 'f0_f1.weight': 0.0082\n",
      "Gradient norm for 'f1_f2.weight': 0.0842\n",
      "Gradient norm for 'f2_f3.weight': 0.1356\n",
      "Gradient norm for 'f3_f4.weight': 0.5301\n",
      "Gradient norm for 'f4_o.weight': 2.9373\n",
      "saving max acc: 49.3\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [20/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.33430\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.33214\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.33460\n",
      "l1_score: 0\n",
      "Time elasped: 7.721900939941406\n",
      "Test Loss: 1.4542532980442047\n",
      "Avg spk_count per neuron for all 10 time-steps 0.38142791390419006\n",
      "Avg spk per neuron per layer [2.0251625, 1.51625625, 1.286490625, 1.2749375]\n",
      "Test Accuracy of the model on the test samples: 47.760\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_3': 0.0000\n",
      "Gradient norm for 'tau_m_4': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0207\n",
      "Gradient norm for 'f0_f1.weight': 0.0067\n",
      "Gradient norm for 'f1_f2.weight': 0.0534\n",
      "Gradient norm for 'f2_f3.weight': 0.1386\n",
      "Gradient norm for 'f3_f4.weight': 0.4970\n",
      "Gradient norm for 'f4_o.weight': 3.5357\n",
      "Epoch [21/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.46210\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.48599\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.40979\n",
      "l1_score: 0\n",
      "Time elasped: 7.5322887897491455\n",
      "Test Loss: 1.4290685325860977\n",
      "Avg spk_count per neuron for all 10 time-steps 0.3829376995563507\n",
      "Avg spk per neuron per layer [1.9995, 1.51789375, 1.2810125, 1.328596875]\n",
      "Test Accuracy of the model on the test samples: 48.600\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_3': 0.0000\n",
      "Gradient norm for 'tau_m_4': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0140\n",
      "Gradient norm for 'f0_f1.weight': 0.0066\n",
      "Gradient norm for 'f1_f2.weight': 0.0430\n",
      "Gradient norm for 'f2_f3.weight': 0.1082\n",
      "Gradient norm for 'f3_f4.weight': 0.3669\n",
      "Gradient norm for 'f4_o.weight': 3.0186\n",
      "Epoch [22/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.48708\n",
      "l1_score: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m snn\u001b[38;5;241m.\u001b[39mmodel_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdvs5_seq\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msequence_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdelay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m snn\u001b[38;5;241m.\u001b[39mmodel_name\n\u001b[0;32m     26\u001b[0m snn\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 27\u001b[0m train(snn, train_loader, test_loader, lr, num_epochs, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, \n\u001b[0;32m     28\u001b[0m     test_behavior\u001b[38;5;241m=\u001b[39mtb_save_max_last_acc, ckpt_dir\u001b[38;5;241m=\u001b[39mckpt_dir, scheduler\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m0.95\u001b[39m), test_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[INFO] TIEMPO: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mtaimu1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Python\\SNNdelays\\snn_delays\\utils\\train_utils.py:83\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(snn, train_loader, test_loader, learning_rate, num_epochs, spk_reg, l1_reg, dropout, lr_tau, scheduler, ckpt_dir, test_behavior, test_every, delay_pruning, weight_pruning, lsm, random_delay_pruning, weight_quantization, k, depth, freeze_taus, verbose)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m], learning_rates \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, num_epochs,\n\u001b[0;32m     79\u001b[0m                                                  current_lr, current_lr_tau), flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m k\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 83\u001b[0m     snn\u001b[38;5;241m.\u001b[39mtrain_step(train_loader,\n\u001b[0;32m     84\u001b[0m                 optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m     85\u001b[0m                 scheduler \u001b[38;5;241m=\u001b[39m scheduler,\n\u001b[0;32m     86\u001b[0m                 spk_reg\u001b[38;5;241m=\u001b[39mspk_reg,\n\u001b[0;32m     87\u001b[0m                 l1_reg\u001b[38;5;241m=\u001b[39ml1_reg,\n\u001b[0;32m     88\u001b[0m                 dropout\u001b[38;5;241m=\u001b[39mdropout,\n\u001b[0;32m     89\u001b[0m                 verbose\u001b[38;5;241m=\u001b[39mverbose)        \n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     snn\u001b[38;5;241m.\u001b[39mtrain_step_tr(train_loader\u001b[38;5;241m=\u001b[39mtrain_loader, optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m     92\u001b[0m                     criterion\u001b[38;5;241m=\u001b[39msnn\u001b[38;5;241m.\u001b[39mcriterion, spk_reg\u001b[38;5;241m=\u001b[39mspk_reg,\n\u001b[0;32m     93\u001b[0m                     depth\u001b[38;5;241m=\u001b[39mdepth, k\u001b[38;5;241m=\u001b[39mk, last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Python\\SNNdelays\\snn_delays\\snn.py:187\u001b[0m, in \u001b[0;36mTraining.train_step\u001b[1;34m(self, train_loader, optimizer, scheduler, spk_reg, l1_reg, dropout, verbose)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;66;03m# # Dropout [REVIEW]\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;66;03m# images = self.dropout(images.float())\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m amp\u001b[38;5;241m.\u001b[39mautocast(enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_amp):\n\u001b[0;32m    185\u001b[0m \n\u001b[0;32m    186\u001b[0m     \u001b[38;5;66;03m# Propagate data\u001b[39;00m\n\u001b[1;32m--> 187\u001b[0m     outputs, reference \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(images, labels)\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;66;03m#total spike count (for spike regularization)\u001b[39;00m\n\u001b[0;32m    190\u001b[0m     spk_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh_sum_spike \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_neurons_list) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwin)\n",
      "File \u001b[1;32m~\\Python\\SNNdelays\\snn_delays\\snn.py:123\u001b[0m, in \u001b[0;36mTraining.propagate\u001b[1;34m(self, images, labels)\u001b[0m\n\u001b[0;32m    119\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    121\u001b[0m l_f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn\n\u001b[1;32m--> 123\u001b[0m all_o_mems, all_o_spikes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(images)\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m l_f \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmem_last\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    126\u001b[0m     _, labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(labels\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Python\\SNNdelays\\snn_delays\\snn.py:1001\u001b[0m, in \u001b[0;36mSNN.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    997\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    998\u001b[0m     r_ext_spk \u001b[38;5;241m=\u001b[39m spikes[layer]\n\u001b[0;32m   1000\u001b[0m mems[layer], spikes[layer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_mem_fn(\n\u001b[1;32m-> 1001\u001b[0m     prev_spikes\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), spikes[layer], mems[layer], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthresh, r_ext_spk)\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelay_type:\n\u001b[0;32m   1004\u001b[0m     extended_spikes[layer][:, step\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_d,\n\u001b[0;32m   1005\u001b[0m                         :] \u001b[38;5;241m=\u001b[39m spikes[layer]\u001b[38;5;241m.\u001b[39mclone()  \u001b[38;5;66;03m# possibly detach()\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from snn_delays.utils.train_utils import train\n",
    "from snn_delays.utils.test_behavior import tb_save_max_last_acc\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "taimu1 = time.time()\n",
    "\n",
    "tau_m = 'normal'\n",
    "#delay = (48*2,16*2)\n",
    "#delay = (96,32)\n",
    "delay = None\n",
    "#delay = (45, 15)\n",
    "ckpt_dir = 'exp21_STMNIST_memory' \n",
    "\n",
    "snn = SNN(dataset_dict=dataset_dict, structure=(64, 4), connection_type='f',\n",
    "    delay=delay, delay_type='h', tau_m = tau_m,\n",
    "    win=total_time*sequence_length, loss_fn='mem_sum', batch_size=batch_size, device=device,\n",
    "    debug=False)\n",
    "\n",
    "snn.set_network()\n",
    "\n",
    "snn.model_name = f'dvs5_seq{sequence_length}_{delay}'+ snn.model_name\n",
    "\n",
    "snn.to(device)\n",
    "train(snn, train_loader, test_loader, lr, num_epochs, dropout=0.0, \n",
    "    test_behavior=tb_save_max_last_acc, ckpt_dir=ckpt_dir, scheduler=(100, 0.95), test_every=1)\n",
    "\n",
    "print(f'[INFO] TIEMPO: {time.time() - taimu1}', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delays (10,1) 77%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Delays: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "\n",
      "[INFO] Delays i: tensor([0])\n",
      "\n",
      "[INFO] Delays h: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "\n",
      "[INFO] Delays o: tensor([0])\n",
      "0.0001\n",
      "Delta t: 1e-05 ms\n",
      "mean of normal: 14.508657488628742\n",
      "training dvs5_seq10_(10, 1)memorytask10_l2_10d1.t7 for 100 epochs...\n",
      "Epoch [1/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.10740\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.98572\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.85196\n",
      "l1_score: 0\n",
      "Time elasped: 3.4806418418884277\n",
      "Test Loss: 1.8435319036245346\n",
      "Avg spk_count per neuron for all 10 time-steps 1.1929515600204468\n",
      "Avg spk per neuron per layer [2.602034375, 2.169771875]\n",
      "Test Accuracy of the model on the test samples: 29.940\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0307\n",
      "Gradient norm for 'f0_f1.weight': 0.0493\n",
      "Gradient norm for 'f1_f2.weight': 0.7605\n",
      "Gradient norm for 'f2_o.weight': 2.1382\n",
      "saving max acc: 29.94\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [2/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.80011\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.74583\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.54683\n",
      "l1_score: 0\n",
      "Time elasped: 3.3092949390411377\n",
      "Test Loss: 1.6071477591991425\n",
      "Avg spk_count per neuron for all 10 time-steps 1.1881171464920044\n",
      "Avg spk per neuron per layer [2.521540625, 2.230928125]\n",
      "Test Accuracy of the model on the test samples: 38.980\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0327\n",
      "Gradient norm for 'f0_f1.weight': 0.0657\n",
      "Gradient norm for 'f1_f2.weight': 1.2050\n",
      "Gradient norm for 'f2_o.weight': inf\n",
      "saving max acc: 38.98\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [3/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.45526\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.42912\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.39881\n",
      "l1_score: 0\n",
      "Time elasped: 4.250887155532837\n",
      "Test Loss: 1.3936084508895874\n",
      "Avg spk_count per neuron for all 10 time-steps 1.2334327697753906\n",
      "Avg spk per neuron per layer [2.4880625, 2.44566875]\n",
      "Test Accuracy of the model on the test samples: 50.500\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0113\n",
      "Gradient norm for 'f0_f1.weight': 0.1785\n",
      "Gradient norm for 'f1_f2.weight': 1.9448\n",
      "Gradient norm for 'f2_o.weight': 8.3924\n",
      "saving max acc: 50.5\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [4/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.36936\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.23308\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.27333\n",
      "l1_score: 0\n",
      "Time elasped: 4.317728519439697\n",
      "Test Loss: 1.2312060981988906\n",
      "Avg spk_count per neuron for all 10 time-steps 1.2426828145980835\n",
      "Avg spk per neuron per layer [2.456071875, 2.514659375]\n",
      "Test Accuracy of the model on the test samples: 60.760\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0123\n",
      "Gradient norm for 'f0_f1.weight': 0.0493\n",
      "Gradient norm for 'f1_f2.weight': 1.2833\n",
      "Gradient norm for 'f2_o.weight': 7.6829\n",
      "saving max acc: 60.76\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [5/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.26165\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.16815\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.11975\n",
      "l1_score: 0\n",
      "Time elasped: 4.0123748779296875\n",
      "Test Loss: 1.1901712983846664\n",
      "Avg spk_count per neuron for all 10 time-steps 1.2583163976669312\n",
      "Avg spk per neuron per layer [2.486684375, 2.54658125]\n",
      "Test Accuracy of the model on the test samples: 59.140\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0181\n",
      "Gradient norm for 'f0_f1.weight': 0.0683\n",
      "Gradient norm for 'f1_f2.weight': 1.4787\n",
      "Gradient norm for 'f2_o.weight': 7.8069\n",
      "Epoch [6/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.18359\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.12829\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.06408\n",
      "l1_score: 0\n",
      "Time elasped: 3.990658760070801\n",
      "Test Loss: 1.109934276342392\n",
      "Avg spk_count per neuron for all 10 time-steps 1.259865641593933\n",
      "Avg spk per neuron per layer [2.47905625, 2.56040625]\n",
      "Test Accuracy of the model on the test samples: 64.840\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0030\n",
      "Gradient norm for 'f0_f1.weight': 0.1187\n",
      "Gradient norm for 'f1_f2.weight': 1.2537\n",
      "Gradient norm for 'f2_o.weight': 7.2330\n",
      "saving max acc: 64.84\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [7/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.12459\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.09809\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 0.98078\n",
      "l1_score: 0\n",
      "Time elasped: 4.016745328903198\n",
      "Test Loss: 1.0224420964717864\n",
      "Avg spk_count per neuron for all 10 time-steps 1.2701780796051025\n",
      "Avg spk per neuron per layer [2.480665625, 2.600046875]\n",
      "Test Accuracy of the model on the test samples: 70.560\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0105\n",
      "Gradient norm for 'f0_f1.weight': 0.1802\n",
      "Gradient norm for 'f1_f2.weight': 2.2025\n",
      "Gradient norm for 'f2_o.weight': inf\n",
      "saving max acc: 70.56\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [8/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 0.96895\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.05134\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 0.91777\n",
      "l1_score: 0\n",
      "Time elasped: 4.127796649932861\n",
      "Test Loss: 1.0058135375380517\n",
      "Avg spk_count per neuron for all 10 time-steps 1.2798304557800293\n",
      "Avg spk per neuron per layer [2.485303125, 2.63401875]\n",
      "Test Accuracy of the model on the test samples: 68.940\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0020\n",
      "Gradient norm for 'f0_f1.weight': 0.1153\n",
      "Gradient norm for 'f1_f2.weight': 1.4789\n",
      "Gradient norm for 'f2_o.weight': 8.4325\n",
      "Epoch [9/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.03234\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.04175\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 0.98576\n",
      "l1_score: 0\n",
      "Time elasped: 4.016093015670776\n",
      "Test Loss: 0.9540448218584061\n",
      "Avg spk_count per neuron for all 10 time-steps 1.2897812128067017\n",
      "Avg spk per neuron per layer [2.510078125, 2.649046875]\n",
      "Test Accuracy of the model on the test samples: 72.360\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0027\n",
      "Gradient norm for 'f0_f1.weight': 0.1734\n",
      "Gradient norm for 'f1_f2.weight': 1.2017\n",
      "Gradient norm for 'f2_o.weight': 3.4952\n",
      "saving max acc: 72.36\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [10/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 0.95059\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 0.91842\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 0.95529\n",
      "l1_score: 0\n",
      "Time elasped: 4.053719758987427\n",
      "Test Loss: 0.9869992315769196\n",
      "Avg spk_count per neuron for all 10 time-steps 1.2770577669143677\n",
      "Avg spk per neuron per layer [2.48465, 2.62358125]\n",
      "Test Accuracy of the model on the test samples: 68.980\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0024\n",
      "Gradient norm for 'f0_f1.weight': 0.1436\n",
      "Gradient norm for 'f1_f2.weight': 1.8385\n",
      "Gradient norm for 'f2_o.weight': 9.4084\n",
      "Epoch [11/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 0.95805\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 0.87131\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 0.88952\n",
      "l1_score: 0\n",
      "Time elasped: 4.056094646453857\n",
      "Test Loss: 0.8892860904335975\n",
      "Avg spk_count per neuron for all 10 time-steps 1.2819937467575073\n",
      "Avg spk per neuron per layer [2.486284375, 2.641690625]\n",
      "Test Accuracy of the model on the test samples: 75.500\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0049\n",
      "Gradient norm for 'f0_f1.weight': 0.1504\n",
      "Gradient norm for 'f1_f2.weight': 1.9109\n",
      "Gradient norm for 'f2_o.weight': 6.5665\n",
      "saving max acc: 75.5\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [12/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 0.91731\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 0.85471\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 0.94426\n",
      "l1_score: 0\n",
      "Time elasped: 4.172069787979126\n",
      "Test Loss: 0.9071733862161636\n",
      "Avg spk_count per neuron for all 10 time-steps 1.3009397983551025\n",
      "Avg spk per neuron per layer [2.498690625, 2.70506875]\n",
      "Test Accuracy of the model on the test samples: 73.140\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0034\n",
      "Gradient norm for 'f0_f1.weight': 0.1249\n",
      "Gradient norm for 'f1_f2.weight': 1.5577\n",
      "Gradient norm for 'f2_o.weight': 5.4592\n",
      "Epoch [13/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 0.91015\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 0.83030\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 0.85872\n",
      "l1_score: 0\n",
      "Time elasped: 4.0566017627716064\n",
      "Test Loss: 0.8875736519694328\n",
      "Avg spk_count per neuron for all 10 time-steps 1.2904444932937622\n",
      "Avg spk per neuron per layer [2.4896125, 2.672165625]\n",
      "Test Accuracy of the model on the test samples: 75.260\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0017\n",
      "Gradient norm for 'f0_f1.weight': 0.0687\n",
      "Gradient norm for 'f1_f2.weight': 0.9783\n",
      "Gradient norm for 'f2_o.weight': 3.6040\n",
      "Epoch [14/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 0.88664\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 0.88648\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 0.88091\n",
      "l1_score: 0\n",
      "Time elasped: 4.0923261642456055\n",
      "Test Loss: 0.905200007557869\n",
      "Avg spk_count per neuron for all 10 time-steps 1.282557725906372\n",
      "Avg spk per neuron per layer [2.477625, 2.65260625]\n",
      "Test Accuracy of the model on the test samples: 73.060\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0019\n",
      "Gradient norm for 'f0_f1.weight': 0.0542\n",
      "Gradient norm for 'f1_f2.weight': 0.7566\n",
      "Gradient norm for 'f2_o.weight': 3.1189\n",
      "Epoch [15/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 0.81425\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 0.92526\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 0.87836\n",
      "l1_score: 0\n",
      "Time elasped: 4.037229776382446\n",
      "Test Loss: 0.9017367720603943\n",
      "Avg spk_count per neuron for all 10 time-steps 1.2817631959915161\n",
      "Avg spk per neuron per layer [2.463084375, 2.66396875]\n",
      "Test Accuracy of the model on the test samples: 72.540\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0023\n",
      "Gradient norm for 'f0_f1.weight': 0.0867\n",
      "Gradient norm for 'f1_f2.weight': 1.0065\n",
      "Gradient norm for 'f2_o.weight': 5.7354\n",
      "Epoch [16/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 0.87717\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 0.92311\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 0.73539\n",
      "l1_score: 0\n",
      "Time elasped: 4.168735027313232\n",
      "Test Loss: 0.8405736267566681\n",
      "Avg spk_count per neuron for all 10 time-steps 1.279263973236084\n",
      "Avg spk per neuron per layer [2.47646875, 2.6405875]\n",
      "Test Accuracy of the model on the test samples: 76.120\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0044\n",
      "Gradient norm for 'f0_f1.weight': 0.0952\n",
      "Gradient norm for 'f1_f2.weight': 0.9552\n",
      "Gradient norm for 'f2_o.weight': 2.8642\n",
      "saving max acc: 76.12\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [17/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 0.81530\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 0.81597\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 0.87221\n",
      "l1_score: 0\n",
      "Time elasped: 4.27100682258606\n",
      "Test Loss: 0.842218229174614\n",
      "Avg spk_count per neuron for all 10 time-steps 1.2821944952011108\n",
      "Avg spk per neuron per layer [2.4696125, 2.659165625]\n",
      "Test Accuracy of the model on the test samples: 75.760\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0054\n",
      "Gradient norm for 'f0_f1.weight': 0.1762\n",
      "Gradient norm for 'f1_f2.weight': 1.7674\n",
      "Gradient norm for 'f2_o.weight': 8.3716\n",
      "Epoch [18/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 0.84444\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 0.78369\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 0.86049\n",
      "l1_score: 0\n",
      "Time elasped: 4.199903726577759\n",
      "Test Loss: 0.8313453689217567\n",
      "Avg spk_count per neuron for all 10 time-steps 1.2897086143493652\n",
      "Avg spk per neuron per layer [2.473459375, 2.685375]\n",
      "Test Accuracy of the model on the test samples: 76.520\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0038\n",
      "Gradient norm for 'f0_f1.weight': 0.0734\n",
      "Gradient norm for 'f1_f2.weight': 1.1572\n",
      "Gradient norm for 'f2_o.weight': 5.4687\n",
      "saving max acc: 76.52\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [19/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 0.82164\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 0.77242\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 0.86754\n",
      "l1_score: 0\n",
      "Time elasped: 3.9652132987976074\n",
      "Test Loss: 0.8359095826745033\n",
      "Avg spk_count per neuron for all 10 time-steps 1.2747187614440918\n",
      "Avg spk per neuron per layer [2.471525, 2.62735]\n",
      "Test Accuracy of the model on the test samples: 75.320\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0022\n",
      "Gradient norm for 'f0_f1.weight': 0.0597\n",
      "Gradient norm for 'f1_f2.weight': 0.8559\n",
      "Gradient norm for 'f2_o.weight': 3.1316\n",
      "Epoch [20/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 0.80004\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 0.77667\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 0.70185\n",
      "l1_score: 0\n",
      "Time elasped: 4.2252678871154785\n",
      "Test Loss: 0.8056290462613106\n",
      "Avg spk_count per neuron for all 10 time-steps 1.280689001083374\n",
      "Avg spk per neuron per layer [2.4825875, 2.64016875]\n",
      "Test Accuracy of the model on the test samples: 77.240\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0035\n",
      "Gradient norm for 'f0_f1.weight': 0.0584\n",
      "Gradient norm for 'f1_f2.weight': 0.7446\n",
      "Gradient norm for 'f2_o.weight': 3.5627\n",
      "saving max acc: 77.24\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [21/100], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 0.77839\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 0.76831\n",
      "l1_score: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m snn\u001b[38;5;241m.\u001b[39mmodel_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdvs5_seq\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msequence_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdelay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m snn\u001b[38;5;241m.\u001b[39mmodel_name\n\u001b[0;32m     26\u001b[0m snn\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 27\u001b[0m train(snn, train_loader, test_loader, lr, num_epochs, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, \n\u001b[0;32m     28\u001b[0m     test_behavior\u001b[38;5;241m=\u001b[39mtb_save_max_last_acc, ckpt_dir\u001b[38;5;241m=\u001b[39mckpt_dir, scheduler\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m0.95\u001b[39m), test_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[INFO] TIEMPO: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mtaimu1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Python\\SNNdelays\\snn_delays\\utils\\train_utils.py:83\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(snn, train_loader, test_loader, learning_rate, num_epochs, spk_reg, l1_reg, dropout, lr_tau, scheduler, ckpt_dir, test_behavior, test_every, delay_pruning, weight_pruning, lsm, random_delay_pruning, weight_quantization, k, depth, freeze_taus, verbose)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m], learning_rates \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, num_epochs,\n\u001b[0;32m     79\u001b[0m                                                  current_lr, current_lr_tau), flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m k\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 83\u001b[0m     snn\u001b[38;5;241m.\u001b[39mtrain_step(train_loader,\n\u001b[0;32m     84\u001b[0m                 optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m     85\u001b[0m                 scheduler \u001b[38;5;241m=\u001b[39m scheduler,\n\u001b[0;32m     86\u001b[0m                 spk_reg\u001b[38;5;241m=\u001b[39mspk_reg,\n\u001b[0;32m     87\u001b[0m                 l1_reg\u001b[38;5;241m=\u001b[39ml1_reg,\n\u001b[0;32m     88\u001b[0m                 dropout\u001b[38;5;241m=\u001b[39mdropout,\n\u001b[0;32m     89\u001b[0m                 verbose\u001b[38;5;241m=\u001b[39mverbose)        \n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     snn\u001b[38;5;241m.\u001b[39mtrain_step_tr(train_loader\u001b[38;5;241m=\u001b[39mtrain_loader, optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m     92\u001b[0m                     criterion\u001b[38;5;241m=\u001b[39msnn\u001b[38;5;241m.\u001b[39mcriterion, spk_reg\u001b[38;5;241m=\u001b[39mspk_reg,\n\u001b[0;32m     93\u001b[0m                     depth\u001b[38;5;241m=\u001b[39mdepth, k\u001b[38;5;241m=\u001b[39mk, last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Python\\SNNdelays\\snn_delays\\snn.py:187\u001b[0m, in \u001b[0;36mTraining.train_step\u001b[1;34m(self, train_loader, optimizer, scheduler, spk_reg, l1_reg, dropout, verbose)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;66;03m# # Dropout [REVIEW]\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;66;03m# images = self.dropout(images.float())\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m amp\u001b[38;5;241m.\u001b[39mautocast(enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_amp):\n\u001b[0;32m    185\u001b[0m \n\u001b[0;32m    186\u001b[0m     \u001b[38;5;66;03m# Propagate data\u001b[39;00m\n\u001b[1;32m--> 187\u001b[0m     outputs, reference \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(images, labels)\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;66;03m#total spike count (for spike regularization)\u001b[39;00m\n\u001b[0;32m    190\u001b[0m     spk_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh_sum_spike \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_neurons_list) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwin)\n",
      "File \u001b[1;32m~\\Python\\SNNdelays\\snn_delays\\snn.py:123\u001b[0m, in \u001b[0;36mTraining.propagate\u001b[1;34m(self, images, labels)\u001b[0m\n\u001b[0;32m    119\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    121\u001b[0m l_f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn\n\u001b[1;32m--> 123\u001b[0m all_o_mems, all_o_spikes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(images)\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m l_f \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmem_last\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    126\u001b[0m     _, labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(labels\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Python\\SNNdelays\\snn_delays\\snn.py:985\u001b[0m, in \u001b[0;36mSNN.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    982\u001b[0m     prev_spikes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf0_f1(delayed_x\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[0;32m    983\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# input layer is propagated (with delays)\u001b[39;00m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 985\u001b[0m     prev_spikes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf0_f1(\u001b[38;5;28minput\u001b[39m[:, step, :]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtau_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from snn_delays.utils.train_utils import train\n",
    "from snn_delays.utils.test_behavior import tb_save_max_last_acc\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "taimu1 = time.time()\n",
    "\n",
    "tau_m = 'normal'\n",
    "#delay = (48*2,16*2)\n",
    "#delay = (96,32)\n",
    "#delay = None\n",
    "delay = (10, 1)\n",
    "ckpt_dir = 'exp21_STMNIST_memory' \n",
    "\n",
    "snn = SNN(dataset_dict=dataset_dict, structure=(64, 2), connection_type='f',\n",
    "    delay=delay, delay_type='h', tau_m = tau_m,\n",
    "    win=total_time*sequence_length, loss_fn='mem_sum', batch_size=batch_size, device=device,\n",
    "    debug=False)\n",
    "\n",
    "snn.set_network()\n",
    "\n",
    "snn.model_name = f'dvs5_seq{sequence_length}_{delay}'+ snn.model_name\n",
    "\n",
    "snn.to(device)\n",
    "train(snn, train_loader, test_loader, lr, num_epochs, dropout=0.0, \n",
    "    test_behavior=tb_save_max_last_acc, ckpt_dir=ckpt_dir, scheduler=(100, 0.95), test_every=1)\n",
    "\n",
    "print(f'[INFO] TIEMPO: {time.time() - taimu1}', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent: 78%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Delays: tensor([0])\n",
      "\n",
      "[INFO] Delays i: tensor([0])\n",
      "\n",
      "[INFO] Delays h: tensor([0])\n",
      "\n",
      "[INFO] Delays o: tensor([0])\n",
      "0.0001\n",
      "Delta t: 1e-05 ms\n",
      "mean of normal: 14.508657488628742\n",
      "training dvs5_seq10_Nonememorytask10_l2_1d1.t7 for 20 epochs...\n",
      "Epoch [1/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.13248\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.01584\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.93346\n",
      "l1_score: 0\n",
      "Time elasped: 4.2424328327178955\n",
      "Test Loss: 1.9097917675971985\n",
      "Avg spk_count per neuron for all 10 time-steps 1.0870429277420044\n",
      "Avg spk per neuron per layer [2.345515625, 2.00265625]\n",
      "Test Accuracy of the model on the test samples: 27.460\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0399\n",
      "Gradient norm for 'f0_f1.weight': 0.0464\n",
      "Gradient norm for 'f1_f1.weight': 0.0593\n",
      "Gradient norm for 'f1_f2.weight': 0.4348\n",
      "Gradient norm for 'f2_f2.weight': 0.3089\n",
      "Gradient norm for 'f2_o.weight': 1.9470\n",
      "saving max acc: 27.46\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [2/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.76076\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.71251\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.53552\n",
      "l1_score: 0\n",
      "Time elasped: 4.254814863204956\n",
      "Test Loss: 1.561393317580223\n",
      "Avg spk_count per neuron for all 10 time-steps 1.292982816696167\n",
      "Avg spk per neuron per layer [2.56431875, 2.6076125]\n",
      "Test Accuracy of the model on the test samples: 41.640\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.1689\n",
      "Gradient norm for 'f0_f1.weight': 0.0819\n",
      "Gradient norm for 'f1_f1.weight': 0.0955\n",
      "Gradient norm for 'f1_f2.weight': 0.7311\n",
      "Gradient norm for 'f2_f2.weight': 0.5804\n",
      "Gradient norm for 'f2_o.weight': 5.1181\n",
      "saving max acc: 41.64\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [3/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.52564\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.45579\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.37729\n",
      "l1_score: 0\n",
      "Time elasped: 4.864647626876831\n",
      "Test Loss: 1.3857007801532746\n",
      "Avg spk_count per neuron for all 10 time-steps 1.3482749462127686\n",
      "Avg spk per neuron per layer [2.700028125, 2.693071875]\n",
      "Test Accuracy of the model on the test samples: 50.920\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0905\n",
      "Gradient norm for 'f0_f1.weight': 0.0754\n",
      "Gradient norm for 'f1_f1.weight': 0.1002\n",
      "Gradient norm for 'f1_f2.weight': 0.6227\n",
      "Gradient norm for 'f2_f2.weight': 0.5467\n",
      "Gradient norm for 'f2_o.weight': 3.9088\n",
      "saving max acc: 50.92\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [4/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.19925\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.27902\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.30962\n",
      "l1_score: 0\n",
      "Time elasped: 5.940248489379883\n",
      "Test Loss: 1.2629063934087754\n",
      "Avg spk_count per neuron for all 10 time-steps 1.4179929494857788\n",
      "Avg spk per neuron per layer [2.673215625, 2.99875625]\n",
      "Test Accuracy of the model on the test samples: 56.020\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0810\n",
      "Gradient norm for 'f0_f1.weight': 0.0874\n",
      "Gradient norm for 'f1_f1.weight': 0.1163\n",
      "Gradient norm for 'f1_f2.weight': 0.7250\n",
      "Gradient norm for 'f2_f2.weight': 0.6352\n",
      "Gradient norm for 'f2_o.weight': 5.5592\n",
      "saving max acc: 56.02\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [5/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.13135\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.21342\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.19113\n",
      "l1_score: 0\n",
      "Time elasped: 7.145057439804077\n",
      "Test Loss: 1.1321053892374038\n",
      "Avg spk_count per neuron for all 10 time-steps 1.4398624897003174\n",
      "Avg spk per neuron per layer [2.734428125, 3.025021875]\n",
      "Test Accuracy of the model on the test samples: 64.160\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.1640\n",
      "Gradient norm for 'f0_f1.weight': 0.0627\n",
      "Gradient norm for 'f1_f1.weight': 0.0833\n",
      "Gradient norm for 'f1_f2.weight': 1.0137\n",
      "Gradient norm for 'f2_f2.weight': 0.9239\n",
      "Gradient norm for 'f2_o.weight': inf\n",
      "saving max acc: 64.16\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [6/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.10659\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.09736\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.05015\n",
      "l1_score: 0\n",
      "Time elasped: 5.488908052444458\n",
      "Test Loss: 1.0722602248191833\n",
      "Avg spk_count per neuron for all 10 time-steps 1.4710100889205933\n",
      "Avg spk per neuron per layer [2.8120875, 3.071953125]\n",
      "Test Accuracy of the model on the test samples: 66.680\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0502\n",
      "Gradient norm for 'f0_f1.weight': 0.1028\n",
      "Gradient norm for 'f1_f1.weight': 0.1419\n",
      "Gradient norm for 'f1_f2.weight': 0.7967\n",
      "Gradient norm for 'f2_f2.weight': 0.7400\n",
      "Gradient norm for 'f2_o.weight': 4.7323\n",
      "saving max acc: 66.68\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [7/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.14038\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.05708\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.08430\n",
      "l1_score: 0\n",
      "Time elasped: 5.652233362197876\n",
      "Test Loss: 1.0260389357805253\n",
      "Avg spk_count per neuron for all 10 time-steps 1.4528640508651733\n",
      "Avg spk per neuron per layer [2.748603125, 3.062853125]\n",
      "Test Accuracy of the model on the test samples: 67.820\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.1170\n",
      "Gradient norm for 'f0_f1.weight': 0.2101\n",
      "Gradient norm for 'f1_f1.weight': 0.2962\n",
      "Gradient norm for 'f1_f2.weight': 1.6417\n",
      "Gradient norm for 'f2_f2.weight': 1.5263\n",
      "Gradient norm for 'f2_o.weight': 10.5117\n",
      "saving max acc: 67.82\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [8/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 0.96246\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.11131\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.03425\n",
      "l1_score: 0\n",
      "Time elasped: 6.099179744720459\n",
      "Test Loss: 0.993543517589569\n",
      "Avg spk_count per neuron for all 10 time-steps 1.4774913787841797\n",
      "Avg spk per neuron per layer [2.738615625, 3.17135]\n",
      "Test Accuracy of the model on the test samples: 68.740\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0876\n",
      "Gradient norm for 'f0_f1.weight': 0.0946\n",
      "Gradient norm for 'f1_f1.weight': 0.1347\n",
      "Gradient norm for 'f1_f2.weight': 0.7328\n",
      "Gradient norm for 'f2_f2.weight': 0.7090\n",
      "Gradient norm for 'f2_o.weight': 5.5764\n",
      "saving max acc: 68.74\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [9/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.03678\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 0.91487\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 0.89959\n",
      "l1_score: 0\n",
      "Time elasped: 6.119550466537476\n",
      "Test Loss: 0.9418531402945518\n",
      "Avg spk_count per neuron for all 10 time-steps 1.4982726573944092\n",
      "Avg spk per neuron per layer [2.756653125, 3.2364375]\n",
      "Test Accuracy of the model on the test samples: 71.160\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0907\n",
      "Gradient norm for 'f0_f1.weight': 0.0748\n",
      "Gradient norm for 'f1_f1.weight': 0.0923\n",
      "Gradient norm for 'f1_f2.weight': 0.8257\n",
      "Gradient norm for 'f2_f2.weight': 0.7749\n",
      "Gradient norm for 'f2_o.weight': 9.5579\n",
      "saving max acc: 71.16\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [10/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 0.96345\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 0.88234\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 0.89043\n",
      "l1_score: 0\n",
      "Time elasped: 5.752793788909912\n",
      "Test Loss: 0.9088034898042678\n",
      "Avg spk_count per neuron for all 10 time-steps 1.530843734741211\n",
      "Avg spk per neuron per layer [2.8087875, 3.3145875]\n",
      "Test Accuracy of the model on the test samples: 72.260\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0731\n",
      "Gradient norm for 'f0_f1.weight': 0.0666\n",
      "Gradient norm for 'f1_f1.weight': 0.0930\n",
      "Gradient norm for 'f1_f2.weight': 0.5421\n",
      "Gradient norm for 'f2_f2.weight': 0.4976\n",
      "Gradient norm for 'f2_o.weight': 4.3274\n",
      "saving max acc: 72.26\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [11/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 0.91110\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 0.79737\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 0.87941\n",
      "l1_score: 0\n",
      "Time elasped: 6.276110410690308\n",
      "Test Loss: 0.8905426040291786\n",
      "Avg spk_count per neuron for all 10 time-steps 1.5326069593429565\n",
      "Avg spk per neuron per layer [2.788825, 3.341603125]\n",
      "Test Accuracy of the model on the test samples: 73.540\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0783\n",
      "Gradient norm for 'f0_f1.weight': 0.0791\n",
      "Gradient norm for 'f1_f1.weight': 0.1090\n",
      "Gradient norm for 'f1_f2.weight': 0.6850\n",
      "Gradient norm for 'f2_f2.weight': 0.7078\n",
      "Gradient norm for 'f2_o.weight': 3.3107\n",
      "saving max acc: 73.54\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [12/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 0.83226\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 0.97013\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 0.85823\n",
      "l1_score: 0\n",
      "Time elasped: 6.248752593994141\n",
      "Test Loss: 0.8617252215743065\n",
      "Avg spk_count per neuron for all 10 time-steps 1.5417624711990356\n",
      "Avg spk per neuron per layer [2.771584375, 3.395465625]\n",
      "Test Accuracy of the model on the test samples: 75.540\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0861\n",
      "Gradient norm for 'f0_f1.weight': 0.1244\n",
      "Gradient norm for 'f1_f1.weight': 0.1584\n",
      "Gradient norm for 'f1_f2.weight': 1.1358\n",
      "Gradient norm for 'f2_f2.weight': 1.1209\n",
      "Gradient norm for 'f2_o.weight': 6.4227\n",
      "saving max acc: 75.54\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [13/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 0.84336\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 0.87925\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 0.81157\n",
      "l1_score: 0\n",
      "Time elasped: 6.081692695617676\n",
      "Test Loss: 0.870267029106617\n",
      "Avg spk_count per neuron for all 10 time-steps 1.5558483600616455\n",
      "Avg spk per neuron per layer [2.77930625, 3.4440875]\n",
      "Test Accuracy of the model on the test samples: 75.080\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0378\n",
      "Gradient norm for 'f0_f1.weight': 0.0819\n",
      "Gradient norm for 'f1_f1.weight': 0.1143\n",
      "Gradient norm for 'f1_f2.weight': 0.7411\n",
      "Gradient norm for 'f2_f2.weight': 0.7658\n",
      "Gradient norm for 'f2_o.weight': 7.1651\n",
      "Epoch [14/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 0.89083\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 0.73222\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 0.88740\n",
      "l1_score: 0\n",
      "Time elasped: 6.07053017616272\n",
      "Test Loss: 0.8496180385351181\n",
      "Avg spk_count per neuron for all 10 time-steps 1.5600796937942505\n",
      "Avg spk per neuron per layer [2.774090625, 3.466228125]\n",
      "Test Accuracy of the model on the test samples: 74.760\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0980\n",
      "Gradient norm for 'f0_f1.weight': 0.0635\n",
      "Gradient norm for 'f1_f1.weight': 0.0920\n",
      "Gradient norm for 'f1_f2.weight': 0.6601\n",
      "Gradient norm for 'f2_f2.weight': 0.7005\n",
      "Gradient norm for 'f2_o.weight': 6.7293\n",
      "Epoch [15/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 0.93831\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 0.85389\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 0.87174\n",
      "l1_score: 0\n",
      "Time elasped: 5.948972940444946\n",
      "Test Loss: 0.8261932745575905\n",
      "Avg spk_count per neuron for all 10 time-steps 1.579952359199524\n",
      "Avg spk per neuron per layer [2.795671875, 3.5241375]\n",
      "Test Accuracy of the model on the test samples: 77.500\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0580\n",
      "Gradient norm for 'f0_f1.weight': 0.0606\n",
      "Gradient norm for 'f1_f1.weight': 0.0908\n",
      "Gradient norm for 'f1_f2.weight': 0.6041\n",
      "Gradient norm for 'f2_f2.weight': 0.6330\n",
      "Gradient norm for 'f2_o.weight': 4.0031\n",
      "saving max acc: 77.5\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [16/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 0.85921\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 0.77715\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 0.88938\n",
      "l1_score: 0\n",
      "Time elasped: 5.279212474822998\n",
      "Test Loss: 0.8219612196087838\n",
      "Avg spk_count per neuron for all 10 time-steps 1.5656273365020752\n",
      "Avg spk per neuron per layer [2.788665625, 3.47384375]\n",
      "Test Accuracy of the model on the test samples: 76.880\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0877\n",
      "Gradient norm for 'f0_f1.weight': 0.0466\n",
      "Gradient norm for 'f1_f1.weight': 0.0673\n",
      "Gradient norm for 'f1_f2.weight': 0.3865\n",
      "Gradient norm for 'f2_f2.weight': 0.4344\n",
      "Gradient norm for 'f2_o.weight': 4.1037\n",
      "Epoch [17/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 0.80087\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 0.85216\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 0.74113\n",
      "l1_score: 0\n",
      "Time elasped: 5.223773241043091\n",
      "Test Loss: 0.8006111547350884\n",
      "Avg spk_count per neuron for all 10 time-steps 1.6038601398468018\n",
      "Avg spk per neuron per layer [2.824009375, 3.59143125]\n",
      "Test Accuracy of the model on the test samples: 78.720\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.1126\n",
      "Gradient norm for 'f0_f1.weight': 0.0550\n",
      "Gradient norm for 'f1_f1.weight': 0.0846\n",
      "Gradient norm for 'f1_f2.weight': 0.6846\n",
      "Gradient norm for 'f2_f2.weight': 0.7043\n",
      "Gradient norm for 'f2_o.weight': 8.6104\n",
      "saving max acc: 78.72\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [18/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 0.86479\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 0.76993\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 0.87402\n",
      "l1_score: 0\n",
      "Time elasped: 5.199341773986816\n",
      "Test Loss: 0.804779639840126\n",
      "Avg spk_count per neuron for all 10 time-steps 1.6110483407974243\n",
      "Avg spk per neuron per layer [2.86496875, 3.579225]\n",
      "Test Accuracy of the model on the test samples: 78.580\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0669\n",
      "Gradient norm for 'f0_f1.weight': 0.0710\n",
      "Gradient norm for 'f1_f1.weight': 0.0965\n",
      "Gradient norm for 'f1_f2.weight': 0.5374\n",
      "Gradient norm for 'f2_f2.weight': 0.5761\n",
      "Gradient norm for 'f2_o.weight': 5.0347\n",
      "Epoch [19/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 0.82995\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 0.83919\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 0.81916\n",
      "l1_score: 0\n",
      "Time elasped: 5.221554279327393\n",
      "Test Loss: 0.8080728888511658\n",
      "Avg spk_count per neuron for all 10 time-steps 1.5825499296188354\n",
      "Avg spk per neuron per layer [2.804415625, 3.525784375]\n",
      "Test Accuracy of the model on the test samples: 76.720\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0604\n",
      "Gradient norm for 'f0_f1.weight': 0.0711\n",
      "Gradient norm for 'f1_f1.weight': 0.1007\n",
      "Gradient norm for 'f1_f2.weight': 0.7534\n",
      "Gradient norm for 'f2_f2.weight': 0.7835\n",
      "Gradient norm for 'f2_o.weight': 5.3719\n",
      "Epoch [20/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 0.85691\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 0.74365\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 0.78614\n",
      "l1_score: 0\n",
      "Time elasped: 5.434660911560059\n",
      "Test Loss: 0.7787661030888557\n",
      "Avg spk_count per neuron for all 10 time-steps 1.5879484415054321\n",
      "Avg spk per neuron per layer [2.76539375, 3.5864]\n",
      "Test Accuracy of the model on the test samples: 78.360\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.1200\n",
      "Gradient norm for 'f0_f1.weight': 0.0953\n",
      "Gradient norm for 'f1_f1.weight': 0.1458\n",
      "Gradient norm for 'f1_f2.weight': 0.9132\n",
      "Gradient norm for 'f2_f2.weight': 1.0382\n",
      "Gradient norm for 'f2_o.weight': 6.8953\n",
      "[INFO] TIEMPO: 141.2463400363922\n"
     ]
    }
   ],
   "source": [
    "from snn_delays.utils.train_utils import train\n",
    "from snn_delays.utils.test_behavior import tb_save_max_last_acc\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "taimu1 = time.time()\n",
    "\n",
    "tau_m = 'normal'\n",
    "#delay = (48*2,16*2)\n",
    "#delay = (96,32)\n",
    "delay = None\n",
    "#delay = (50, 1)\n",
    "ckpt_dir = 'exp21_STMNIST_memory' \n",
    "\n",
    "snn = SNN(dataset_dict=dataset_dict, structure=(64, 2), connection_type='r',\n",
    "    delay=delay, delay_type='h', tau_m = tau_m,\n",
    "    win=total_time*sequence_length, loss_fn='mem_sum', batch_size=batch_size, device=device,\n",
    "    debug=False)\n",
    "\n",
    "snn.set_network()\n",
    "\n",
    "snn.model_name = f'dvs5_seq{sequence_length}_{delay}'+ snn.model_name\n",
    "\n",
    "snn.to(device)\n",
    "train(snn, train_loader, test_loader, lr, num_epochs, dropout=0.0, \n",
    "    test_behavior=tb_save_max_last_acc, ckpt_dir=ckpt_dir, scheduler=(100, 0.95), test_every=1)\n",
    "\n",
    "print(f'[INFO] TIEMPO: {time.time() - taimu1}', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delays (10,4): 74%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Delays: tensor([0, 4, 8])\n",
      "\n",
      "[INFO] Delays i: tensor([0])\n",
      "\n",
      "[INFO] Delays h: tensor([0, 4, 8])\n",
      "\n",
      "[INFO] Delays o: tensor([0])\n",
      "0.0001\n",
      "Delta t: 1e-05 ms\n",
      "mean of normal: 14.508657488628742\n",
      "training dvs5_seq10_(10, 4)memorytask10_l2_10d4.t7 for 20 epochs...\n",
      "Epoch [1/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.07080\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.93441\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.97424\n",
      "l1_score: 0\n",
      "Time elasped: 3.926501512527466\n",
      "Test Loss: 1.9555294454097747\n",
      "Avg spk_count per neuron for all 10 time-steps 1.1307835578918457\n",
      "Avg spk per neuron per layer [2.72014375, 1.802990625]\n",
      "Test Accuracy of the model on the test samples: 24.860\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0406\n",
      "Gradient norm for 'f0_f1.weight': 0.1073\n",
      "Gradient norm for 'f1_f2.weight': 0.8903\n",
      "Gradient norm for 'f2_o.weight': 2.3886\n",
      "saving max acc: 24.86\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [2/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.91868\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.79987\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.74058\n",
      "l1_score: 0\n",
      "Time elasped: 3.348635196685791\n",
      "Test Loss: 1.7333348155021668\n",
      "Avg spk_count per neuron for all 10 time-steps 1.0632210969924927\n",
      "Avg spk per neuron per layer [2.605075, 1.647809375]\n",
      "Test Accuracy of the model on the test samples: 36.180\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0352\n",
      "Gradient norm for 'f0_f1.weight': 0.1346\n",
      "Gradient norm for 'f1_f2.weight': 1.3857\n",
      "Gradient norm for 'f2_o.weight': 2.2639\n",
      "saving max acc: 36.18\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [3/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.72745\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.61016\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.57913\n",
      "l1_score: 0\n",
      "Time elasped: 4.124876976013184\n",
      "Test Loss: 1.5783387899398804\n",
      "Avg spk_count per neuron for all 10 time-steps 1.0374882221221924\n",
      "Avg spk per neuron per layer [2.549859375, 1.60009375]\n",
      "Test Accuracy of the model on the test samples: 44.860\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0142\n",
      "Gradient norm for 'f0_f1.weight': 0.1186\n",
      "Gradient norm for 'f1_f2.weight': 1.2011\n",
      "Gradient norm for 'f2_o.weight': 2.6348\n",
      "saving max acc: 44.86\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [4/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.54233\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.45779\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.48085\n",
      "l1_score: 0\n",
      "Time elasped: 4.055920362472534\n",
      "Test Loss: 1.4348921358585358\n",
      "Avg spk_count per neuron for all 10 time-steps 1.0243250131607056\n",
      "Avg spk per neuron per layer [2.4725625, 1.6247375]\n",
      "Test Accuracy of the model on the test samples: 51.100\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0192\n",
      "Gradient norm for 'f0_f1.weight': 0.2196\n",
      "Gradient norm for 'f1_f2.weight': 1.6856\n",
      "Gradient norm for 'f2_o.weight': 3.7987\n",
      "saving max acc: 51.1\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [5/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.33301\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.42025\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.42556\n",
      "l1_score: 0\n",
      "Time elasped: 4.229181289672852\n",
      "Test Loss: 1.3560352146625518\n",
      "Avg spk_count per neuron for all 10 time-steps 0.993470311164856\n",
      "Avg spk per neuron per layer [2.414921875, 1.558959375]\n",
      "Test Accuracy of the model on the test samples: 54.220\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0077\n",
      "Gradient norm for 'f0_f1.weight': 0.0739\n",
      "Gradient norm for 'f1_f2.weight': 1.6848\n",
      "Gradient norm for 'f2_o.weight': 4.4142\n",
      "saving max acc: 54.22\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [6/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.38822\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.30899\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.27360\n",
      "l1_score: 0\n",
      "Time elasped: 4.330074310302734\n",
      "Test Loss: 1.2635456532239915\n",
      "Avg spk_count per neuron for all 10 time-steps 1.0036585330963135\n",
      "Avg spk per neuron per layer [2.39236875, 1.622265625]\n",
      "Test Accuracy of the model on the test samples: 58.140\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0036\n",
      "Gradient norm for 'f0_f1.weight': 0.1807\n",
      "Gradient norm for 'f1_f2.weight': 1.8216\n",
      "Gradient norm for 'f2_o.weight': inf\n",
      "saving max acc: 58.14\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [7/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.19168\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.27553\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.27493\n",
      "l1_score: 0\n",
      "Time elasped: 4.739279508590698\n",
      "Test Loss: 1.2307891577482224\n",
      "Avg spk_count per neuron for all 10 time-steps 0.9966468214988708\n",
      "Avg spk per neuron per layer [2.3789625, 1.607625]\n",
      "Test Accuracy of the model on the test samples: 59.860\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0015\n",
      "Gradient norm for 'f0_f1.weight': 0.1657\n",
      "Gradient norm for 'f1_f2.weight': 1.7016\n",
      "Gradient norm for 'f2_o.weight': 2.8521\n",
      "saving max acc: 59.86\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [8/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.14573\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.15889\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.17117\n",
      "l1_score: 0\n",
      "Time elasped: 4.12527871131897\n",
      "Test Loss: 1.1897501707077027\n",
      "Avg spk_count per neuron for all 10 time-steps 0.9787679314613342\n",
      "Avg spk per neuron per layer [2.330953125, 1.58411875]\n",
      "Test Accuracy of the model on the test samples: 59.600\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0015\n",
      "Gradient norm for 'f0_f1.weight': 0.2022\n",
      "Gradient norm for 'f1_f2.weight': 1.5779\n",
      "Gradient norm for 'f2_o.weight': 3.1516\n",
      "Epoch [9/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.18582\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.16385\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.14691\n",
      "l1_score: 0\n",
      "Time elasped: 4.362880706787109\n",
      "Test Loss: 1.1341467916965484\n",
      "Avg spk_count per neuron for all 10 time-steps 0.9899062514305115\n",
      "Avg spk per neuron per layer [2.34059375, 1.61903125]\n",
      "Test Accuracy of the model on the test samples: 65.100\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0025\n",
      "Gradient norm for 'f0_f1.weight': 0.1075\n",
      "Gradient norm for 'f1_f2.weight': 1.4706\n",
      "Gradient norm for 'f2_o.weight': 3.0997\n",
      "saving max acc: 65.1\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [10/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.07264\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.17285\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.06232\n",
      "l1_score: 0\n",
      "Time elasped: 4.068178176879883\n",
      "Test Loss: 1.0896256178617478\n",
      "Avg spk_count per neuron for all 10 time-steps 0.9728101491928101\n",
      "Avg spk per neuron per layer [2.314071875, 1.57716875]\n",
      "Test Accuracy of the model on the test samples: 65.280\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0020\n",
      "Gradient norm for 'f0_f1.weight': 0.2485\n",
      "Gradient norm for 'f1_f2.weight': 1.9805\n",
      "Gradient norm for 'f2_o.weight': 4.3267\n",
      "saving max acc: 65.28\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [11/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.07521\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.03698\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.10129\n",
      "l1_score: 0\n",
      "Time elasped: 4.210788726806641\n",
      "Test Loss: 1.0796404287219048\n",
      "Avg spk_count per neuron for all 10 time-steps 0.9797335863113403\n",
      "Avg spk per neuron per layer [2.30618125, 1.612753125]\n",
      "Test Accuracy of the model on the test samples: 64.520\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0009\n",
      "Gradient norm for 'f0_f1.weight': 0.3682\n",
      "Gradient norm for 'f1_f2.weight': 1.7252\n",
      "Gradient norm for 'f2_o.weight': 3.0362\n",
      "Epoch [12/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.15851\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 0.99490\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 0.98526\n",
      "l1_score: 0\n",
      "Time elasped: 3.95924711227417\n",
      "Test Loss: 1.0284273013472558\n",
      "Avg spk_count per neuron for all 10 time-steps 0.9843366742134094\n",
      "Avg spk per neuron per layer [2.299503125, 1.63784375]\n",
      "Test Accuracy of the model on the test samples: 67.480\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0006\n",
      "Gradient norm for 'f0_f1.weight': 0.1733\n",
      "Gradient norm for 'f1_f2.weight': 1.8567\n",
      "Gradient norm for 'f2_o.weight': 3.3154\n",
      "saving max acc: 67.48\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [13/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.07986\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.04601\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 0.96502\n",
      "l1_score: 0\n",
      "Time elasped: 4.483720541000366\n",
      "Test Loss: 0.9986456096172333\n",
      "Avg spk_count per neuron for all 10 time-steps 1.0051554441452026\n",
      "Avg spk per neuron per layer [2.326590625, 1.69403125]\n",
      "Test Accuracy of the model on the test samples: 68.340\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0015\n",
      "Gradient norm for 'f0_f1.weight': 0.1618\n",
      "Gradient norm for 'f1_f2.weight': 1.8044\n",
      "Gradient norm for 'f2_o.weight': 3.7857\n",
      "saving max acc: 68.34\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [14/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.01822\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.06043\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.03220\n",
      "l1_score: 0\n",
      "Time elasped: 4.099878549575806\n",
      "Test Loss: 0.9845992684364319\n",
      "Avg spk_count per neuron for all 10 time-steps 0.9987343549728394\n",
      "Avg spk per neuron per layer [2.334653125, 1.660284375]\n",
      "Test Accuracy of the model on the test samples: 69.720\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0003\n",
      "Gradient norm for 'f0_f1.weight': 0.1738\n",
      "Gradient norm for 'f1_f2.weight': 1.8664\n",
      "Gradient norm for 'f2_o.weight': 5.5201\n",
      "saving max acc: 69.72\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [15/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 0.92938\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 0.90565\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.04412\n",
      "l1_score: 0\n",
      "Time elasped: 4.127445459365845\n",
      "Test Loss: 0.9751434326171875\n",
      "Avg spk_count per neuron for all 10 time-steps 0.983549952507019\n",
      "Avg spk per neuron per layer [2.314490625, 1.619709375]\n",
      "Test Accuracy of the model on the test samples: 69.060\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0004\n",
      "Gradient norm for 'f0_f1.weight': 0.1184\n",
      "Gradient norm for 'f1_f2.weight': 1.5841\n",
      "Gradient norm for 'f2_o.weight': 3.3655\n",
      "Epoch [16/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 0.86656\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 0.96593\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 0.87923\n",
      "l1_score: 0\n",
      "Time elasped: 3.980630874633789\n",
      "Test Loss: 0.9447397023439408\n",
      "Avg spk_count per neuron for all 10 time-steps 0.9962640404701233\n",
      "Avg spk per neuron per layer [2.321103125, 1.663953125]\n",
      "Test Accuracy of the model on the test samples: 70.360\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0013\n",
      "Gradient norm for 'f0_f1.weight': 0.1550\n",
      "Gradient norm for 'f1_f2.weight': 1.3537\n",
      "Gradient norm for 'f2_o.weight': 2.2938\n",
      "saving max acc: 70.36\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [17/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 0.97597\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 0.86970\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 0.99557\n",
      "l1_score: 0\n",
      "Time elasped: 4.118547201156616\n",
      "Test Loss: 0.9206888169050217\n",
      "Avg spk_count per neuron for all 10 time-steps 0.9918944835662842\n",
      "Avg spk per neuron per layer [2.333784375, 1.63379375]\n",
      "Test Accuracy of the model on the test samples: 74.260\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0011\n",
      "Gradient norm for 'f0_f1.weight': 0.3358\n",
      "Gradient norm for 'f1_f2.weight': 2.8342\n",
      "Gradient norm for 'f2_o.weight': 4.6892\n",
      "saving max acc: 74.26\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [18/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 0.85380\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 0.84490\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 0.81354\n",
      "l1_score: 0\n",
      "Time elasped: 4.0441365242004395\n",
      "Test Loss: 0.9652853965759277\n",
      "Avg spk_count per neuron for all 10 time-steps 0.989828884601593\n",
      "Avg spk per neuron per layer [2.319809375, 1.63950625]\n",
      "Test Accuracy of the model on the test samples: 68.660\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0009\n",
      "Gradient norm for 'f0_f1.weight': 0.2517\n",
      "Gradient norm for 'f1_f2.weight': 3.3919\n",
      "Gradient norm for 'f2_o.weight': 6.0380\n",
      "Epoch [19/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 0.91183\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 0.89773\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 0.85698\n",
      "l1_score: 0\n",
      "Time elasped: 4.414011240005493\n",
      "Test Loss: 0.8817605003714561\n",
      "Avg spk_count per neuron for all 10 time-steps 0.9948233962059021\n",
      "Avg spk per neuron per layer [2.32470625, 1.6545875]\n",
      "Test Accuracy of the model on the test samples: 74.240\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0004\n",
      "Gradient norm for 'f0_f1.weight': 0.4037\n",
      "Gradient norm for 'f1_f2.weight': 3.3607\n",
      "Gradient norm for 'f2_o.weight': 6.5681\n",
      "Epoch [20/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 0.81275\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 0.94560\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 0.95129\n",
      "l1_score: 0\n",
      "Time elasped: 4.4211273193359375\n",
      "Test Loss: 0.8776851668953896\n",
      "Avg spk_count per neuron for all 10 time-steps 1.0000890493392944\n",
      "Avg spk per neuron per layer [2.32650625, 1.67385]\n",
      "Test Accuracy of the model on the test samples: 74.480\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0002\n",
      "Gradient norm for 'f0_f1.weight': 0.1213\n",
      "Gradient norm for 'f1_f2.weight': 1.5454\n",
      "Gradient norm for 'f2_o.weight': 2.7014\n",
      "saving max acc: 74.48\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "[INFO] TIEMPO: 106.38970756530762\n"
     ]
    }
   ],
   "source": [
    "from snn_delays.utils.train_utils import train\n",
    "from snn_delays.utils.test_behavior import tb_save_max_last_acc\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "taimu1 = time.time()\n",
    "\n",
    "tau_m = 'normal'\n",
    "#delay = (48*2,16*2)\n",
    "#delay = (96,32)\n",
    "#delay = None\n",
    "delay = (10, 4)\n",
    "ckpt_dir = 'exp21_STMNIST_memory' \n",
    "\n",
    "snn = SNN(dataset_dict=dataset_dict, structure=(64, 2), connection_type='f',\n",
    "    delay=delay, delay_type='h', tau_m = tau_m,\n",
    "    win=total_time*sequence_length, loss_fn='mem_sum', batch_size=batch_size, device=device,\n",
    "    debug=False)\n",
    "\n",
    "snn.set_network()\n",
    "\n",
    "snn.model_name = f'dvs5_seq{sequence_length}_{delay}'+ snn.model_name\n",
    "\n",
    "snn.to(device)\n",
    "train(snn, train_loader, test_loader, lr, num_epochs, dropout=0.0, \n",
    "    test_behavior=tb_save_max_last_acc, ckpt_dir=ckpt_dir, scheduler=(100, 0.95), test_every=1)\n",
    "\n",
    "print(f'[INFO] TIEMPO: {time.time() - taimu1}', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With longer sequence lenghts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_input': 10, 'num_training_samples': 10000, 'num_output': 9, 'time_ms': 0.001, 'dataset_name': 'memorytask'}\n"
     ]
    }
   ],
   "source": [
    "from snn_delays.datasets.custom_datasets import CustomDataset\n",
    "\n",
    "lbl = [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], \n",
    "         [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]]\n",
    "\n",
    "imgs = [[1, 0, 1, 0, 1, 0, 1, 0, 1, 0],\n",
    "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 1, 1, 1, 1, 1], \n",
    "         [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]]\n",
    "\n",
    "num_samples = 15000\n",
    "\n",
    "data = np.zeros((num_samples, 1, 10))\n",
    "labels = np.zeros((num_samples, 10))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    cl = np.random.randint(4)\n",
    "    data[i] = 0.2*np.random.rand(10) + imgs[cl]\n",
    "    labels[i] = lbl[cl]\n",
    "\n",
    "train_dataset = CustomDataset(data[:10000], labels[:10000])\n",
    "test_dataset = CustomDataset(data[10000:], labels[10000:])\n",
    "\n",
    "dataset_dict = train_dataset.get_train_attributes()\n",
    "\n",
    "target_classes = [1, 3, 8]\n",
    "sequence_length = 100\n",
    "\n",
    "conc_test_dataset = SequentialMemoryRetrievalDataset(test_dataset, sequence_length, target_classes)\n",
    "conc_train_dataset = SequentialMemoryRetrievalDataset(train_dataset, sequence_length, target_classes)\n",
    "\n",
    "train_dataset = MemoryCachedDataset(conc_train_dataset)\n",
    "test_dataset = MemoryCachedDataset(conc_test_dataset)\n",
    "\n",
    "total_time = 1\n",
    "batch_size = 128\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            drop_last=False,\n",
    "                            pin_memory=True,\n",
    "                            num_workers=0)\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            drop_last=False,\n",
    "                            pin_memory=True,\n",
    "                            num_workers=0)\n",
    "\n",
    "dataset_dict[\"num_output\"] = conc_train_dataset.total_combinations\n",
    "dataset_dict[\"num_training_samples\"] = len(conc_train_dataset)\n",
    "dataset_dict[\"time_ms\"] = 1e-3\n",
    "dataset_dict[\"dataset_name\"] = \"memorytask\"\n",
    "\n",
    "print(dataset_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent: 16%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Delays: tensor([0])\n",
      "\n",
      "[INFO] Delays i: tensor([0])\n",
      "\n",
      "[INFO] Delays h: tensor([0])\n",
      "\n",
      "[INFO] Delays o: tensor([0])\n",
      "0.001\n",
      "Delta t: 1e-05 ms\n",
      "mean of normal: 14.508657488628742\n",
      "training dvs5_seq100_Nonememorytask100_l2_1d1.t7 for 20 epochs...\n",
      "Epoch [1/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.29481\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.19039\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.21622\n",
      "l1_score: 0\n",
      "Time elasped: 357.53864908218384\n",
      "Test Loss: 2.212411403656006\n",
      "Avg spk_count per neuron for all 100 time-steps 12.222721099853516\n",
      "Avg spk per neuron per layer [27.838278125, 21.052609375]\n",
      "Test Accuracy of the model on the test samples: 12.220\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0362\n",
      "Gradient norm for 'f0_f1.weight': 0.0968\n",
      "Gradient norm for 'f1_f1.weight': 0.1771\n",
      "Gradient norm for 'f1_f2.weight': 1.2339\n",
      "Gradient norm for 'f2_f2.weight': 0.9937\n",
      "Gradient norm for 'f2_o.weight': 9.6697\n",
      "saving max acc: 12.22\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [2/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.20751\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.24323\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.19972\n",
      "l1_score: 0\n",
      "Time elasped: 52.665268421173096\n",
      "Test Loss: 2.214883691072464\n",
      "Avg spk_count per neuron for all 100 time-steps 12.473183631896973\n",
      "Avg spk per neuron per layer [28.13021875, 21.762515625]\n",
      "Test Accuracy of the model on the test samples: 11.860\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0513\n",
      "Gradient norm for 'f0_f1.weight': 0.1523\n",
      "Gradient norm for 'f1_f1.weight': 0.2749\n",
      "Gradient norm for 'f1_f2.weight': 2.2296\n",
      "Gradient norm for 'f2_f2.weight': 1.8414\n",
      "Gradient norm for 'f2_o.weight': 14.7646\n",
      "Epoch [3/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.21331\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.21747\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.22286\n",
      "l1_score: 0\n",
      "Time elasped: 49.13177704811096\n",
      "Test Loss: 2.201863354444504\n",
      "Avg spk_count per neuron for all 100 time-steps 12.595922470092773\n",
      "Avg spk per neuron per layer [28.10936875, 22.274321875]\n",
      "Test Accuracy of the model on the test samples: 12.000\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0184\n",
      "Gradient norm for 'f0_f1.weight': 0.1253\n",
      "Gradient norm for 'f1_f1.weight': 0.2263\n",
      "Gradient norm for 'f1_f2.weight': 1.4390\n",
      "Gradient norm for 'f2_f2.weight': 1.2272\n",
      "Gradient norm for 'f2_o.weight': 9.6775\n",
      "Epoch [4/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.21585\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.22656\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.38965\n",
      "l1_score: 0\n",
      "Time elasped: 48.55230259895325\n",
      "Test Loss: 2.218744766712189\n",
      "Avg spk_count per neuron for all 100 time-steps 12.872040748596191\n",
      "Avg spk per neuron per layer [28.087246875, 23.400915625]\n",
      "Test Accuracy of the model on the test samples: 11.200\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0087\n",
      "Gradient norm for 'f0_f1.weight': 0.1013\n",
      "Gradient norm for 'f1_f1.weight': 0.1836\n",
      "Gradient norm for 'f1_f2.weight': 1.1601\n",
      "Gradient norm for 'f2_f2.weight': 1.0357\n",
      "Gradient norm for 'f2_o.weight': 10.5090\n",
      "Epoch [5/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.21584\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.21295\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.18680\n",
      "l1_score: 0\n",
      "Time elasped: 55.23609924316406\n",
      "Test Loss: 2.192597061395645\n",
      "Avg spk_count per neuron for all 100 time-steps 12.989697456359863\n",
      "Avg spk per neuron per layer [28.37125625, 23.587534375]\n",
      "Test Accuracy of the model on the test samples: 13.400\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0091\n",
      "Gradient norm for 'f0_f1.weight': 0.1504\n",
      "Gradient norm for 'f1_f1.weight': 0.2655\n",
      "Gradient norm for 'f1_f2.weight': 1.4637\n",
      "Gradient norm for 'f2_f2.weight': 1.2918\n",
      "Gradient norm for 'f2_o.weight': 10.0575\n",
      "saving max acc: 13.4\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [6/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.19522\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.18668\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.21283\n",
      "l1_score: 0\n",
      "Time elasped: 57.503562450408936\n",
      "Test Loss: 2.191961205005646\n",
      "Avg spk_count per neuron for all 100 time-steps 12.894198417663574\n",
      "Avg spk per neuron per layer [28.07401875, 23.502775]\n",
      "Test Accuracy of the model on the test samples: 13.760\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0074\n",
      "Gradient norm for 'f0_f1.weight': 0.0934\n",
      "Gradient norm for 'f1_f1.weight': 0.1682\n",
      "Gradient norm for 'f1_f2.weight': 1.1402\n",
      "Gradient norm for 'f2_f2.weight': 1.0191\n",
      "Gradient norm for 'f2_o.weight': 7.3497\n",
      "saving max acc: 13.76\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [7/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.21562\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.19103\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.20414\n",
      "l1_score: 0\n",
      "Time elasped: 56.380197048187256\n",
      "Test Loss: 2.1907924234867098\n",
      "Avg spk_count per neuron for all 100 time-steps 12.791980743408203\n",
      "Avg spk per neuron per layer [27.7652, 23.402725]\n",
      "Test Accuracy of the model on the test samples: 13.500\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0092\n",
      "Gradient norm for 'f0_f1.weight': 0.0901\n",
      "Gradient norm for 'f1_f1.weight': 0.1646\n",
      "Gradient norm for 'f1_f2.weight': 1.3682\n",
      "Gradient norm for 'f2_f2.weight': 1.2180\n",
      "Gradient norm for 'f2_o.weight': 10.2145\n",
      "Epoch [8/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.14895\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.19902\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.19270\n",
      "l1_score: 0\n",
      "Time elasped: 56.20775389671326\n",
      "Test Loss: 2.1955193519592284\n",
      "Avg spk_count per neuron for all 100 time-steps 12.898058891296387\n",
      "Avg spk per neuron per layer [27.910184375, 23.682053125]\n",
      "Test Accuracy of the model on the test samples: 13.380\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0045\n",
      "Gradient norm for 'f0_f1.weight': 0.0521\n",
      "Gradient norm for 'f1_f1.weight': 0.0934\n",
      "Gradient norm for 'f1_f2.weight': 0.8020\n",
      "Gradient norm for 'f2_f2.weight': 0.7268\n",
      "Gradient norm for 'f2_o.weight': 8.2877\n",
      "Epoch [9/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.23229\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.15769\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.15882\n",
      "l1_score: 0\n",
      "Time elasped: 57.72470760345459\n",
      "Test Loss: 2.1898384988307953\n",
      "Avg spk_count per neuron for all 100 time-steps 12.780831336975098\n",
      "Avg spk per neuron per layer [27.947271875, 23.176053125]\n",
      "Test Accuracy of the model on the test samples: 14.560\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0056\n",
      "Gradient norm for 'f0_f1.weight': 0.0958\n",
      "Gradient norm for 'f1_f1.weight': 0.1670\n",
      "Gradient norm for 'f1_f2.weight': 1.2615\n",
      "Gradient norm for 'f2_f2.weight': 1.1444\n",
      "Gradient norm for 'f2_o.weight': 11.4650\n",
      "saving max acc: 14.56\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [10/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.21701\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.23479\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.19592\n",
      "l1_score: 0\n",
      "Time elasped: 57.744739294052124\n",
      "Test Loss: 2.2004833459854125\n",
      "Avg spk_count per neuron for all 100 time-steps 12.712956428527832\n",
      "Avg spk per neuron per layer [27.25504375, 23.596784375]\n",
      "Test Accuracy of the model on the test samples: 12.780\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0043\n",
      "Gradient norm for 'f0_f1.weight': 0.0760\n",
      "Gradient norm for 'f1_f1.weight': 0.1329\n",
      "Gradient norm for 'f1_f2.weight': 1.1896\n",
      "Gradient norm for 'f2_f2.weight': 1.1013\n",
      "Gradient norm for 'f2_o.weight': 10.7117\n",
      "Epoch [11/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.21019\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.20315\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.18121\n",
      "l1_score: 0\n",
      "Time elasped: 58.09579563140869\n",
      "Test Loss: 2.1985857784748077\n",
      "Avg spk_count per neuron for all 100 time-steps 12.823101043701172\n",
      "Avg spk per neuron per layer [27.297921875, 23.994484375]\n",
      "Test Accuracy of the model on the test samples: 13.420\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0100\n",
      "Gradient norm for 'f0_f1.weight': 0.1011\n",
      "Gradient norm for 'f1_f1.weight': 0.1729\n",
      "Gradient norm for 'f1_f2.weight': 1.6219\n",
      "Gradient norm for 'f2_f2.weight': 1.5521\n",
      "Gradient norm for 'f2_o.weight': 15.2154\n",
      "Epoch [12/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.20434\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.20495\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.20852\n",
      "l1_score: 0\n",
      "Time elasped: 55.54342341423035\n",
      "Test Loss: 2.1978692412376404\n",
      "Avg spk_count per neuron for all 100 time-steps 12.904768943786621\n",
      "Avg spk per neuron per layer [27.2490375, 24.370040625]\n",
      "Test Accuracy of the model on the test samples: 13.760\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0048\n",
      "Gradient norm for 'f0_f1.weight': 0.0984\n",
      "Gradient norm for 'f1_f1.weight': 0.1680\n",
      "Gradient norm for 'f1_f2.weight': 1.0208\n",
      "Gradient norm for 'f2_f2.weight': 0.9861\n",
      "Gradient norm for 'f2_o.weight': 9.8930\n",
      "Epoch [13/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.22275\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.15769\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.18182\n",
      "l1_score: 0\n",
      "Time elasped: 55.63709783554077\n",
      "Test Loss: 2.1752674996852877\n",
      "Avg spk_count per neuron for all 100 time-steps 12.669964790344238\n",
      "Avg spk per neuron per layer [26.820103125, 23.85975625]\n",
      "Test Accuracy of the model on the test samples: 14.640\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0036\n",
      "Gradient norm for 'f0_f1.weight': 0.1289\n",
      "Gradient norm for 'f1_f1.weight': 0.2165\n",
      "Gradient norm for 'f1_f2.weight': 1.2719\n",
      "Gradient norm for 'f2_f2.weight': 1.2174\n",
      "Gradient norm for 'f2_o.weight': 10.6527\n",
      "saving max acc: 14.64\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [14/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.18025\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.17585\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.20526\n",
      "l1_score: 0\n",
      "Time elasped: 54.56143665313721\n",
      "Test Loss: 2.183753329515457\n",
      "Avg spk_count per neuron for all 100 time-steps 12.632216453552246\n",
      "Avg spk per neuron per layer [27.167734375, 23.36113125]\n",
      "Test Accuracy of the model on the test samples: 14.420\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0035\n",
      "Gradient norm for 'f0_f1.weight': 0.0770\n",
      "Gradient norm for 'f1_f1.weight': 0.1287\n",
      "Gradient norm for 'f1_f2.weight': 0.7519\n",
      "Gradient norm for 'f2_f2.weight': 0.7065\n",
      "Gradient norm for 'f2_o.weight': 6.2411\n",
      "Epoch [15/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.17622\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.20578\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.16733\n",
      "l1_score: 0\n",
      "Time elasped: 52.0506534576416\n",
      "Test Loss: 2.1744660556316378\n",
      "Avg spk_count per neuron for all 100 time-steps 12.719529151916504\n",
      "Avg spk per neuron per layer [27.16185, 23.71626875]\n",
      "Test Accuracy of the model on the test samples: 15.920\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0029\n",
      "Gradient norm for 'f0_f1.weight': 0.0702\n",
      "Gradient norm for 'f1_f1.weight': 0.1209\n",
      "Gradient norm for 'f1_f2.weight': 1.0079\n",
      "Gradient norm for 'f2_f2.weight': 0.9606\n",
      "Gradient norm for 'f2_o.weight': 8.5375\n",
      "saving max acc: 15.92\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [16/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.17235\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.17224\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.18007\n",
      "l1_score: 0\n",
      "Time elasped: 49.894838094711304\n",
      "Test Loss: 2.187711650133133\n",
      "Avg spk_count per neuron for all 100 time-steps 12.62691879272461\n",
      "Avg spk per neuron per layer [27.561571875, 22.94610625]\n",
      "Test Accuracy of the model on the test samples: 14.820\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0069\n",
      "Gradient norm for 'f0_f1.weight': 0.1006\n",
      "Gradient norm for 'f1_f1.weight': 0.1683\n",
      "Gradient norm for 'f1_f2.weight': 0.9139\n",
      "Gradient norm for 'f2_f2.weight': 0.8578\n",
      "Gradient norm for 'f2_o.weight': 8.8726\n",
      "Epoch [17/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.17057\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.22402\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.19309\n",
      "l1_score: 0\n",
      "Time elasped: 49.541574478149414\n",
      "Test Loss: 2.168776297569275\n",
      "Avg spk_count per neuron for all 100 time-steps 13.141053199768066\n",
      "Avg spk per neuron per layer [28.269003125, 24.2952125]\n",
      "Test Accuracy of the model on the test samples: 16.220\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0068\n",
      "Gradient norm for 'f0_f1.weight': 0.0931\n",
      "Gradient norm for 'f1_f1.weight': 0.1591\n",
      "Gradient norm for 'f1_f2.weight': 1.0320\n",
      "Gradient norm for 'f2_f2.weight': 0.9699\n",
      "Gradient norm for 'f2_o.weight': 7.2498\n",
      "saving max acc: 16.22\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [18/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.20096\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.13519\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.11086\n",
      "l1_score: 0\n",
      "Time elasped: 49.09322786331177\n",
      "Test Loss: 2.148975193500519\n",
      "Avg spk_count per neuron for all 100 time-steps 13.245479583740234\n",
      "Avg spk per neuron per layer [28.57175625, 24.4101625]\n",
      "Test Accuracy of the model on the test samples: 16.760\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0026\n",
      "Gradient norm for 'f0_f1.weight': 0.0780\n",
      "Gradient norm for 'f1_f1.weight': 0.1341\n",
      "Gradient norm for 'f1_f2.weight': 0.6447\n",
      "Gradient norm for 'f2_f2.weight': 0.6148\n",
      "Gradient norm for 'f2_o.weight': 5.8924\n",
      "saving max acc: 16.76\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [19/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.15391\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.15659\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.13712\n",
      "l1_score: 0\n",
      "Time elasped: 50.30498456954956\n",
      "Test Loss: 2.190424931049347\n",
      "Avg spk_count per neuron for all 100 time-steps 13.768481254577637\n",
      "Avg spk per neuron per layer [30.16508125, 24.908846875]\n",
      "Test Accuracy of the model on the test samples: 16.020\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0022\n",
      "Gradient norm for 'f0_f1.weight': 0.0680\n",
      "Gradient norm for 'f1_f1.weight': 0.1225\n",
      "Gradient norm for 'f1_f2.weight': 0.9880\n",
      "Gradient norm for 'f2_f2.weight': 0.9217\n",
      "Gradient norm for 'f2_o.weight': 7.5634\n",
      "Epoch [20/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.13044\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.14933\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.16433\n",
      "l1_score: 0\n",
      "Time elasped: 51.37801647186279\n",
      "Test Loss: 2.1678530037403108\n",
      "Avg spk_count per neuron for all 100 time-steps 13.759246826171875\n",
      "Avg spk per neuron per layer [29.715953125, 25.321034375]\n",
      "Test Accuracy of the model on the test samples: 15.340\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0045\n",
      "Gradient norm for 'f0_f1.weight': 0.0958\n",
      "Gradient norm for 'f1_f1.weight': 0.1682\n",
      "Gradient norm for 'f1_f2.weight': 1.4185\n",
      "Gradient norm for 'f2_f2.weight': 1.3372\n",
      "Gradient norm for 'f2_o.weight': 12.3946\n",
      "[INFO] TIEMPO: 1698.9691262245178\n"
     ]
    }
   ],
   "source": [
    "from snn_delays.utils.train_utils import train\n",
    "from snn_delays.utils.test_behavior import tb_save_max_last_acc\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "taimu1 = time.time()\n",
    "\n",
    "tau_m = 'normal'\n",
    "#delay = (48*2,16*2)\n",
    "#delay = (96,32)\n",
    "delay = None\n",
    "#delay = (50, 1)\n",
    "ckpt_dir = 'exp21_STMNIST_memory' \n",
    "\n",
    "snn = SNN(dataset_dict=dataset_dict, structure=(64, 2), connection_type='r',\n",
    "    delay=delay, delay_type='h', tau_m = tau_m,\n",
    "    win=total_time*sequence_length, loss_fn='mem_sum', batch_size=batch_size, device=device,\n",
    "    debug=False)\n",
    "\n",
    "snn.set_network()\n",
    "\n",
    "snn.model_name = f'dvs5_seq{sequence_length}_{delay}'+ snn.model_name\n",
    "\n",
    "snn.to(device)\n",
    "train(snn, train_loader, test_loader, lr, num_epochs, dropout=0.0, \n",
    "    test_behavior=tb_save_max_last_acc, ckpt_dir=ckpt_dir, scheduler=(100, 0.95), test_every=1)\n",
    "\n",
    "print(f'[INFO] TIEMPO: {time.time() - taimu1}', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delays (full): 12%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Delays: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
      "        90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n",
      "\n",
      "[INFO] Delays i: tensor([0])\n",
      "\n",
      "[INFO] Delays h: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
      "        90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n",
      "\n",
      "[INFO] Delays o: tensor([0])\n",
      "0.001\n",
      "Delta t: 1e-05 ms\n",
      "mean of normal: 14.508657488628742\n",
      "training dvs5_seq100_(100, 1)memorytask100_l2_100d1.t7 for 20 epochs...\n",
      "Epoch [1/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 5.02127\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.57038\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.20891\n",
      "l1_score: 0\n",
      "Time elasped: 41.727736711502075\n",
      "Test Loss: 2.211305338144302\n",
      "Avg spk_count per neuron for all 100 time-steps 14.738078117370605\n",
      "Avg spk per neuron per layer [25.655571875, 33.29675]\n",
      "Test Accuracy of the model on the test samples: 11.080\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.1634\n",
      "Gradient norm for 'f0_f1.weight': 0.0072\n",
      "Gradient norm for 'f1_f2.weight': 0.6196\n",
      "Gradient norm for 'f2_o.weight': 18.5983\n",
      "saving max acc: 11.08\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [2/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.19523\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.19875\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.22199\n",
      "l1_score: 0\n",
      "Time elasped: 41.04301691055298\n",
      "Test Loss: 2.2010635852813722\n",
      "Avg spk_count per neuron for all 100 time-steps 14.747498512268066\n",
      "Avg spk per neuron per layer [25.631590625, 33.358403125]\n",
      "Test Accuracy of the model on the test samples: 11.280\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.2186\n",
      "Gradient norm for 'f0_f1.weight': 0.0058\n",
      "Gradient norm for 'f1_f2.weight': 0.4977\n",
      "Gradient norm for 'f2_o.weight': 21.6257\n",
      "saving max acc: 11.28\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [3/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.21026\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.21997\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.20344\n",
      "l1_score: 0\n",
      "Time elasped: 40.90446758270264\n",
      "Test Loss: 2.1977305173873902\n",
      "Avg spk_count per neuron for all 100 time-steps 14.716180801391602\n",
      "Avg spk per neuron per layer [25.592928125, 33.271790625]\n",
      "Test Accuracy of the model on the test samples: 10.880\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.2344\n",
      "Gradient norm for 'f0_f1.weight': 0.0058\n",
      "Gradient norm for 'f1_f2.weight': 0.4138\n",
      "Gradient norm for 'f2_o.weight': 23.8856\n",
      "Epoch [4/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.23118\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.20500\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.20226\n",
      "l1_score: 0\n",
      "Time elasped: 39.2756609916687\n",
      "Test Loss: 2.196588563919067\n",
      "Avg spk_count per neuron for all 100 time-steps 14.673360824584961\n",
      "Avg spk per neuron per layer [25.579790625, 33.113653125]\n",
      "Test Accuracy of the model on the test samples: 11.640\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.2193\n",
      "Gradient norm for 'f0_f1.weight': 0.0124\n",
      "Gradient norm for 'f1_f2.weight': 0.5377\n",
      "Gradient norm for 'f2_o.weight': 22.3188\n",
      "saving max acc: 11.64\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [5/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.18715\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.20494\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.19451\n",
      "l1_score: 0\n",
      "Time elasped: 40.60551166534424\n",
      "Test Loss: 2.2079174399375914\n",
      "Avg spk_count per neuron for all 100 time-steps 14.567390441894531\n",
      "Avg spk per neuron per layer [25.41325, 32.8563125]\n",
      "Test Accuracy of the model on the test samples: 9.920\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.2002\n",
      "Gradient norm for 'f0_f1.weight': 0.0216\n",
      "Gradient norm for 'f1_f2.weight': 0.5518\n",
      "Gradient norm for 'f2_o.weight': 22.3364\n",
      "Epoch [6/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.22490\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.19699\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.21008\n",
      "l1_score: 0\n",
      "Time elasped: 42.014625549316406\n",
      "Test Loss: 2.2053885400295257\n",
      "Avg spk_count per neuron for all 100 time-steps 14.587418556213379\n",
      "Avg spk per neuron per layer [25.21225, 33.13741875]\n",
      "Test Accuracy of the model on the test samples: 12.200\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0738\n",
      "Gradient norm for 'f0_f1.weight': 0.0218\n",
      "Gradient norm for 'f1_f2.weight': 0.3728\n",
      "Gradient norm for 'f2_o.weight': 9.0907\n",
      "saving max acc: 12.2\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [7/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.20441\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.22317\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.17032\n",
      "l1_score: 0\n",
      "Time elasped: 40.21086835861206\n",
      "Test Loss: 2.2018565058708193\n",
      "Avg spk_count per neuron for all 100 time-steps 14.497602462768555\n",
      "Avg spk per neuron per layer [24.961665625, 33.028746875]\n",
      "Test Accuracy of the model on the test samples: 11.000\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.1269\n",
      "Gradient norm for 'f0_f1.weight': 0.0273\n",
      "Gradient norm for 'f1_f2.weight': 0.3555\n",
      "Gradient norm for 'f2_o.weight': 12.7782\n",
      "Epoch [8/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.20059\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.16463\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.18293\n",
      "l1_score: 0\n",
      "Time elasped: 41.19558501243591\n",
      "Test Loss: 2.198188507556915\n",
      "Avg spk_count per neuron for all 100 time-steps 14.442461967468262\n",
      "Avg spk per neuron per layer [24.855171875, 32.914671875]\n",
      "Test Accuracy of the model on the test samples: 12.040\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.1963\n",
      "Gradient norm for 'f0_f1.weight': 0.0252\n",
      "Gradient norm for 'f1_f2.weight': 0.5807\n",
      "Gradient norm for 'f2_o.weight': 23.2623\n",
      "Epoch [9/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.23130\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.19072\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.21047\n",
      "l1_score: 0\n",
      "Time elasped: 40.40229678153992\n",
      "Test Loss: 2.2020372986793517\n",
      "Avg spk_count per neuron for all 100 time-steps 14.475261688232422\n",
      "Avg spk per neuron per layer [24.80095, 33.100103125]\n",
      "Test Accuracy of the model on the test samples: 11.680\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.1598\n",
      "Gradient norm for 'f0_f1.weight': 0.0214\n",
      "Gradient norm for 'f1_f2.weight': 0.5075\n",
      "Gradient norm for 'f2_o.weight': 20.1474\n",
      "Epoch [10/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.20662\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.19795\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.18347\n",
      "l1_score: 0\n",
      "Time elasped: 39.49201774597168\n",
      "Test Loss: 2.2043407797813415\n",
      "Avg spk_count per neuron for all 100 time-steps 14.43234920501709\n",
      "Avg spk per neuron per layer [24.645375, 33.08401875]\n",
      "Test Accuracy of the model on the test samples: 11.560\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.1804\n",
      "Gradient norm for 'f0_f1.weight': 0.0189\n",
      "Gradient norm for 'f1_f2.weight': 0.3972\n",
      "Gradient norm for 'f2_o.weight': 19.7705\n",
      "Epoch [11/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.19699\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.18660\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.19582\n",
      "l1_score: 0\n",
      "Time elasped: 41.31996726989746\n",
      "Test Loss: 2.202173227071762\n",
      "Avg spk_count per neuron for all 100 time-steps 14.371465682983398\n",
      "Avg spk per neuron per layer [24.510696875, 32.975178125]\n",
      "Test Accuracy of the model on the test samples: 11.240\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0600\n",
      "Gradient norm for 'f0_f1.weight': 0.0162\n",
      "Gradient norm for 'f1_f2.weight': 0.2416\n",
      "Gradient norm for 'f2_o.weight': 9.8212\n",
      "Epoch [12/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.16577\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.21207\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.17214\n",
      "l1_score: 0\n",
      "Time elasped: 40.49554991722107\n",
      "Test Loss: 2.2071362376213073\n",
      "Avg spk_count per neuron for all 100 time-steps 14.321306228637695\n",
      "Avg spk per neuron per layer [24.189396875, 33.09583125]\n",
      "Test Accuracy of the model on the test samples: 11.260\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0971\n",
      "Gradient norm for 'f0_f1.weight': 0.0303\n",
      "Gradient norm for 'f1_f2.weight': 0.4875\n",
      "Gradient norm for 'f2_o.weight': 14.7646\n",
      "Epoch [13/20], learning_rates 0.001000, 0.100000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m snn\u001b[38;5;241m.\u001b[39mmodel_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdvs5_seq\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msequence_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdelay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m snn\u001b[38;5;241m.\u001b[39mmodel_name\n\u001b[0;32m     26\u001b[0m snn\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 27\u001b[0m train(snn, train_loader, test_loader, lr, num_epochs, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, \n\u001b[0;32m     28\u001b[0m     test_behavior\u001b[38;5;241m=\u001b[39mtb_save_max_last_acc, ckpt_dir\u001b[38;5;241m=\u001b[39mckpt_dir, scheduler\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m0.95\u001b[39m), test_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[INFO] TIEMPO: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mtaimu1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Python\\SNNdelays\\snn_delays\\utils\\train_utils.py:83\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(snn, train_loader, test_loader, learning_rate, num_epochs, spk_reg, l1_reg, dropout, lr_tau, scheduler, ckpt_dir, test_behavior, test_every, delay_pruning, weight_pruning, lsm, random_delay_pruning, weight_quantization, k, depth, freeze_taus, verbose)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m], learning_rates \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, num_epochs,\n\u001b[0;32m     79\u001b[0m                                                  current_lr, current_lr_tau), flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m k\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 83\u001b[0m     snn\u001b[38;5;241m.\u001b[39mtrain_step(train_loader,\n\u001b[0;32m     84\u001b[0m                 optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m     85\u001b[0m                 scheduler \u001b[38;5;241m=\u001b[39m scheduler,\n\u001b[0;32m     86\u001b[0m                 spk_reg\u001b[38;5;241m=\u001b[39mspk_reg,\n\u001b[0;32m     87\u001b[0m                 l1_reg\u001b[38;5;241m=\u001b[39ml1_reg,\n\u001b[0;32m     88\u001b[0m                 dropout\u001b[38;5;241m=\u001b[39mdropout,\n\u001b[0;32m     89\u001b[0m                 verbose\u001b[38;5;241m=\u001b[39mverbose)        \n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     snn\u001b[38;5;241m.\u001b[39mtrain_step_tr(train_loader\u001b[38;5;241m=\u001b[39mtrain_loader, optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m     92\u001b[0m                     criterion\u001b[38;5;241m=\u001b[39msnn\u001b[38;5;241m.\u001b[39mcriterion, spk_reg\u001b[38;5;241m=\u001b[39mspk_reg,\n\u001b[0;32m     93\u001b[0m                     depth\u001b[38;5;241m=\u001b[39mdepth, k\u001b[38;5;241m=\u001b[39mk, last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Python\\SNNdelays\\snn_delays\\snn.py:187\u001b[0m, in \u001b[0;36mTraining.train_step\u001b[1;34m(self, train_loader, optimizer, scheduler, spk_reg, l1_reg, dropout, verbose)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;66;03m# # Dropout [REVIEW]\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;66;03m# images = self.dropout(images.float())\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m amp\u001b[38;5;241m.\u001b[39mautocast(enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_amp):\n\u001b[0;32m    185\u001b[0m \n\u001b[0;32m    186\u001b[0m     \u001b[38;5;66;03m# Propagate data\u001b[39;00m\n\u001b[1;32m--> 187\u001b[0m     outputs, reference \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(images, labels)\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;66;03m#total spike count (for spike regularization)\u001b[39;00m\n\u001b[0;32m    190\u001b[0m     spk_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh_sum_spike \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_neurons_list) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwin)\n",
      "File \u001b[1;32m~\\Python\\SNNdelays\\snn_delays\\snn.py:123\u001b[0m, in \u001b[0;36mTraining.propagate\u001b[1;34m(self, images, labels)\u001b[0m\n\u001b[0;32m    119\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    121\u001b[0m l_f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn\n\u001b[1;32m--> 123\u001b[0m all_o_mems, all_o_spikes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(images)\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m l_f \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmem_last\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    126\u001b[0m     _, labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(labels\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Python\\SNNdelays\\snn_delays\\snn.py:1005\u001b[0m, in \u001b[0;36mSNN.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m   1000\u001b[0m mems[layer], spikes[layer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_mem_fn(\n\u001b[0;32m   1001\u001b[0m     prev_spikes\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), spikes[layer], mems[layer], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthresh, r_ext_spk)\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelay_type:\n\u001b[0;32m   1004\u001b[0m     extended_spikes[layer][:, step\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_d,\n\u001b[1;32m-> 1005\u001b[0m                         :] \u001b[38;5;241m=\u001b[39m spikes[layer]\u001b[38;5;241m.\u001b[39mclone()  \u001b[38;5;66;03m# possibly detach()\u001b[39;00m\n\u001b[0;32m   1006\u001b[0m     prev_spikes \u001b[38;5;241m=\u001b[39m extended_spikes[layer][:, step \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelays, :]\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mclone()\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from snn_delays.utils.train_utils import train\n",
    "from snn_delays.utils.test_behavior import tb_save_max_last_acc\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "taimu1 = time.time()\n",
    "\n",
    "tau_m = 'normal'\n",
    "#delay = (48*2,16*2)\n",
    "#delay = (96,32)\n",
    "#delay = None\n",
    "delay = (100, 1)\n",
    "ckpt_dir = 'exp21_STMNIST_memory' \n",
    "\n",
    "snn = SNN(dataset_dict=dataset_dict, structure=(64, 2), connection_type='f',\n",
    "    delay=delay, delay_type='h', tau_m = tau_m,\n",
    "    win=total_time*sequence_length, loss_fn='mem_sum', batch_size=batch_size, device=device,\n",
    "    debug=False)\n",
    "\n",
    "snn.set_network()\n",
    "\n",
    "snn.model_name = f'dvs5_seq{sequence_length}_{delay}'+ snn.model_name\n",
    "\n",
    "snn.to(device)\n",
    "train(snn, train_loader, test_loader, lr, num_epochs, dropout=0.0, \n",
    "    test_behavior=tb_save_max_last_acc, ckpt_dir=ckpt_dir, scheduler=(100, 0.95), test_every=1)\n",
    "\n",
    "print(f'[INFO] TIEMPO: {time.time() - taimu1}', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Delays: tensor([0, 1])\n",
      "\n",
      "[INFO] Delays i: tensor([0])\n",
      "\n",
      "[INFO] Delays h: tensor([0, 1])\n",
      "\n",
      "[INFO] Delays o: tensor([0])\n",
      "0.001\n",
      "Delta t: 1e-05 ms\n",
      "mean of normal: 14.508657488628742\n",
      "training dvs5_seq100_(2, 1)memorytask100_l2_2d1.t7 for 20 epochs...\n",
      "Epoch [1/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.24239\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.22359\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.19778\n",
      "l1_score: 0\n",
      "Time elasped: 39.87898373603821\n",
      "Test Loss: 2.2141391932964325\n",
      "Avg spk_count per neuron for all 100 time-steps 10.067021369934082\n",
      "Avg spk per neuron per layer [23.759353125, 16.508734375]\n",
      "Test Accuracy of the model on the test samples: 12.100\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0138\n",
      "Gradient norm for 'f0_f1.weight': 0.2334\n",
      "Gradient norm for 'f1_f2.weight': 2.1991\n",
      "Gradient norm for 'f2_o.weight': 5.4545\n",
      "saving max acc: 12.1\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [2/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.19855\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.20344\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.20190\n",
      "l1_score: 0\n",
      "Time elasped: 40.218748807907104\n",
      "Test Loss: 2.1967374980449677\n",
      "Avg spk_count per neuron for all 100 time-steps 10.114051818847656\n",
      "Avg spk per neuron per layer [23.80083125, 16.655378125]\n",
      "Test Accuracy of the model on the test samples: 13.480\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0214\n",
      "Gradient norm for 'f0_f1.weight': 0.3894\n",
      "Gradient norm for 'f1_f2.weight': 4.2096\n",
      "Gradient norm for 'f2_o.weight': 9.8807\n",
      "saving max acc: 13.48\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [3/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.13897\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.21806\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.18862\n",
      "l1_score: 0\n",
      "Time elasped: 39.66863560676575\n",
      "Test Loss: 2.211423009634018\n",
      "Avg spk_count per neuron for all 100 time-steps 10.139689445495605\n",
      "Avg spk per neuron per layer [23.843734375, 16.715025]\n",
      "Test Accuracy of the model on the test samples: 11.340\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0093\n",
      "Gradient norm for 'f0_f1.weight': 0.2701\n",
      "Gradient norm for 'f1_f2.weight': 2.7039\n",
      "Gradient norm for 'f2_o.weight': 7.0543\n",
      "Epoch [4/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.19103\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.17363\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.19266\n",
      "l1_score: 0\n",
      "Time elasped: 40.87267017364502\n",
      "Test Loss: 2.1945831775665283\n",
      "Avg spk_count per neuron for all 100 time-steps 10.085479736328125\n",
      "Avg spk per neuron per layer [23.79891875, 16.543]\n",
      "Test Accuracy of the model on the test samples: 14.680\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0086\n",
      "Gradient norm for 'f0_f1.weight': 0.2397\n",
      "Gradient norm for 'f1_f2.weight': 2.1017\n",
      "Gradient norm for 'f2_o.weight': 6.6230\n",
      "saving max acc: 14.68\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [5/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.16322\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.19989\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.17656\n",
      "l1_score: 0\n",
      "Time elasped: 40.47536849975586\n",
      "Test Loss: 2.189240127801895\n",
      "Avg spk_count per neuron for all 100 time-steps 10.014257431030273\n",
      "Avg spk per neuron per layer [23.70268125, 16.35435]\n",
      "Test Accuracy of the model on the test samples: 12.960\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0073\n",
      "Gradient norm for 'f0_f1.weight': 0.3016\n",
      "Gradient norm for 'f1_f2.weight': 2.1563\n",
      "Gradient norm for 'f2_o.weight': 6.9631\n",
      "Epoch [6/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.19868\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.18243\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.15718\n",
      "l1_score: 0\n",
      "Time elasped: 40.396852254867554\n",
      "Test Loss: 2.174854701757431\n",
      "Avg spk_count per neuron for all 100 time-steps 10.060154914855957\n",
      "Avg spk per neuron per layer [23.596734375, 16.6438875]\n",
      "Test Accuracy of the model on the test samples: 14.520\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0062\n",
      "Gradient norm for 'f0_f1.weight': 0.4035\n",
      "Gradient norm for 'f1_f2.weight': 3.0137\n",
      "Gradient norm for 'f2_o.weight': 8.1321\n",
      "Epoch [7/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.16183\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.17147\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.16432\n",
      "l1_score: 0\n",
      "Time elasped: 40.20671033859253\n",
      "Test Loss: 2.1924804925918577\n",
      "Avg spk_count per neuron for all 100 time-steps 10.11623477935791\n",
      "Avg spk per neuron per layer [23.609496875, 16.85544375]\n",
      "Test Accuracy of the model on the test samples: 13.020\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0042\n",
      "Gradient norm for 'f0_f1.weight': 0.1793\n",
      "Gradient norm for 'f1_f2.weight': 2.0873\n",
      "Gradient norm for 'f2_o.weight': 6.1985\n",
      "Epoch [8/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.15963\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.16120\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.19863\n",
      "l1_score: 0\n",
      "Time elasped: 40.32623219490051\n",
      "Test Loss: 2.183345949649811\n",
      "Avg spk_count per neuron for all 100 time-steps 9.955625534057617\n",
      "Avg spk per neuron per layer [23.409425, 16.413078125]\n",
      "Test Accuracy of the model on the test samples: 14.300\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0249\n",
      "Gradient norm for 'f0_f1.weight': 0.2725\n",
      "Gradient norm for 'f1_f2.weight': 2.0262\n",
      "Gradient norm for 'f2_o.weight': 5.1867\n",
      "Epoch [9/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.17795\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.17614\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.13889\n",
      "l1_score: 0\n",
      "Time elasped: 40.13361692428589\n",
      "Test Loss: 2.2139922380447388\n",
      "Avg spk_count per neuron for all 100 time-steps 10.114288330078125\n",
      "Avg spk per neuron per layer [23.37934375, 17.077809375]\n",
      "Test Accuracy of the model on the test samples: 13.680\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0137\n",
      "Gradient norm for 'f0_f1.weight': 0.2472\n",
      "Gradient norm for 'f1_f2.weight': 2.4895\n",
      "Gradient norm for 'f2_o.weight': 6.5960\n",
      "Epoch [10/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.17372\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.19021\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.19584\n",
      "l1_score: 0\n",
      "Time elasped: 40.14085912704468\n",
      "Test Loss: 2.189528852701187\n",
      "Avg spk_count per neuron for all 100 time-steps 10.089324951171875\n",
      "Avg spk per neuron per layer [23.011878125, 17.345421875]\n",
      "Test Accuracy of the model on the test samples: 13.940\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0038\n",
      "Gradient norm for 'f0_f1.weight': 0.1457\n",
      "Gradient norm for 'f1_f2.weight': 1.5167\n",
      "Gradient norm for 'f2_o.weight': 5.2419\n",
      "Epoch [11/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.20301\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.16411\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.17381\n",
      "l1_score: 0\n",
      "Time elasped: 40.02713346481323\n",
      "Test Loss: 2.184476727247238\n",
      "Avg spk_count per neuron for all 100 time-steps 10.004658699035645\n",
      "Avg spk per neuron per layer [22.834290625, 17.18434375]\n",
      "Test Accuracy of the model on the test samples: 13.880\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0033\n",
      "Gradient norm for 'f0_f1.weight': 0.3112\n",
      "Gradient norm for 'f1_f2.weight': 2.5505\n",
      "Gradient norm for 'f2_o.weight': 7.7841\n",
      "Epoch [12/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.22448\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.20178\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.19564\n",
      "l1_score: 0\n",
      "Time elasped: 40.1853928565979\n",
      "Test Loss: 2.1817318201065063\n",
      "Avg spk_count per neuron for all 100 time-steps 10.014009475708008\n",
      "Avg spk per neuron per layer [22.728225, 17.3278125]\n",
      "Test Accuracy of the model on the test samples: 15.080\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0056\n",
      "Gradient norm for 'f0_f1.weight': 0.1937\n",
      "Gradient norm for 'f1_f2.weight': 1.7675\n",
      "Gradient norm for 'f2_o.weight': 5.8861\n",
      "saving max acc: 15.08\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [13/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.18018\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.15911\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.17441\n",
      "l1_score: 0\n",
      "Time elasped: 39.620888471603394\n",
      "Test Loss: 2.18747056722641\n",
      "Avg spk_count per neuron for all 100 time-steps 9.959115982055664\n",
      "Avg spk per neuron per layer [22.52064375, 17.315821875]\n",
      "Test Accuracy of the model on the test samples: 14.200\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0187\n",
      "Gradient norm for 'f0_f1.weight': 0.1918\n",
      "Gradient norm for 'f1_f2.weight': 1.5921\n",
      "Gradient norm for 'f2_o.weight': 6.1923\n",
      "Epoch [14/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.16856\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.20816\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.20245\n",
      "l1_score: 0\n",
      "Time elasped: 40.68684911727905\n",
      "Test Loss: 2.1771272480487824\n",
      "Avg spk_count per neuron for all 100 time-steps 10.009295463562012\n",
      "Avg spk per neuron per layer [22.507303125, 17.52988125]\n",
      "Test Accuracy of the model on the test samples: 15.200\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0036\n",
      "Gradient norm for 'f0_f1.weight': 0.2429\n",
      "Gradient norm for 'f1_f2.weight': 1.6120\n",
      "Gradient norm for 'f2_o.weight': 6.8610\n",
      "saving max acc: 15.2\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [15/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.15689\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.14538\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.15540\n",
      "l1_score: 0\n",
      "Time elasped: 40.34157204627991\n",
      "Test Loss: 2.167914429306984\n",
      "Avg spk_count per neuron for all 100 time-steps 9.983591079711914\n",
      "Avg spk per neuron per layer [22.5646875, 17.369678125]\n",
      "Test Accuracy of the model on the test samples: 15.400\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0045\n",
      "Gradient norm for 'f0_f1.weight': 0.2491\n",
      "Gradient norm for 'f1_f2.weight': 2.8724\n",
      "Gradient norm for 'f2_o.weight': 8.1374\n",
      "saving max acc: 15.4\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [16/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.15622\n",
      "l1_score: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m snn\u001b[38;5;241m.\u001b[39mmodel_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdvs5_seq\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msequence_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdelay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m snn\u001b[38;5;241m.\u001b[39mmodel_name\n\u001b[0;32m     26\u001b[0m snn\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 27\u001b[0m train(snn, train_loader, test_loader, lr, num_epochs, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, \n\u001b[0;32m     28\u001b[0m     test_behavior\u001b[38;5;241m=\u001b[39mtb_save_max_last_acc, ckpt_dir\u001b[38;5;241m=\u001b[39mckpt_dir, scheduler\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m0.95\u001b[39m), test_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[INFO] TIEMPO: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mtaimu1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Python\\SNNdelays\\snn_delays\\utils\\train_utils.py:83\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(snn, train_loader, test_loader, learning_rate, num_epochs, spk_reg, l1_reg, dropout, lr_tau, scheduler, ckpt_dir, test_behavior, test_every, delay_pruning, weight_pruning, lsm, random_delay_pruning, weight_quantization, k, depth, freeze_taus, verbose)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m], learning_rates \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, num_epochs,\n\u001b[0;32m     79\u001b[0m                                                  current_lr, current_lr_tau), flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m k\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 83\u001b[0m     snn\u001b[38;5;241m.\u001b[39mtrain_step(train_loader,\n\u001b[0;32m     84\u001b[0m                 optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m     85\u001b[0m                 scheduler \u001b[38;5;241m=\u001b[39m scheduler,\n\u001b[0;32m     86\u001b[0m                 spk_reg\u001b[38;5;241m=\u001b[39mspk_reg,\n\u001b[0;32m     87\u001b[0m                 l1_reg\u001b[38;5;241m=\u001b[39ml1_reg,\n\u001b[0;32m     88\u001b[0m                 dropout\u001b[38;5;241m=\u001b[39mdropout,\n\u001b[0;32m     89\u001b[0m                 verbose\u001b[38;5;241m=\u001b[39mverbose)        \n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     snn\u001b[38;5;241m.\u001b[39mtrain_step_tr(train_loader\u001b[38;5;241m=\u001b[39mtrain_loader, optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m     92\u001b[0m                     criterion\u001b[38;5;241m=\u001b[39msnn\u001b[38;5;241m.\u001b[39mcriterion, spk_reg\u001b[38;5;241m=\u001b[39mspk_reg,\n\u001b[0;32m     93\u001b[0m                     depth\u001b[38;5;241m=\u001b[39mdepth, k\u001b[38;5;241m=\u001b[39mk, last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Python\\SNNdelays\\snn_delays\\snn.py:210\u001b[0m, in \u001b[0;36mTraining.train_step\u001b[1;34m(self, train_loader, optimizer, scheduler, spk_reg, l1_reg, dropout, verbose)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;66;03m# Calculate gradients and optimize to update weights\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_amp:\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[1;32mc:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    523\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    524\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    267\u001b[0m     tensors,\n\u001b[0;32m    268\u001b[0m     grad_tensors_,\n\u001b[0;32m    269\u001b[0m     retain_graph,\n\u001b[0;32m    270\u001b[0m     create_graph,\n\u001b[0;32m    271\u001b[0m     inputs,\n\u001b[0;32m    272\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    273\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    274\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from snn_delays.utils.train_utils import train\n",
    "from snn_delays.utils.test_behavior import tb_save_max_last_acc\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "taimu1 = time.time()\n",
    "\n",
    "tau_m = 'normal'\n",
    "#delay = (48*2,16*2)\n",
    "#delay = (96,32)\n",
    "#delay = None\n",
    "delay = (2, 1)\n",
    "ckpt_dir = 'exp21_STMNIST_memory' \n",
    "\n",
    "snn = SNN(dataset_dict=dataset_dict, structure=(64, 2), connection_type='f',\n",
    "    delay=delay, delay_type='h', tau_m = tau_m,\n",
    "    win=total_time*sequence_length, loss_fn='mem_sum', batch_size=batch_size, device=device,\n",
    "    debug=False)\n",
    "\n",
    "snn.set_network()\n",
    "\n",
    "snn.model_name = f'dvs5_seq{sequence_length}_{delay}'+ snn.model_name\n",
    "\n",
    "snn.to(device)\n",
    "train(snn, train_loader, test_loader, lr, num_epochs, dropout=0.0, \n",
    "    test_behavior=tb_save_max_last_acc, ckpt_dir=ckpt_dir, scheduler=(100, 0.95), test_every=1)\n",
    "\n",
    "print(f'[INFO] TIEMPO: {time.time() - taimu1}', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Delays: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])\n",
      "\n",
      "[INFO] Delays i: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])\n",
      "\n",
      "[INFO] Delays h: tensor([0])\n",
      "\n",
      "[INFO] Delays o: tensor([0])\n",
      "0.001\n",
      "Delta t: 1e-05 ms\n",
      "mean of normal: 14.508657488628742\n",
      "training dvs5_seq100_(50, 1)memorytask100_l2_50d1.t7 for 20 epochs...\n",
      "Epoch [1/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.36547\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.20326\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.20739\n",
      "l1_score: 0\n",
      "Time elasped: 39.742767333984375\n",
      "Test Loss: 2.2190694987773893\n",
      "Avg spk_count per neuron for all 100 time-steps 12.099540710449219\n",
      "Avg spk per neuron per layer [25.838778125, 22.559384375]\n",
      "Test Accuracy of the model on the test samples: 11.280\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0057\n",
      "Gradient norm for 'f0_f1.weight': 0.2346\n",
      "Gradient norm for 'f1_f2.weight': 1.7289\n",
      "Gradient norm for 'f2_o.weight': 12.4592\n",
      "saving max acc: 11.28\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [2/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.25419\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.21064\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.19332\n",
      "l1_score: 0\n",
      "Time elasped: 37.02141737937927\n",
      "Test Loss: 2.200242292881012\n",
      "Avg spk_count per neuron for all 100 time-steps 12.254491806030273\n",
      "Avg spk per neuron per layer [26.16681875, 22.85115]\n",
      "Test Accuracy of the model on the test samples: 11.720\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0035\n",
      "Gradient norm for 'f0_f1.weight': 0.1013\n",
      "Gradient norm for 'f1_f2.weight': 0.8724\n",
      "Gradient norm for 'f2_o.weight': 7.6386\n",
      "saving max acc: 11.72\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [3/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.21783\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.23350\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.19431\n",
      "l1_score: 0\n",
      "Time elasped: 32.37256073951721\n",
      "Test Loss: 2.199161046743393\n",
      "Avg spk_count per neuron for all 100 time-steps 12.153958320617676\n",
      "Avg spk per neuron per layer [25.77039375, 22.845440625]\n",
      "Test Accuracy of the model on the test samples: 12.500\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0070\n",
      "Gradient norm for 'f0_f1.weight': 0.2231\n",
      "Gradient norm for 'f1_f2.weight': 2.6628\n",
      "Gradient norm for 'f2_o.weight': 14.5739\n",
      "saving max acc: 12.5\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [4/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.18645\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.19680\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.24440\n",
      "l1_score: 0\n",
      "Time elasped: 32.64028358459473\n",
      "Test Loss: 2.2214179158210756\n",
      "Avg spk_count per neuron for all 100 time-steps 11.963388442993164\n",
      "Avg spk per neuron per layer [25.488803125, 22.364753125]\n",
      "Test Accuracy of the model on the test samples: 12.440\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0083\n",
      "Gradient norm for 'f0_f1.weight': 0.1324\n",
      "Gradient norm for 'f1_f2.weight': 0.7333\n",
      "Gradient norm for 'f2_o.weight': 5.9818\n",
      "Epoch [5/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.19626\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.21934\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.20128\n",
      "l1_score: 0\n",
      "Time elasped: 33.02108573913574\n",
      "Test Loss: 2.1916652977466584\n",
      "Avg spk_count per neuron for all 100 time-steps 12.278349876403809\n",
      "Avg spk per neuron per layer [25.935921875, 23.177478125]\n",
      "Test Accuracy of the model on the test samples: 12.420\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0043\n",
      "Gradient norm for 'f0_f1.weight': 0.1615\n",
      "Gradient norm for 'f1_f2.weight': 1.2167\n",
      "Gradient norm for 'f2_o.weight': 8.6268\n",
      "Epoch [6/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.20588\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.25600\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.20508\n",
      "l1_score: 0\n",
      "Time elasped: 32.96419811248779\n",
      "Test Loss: 2.1930934250354768\n",
      "Avg spk_count per neuron for all 100 time-steps 12.239413261413574\n",
      "Avg spk per neuron per layer [25.942559375, 23.01509375]\n",
      "Test Accuracy of the model on the test samples: 12.160\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0045\n",
      "Gradient norm for 'f0_f1.weight': 0.1495\n",
      "Gradient norm for 'f1_f2.weight': 1.9260\n",
      "Gradient norm for 'f2_o.weight': 14.3946\n",
      "Epoch [7/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.20687\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.17354\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.19185\n",
      "l1_score: 0\n",
      "Time elasped: 32.518527030944824\n",
      "Test Loss: 2.2197778046131136\n",
      "Avg spk_count per neuron for all 100 time-steps 12.162196159362793\n",
      "Avg spk per neuron per layer [25.71499375, 22.93379375]\n",
      "Test Accuracy of the model on the test samples: 12.020\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0083\n",
      "Gradient norm for 'f0_f1.weight': 0.1287\n",
      "Gradient norm for 'f1_f2.weight': 1.4612\n",
      "Gradient norm for 'f2_o.weight': 12.6142\n",
      "Epoch [8/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.21605\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.18728\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.24092\n",
      "l1_score: 0\n",
      "Time elasped: 33.03675317764282\n",
      "Test Loss: 2.194957309961319\n",
      "Avg spk_count per neuron for all 100 time-steps 12.100093841552734\n",
      "Avg spk per neuron per layer [25.697421875, 22.702953125]\n",
      "Test Accuracy of the model on the test samples: 14.020\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0027\n",
      "Gradient norm for 'f0_f1.weight': 0.0973\n",
      "Gradient norm for 'f1_f2.weight': 0.8572\n",
      "Gradient norm for 'f2_o.weight': 7.1388\n",
      "saving max acc: 14.02\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [9/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.18586\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.16301\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.16129\n",
      "l1_score: 0\n",
      "Time elasped: 32.570135831832886\n",
      "Test Loss: 2.187323433160782\n",
      "Avg spk_count per neuron for all 100 time-steps 12.336634635925293\n",
      "Avg spk per neuron per layer [26.0616, 23.284940625]\n",
      "Test Accuracy of the model on the test samples: 14.160\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0033\n",
      "Gradient norm for 'f0_f1.weight': 0.1906\n",
      "Gradient norm for 'f1_f2.weight': 2.0250\n",
      "Gradient norm for 'f2_o.weight': 12.5972\n",
      "saving max acc: 14.16\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [10/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.20457\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.20226\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.19407\n",
      "l1_score: 0\n",
      "Time elasped: 32.71323585510254\n",
      "Test Loss: 2.2047006726264953\n",
      "Avg spk_count per neuron for all 100 time-steps 12.508389472961426\n",
      "Avg spk per neuron per layer [26.563109375, 23.47045]\n",
      "Test Accuracy of the model on the test samples: 13.740\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0036\n",
      "Gradient norm for 'f0_f1.weight': 0.2104\n",
      "Gradient norm for 'f1_f2.weight': 1.7266\n",
      "Gradient norm for 'f2_o.weight': 11.8894\n",
      "Epoch [11/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.19790\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.16151\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.21630\n",
      "l1_score: 0\n",
      "Time elasped: 32.5895037651062\n",
      "Test Loss: 2.214081919193268\n",
      "Avg spk_count per neuron for all 100 time-steps 12.321168899536133\n",
      "Avg spk per neuron per layer [26.050096875, 23.234578125]\n",
      "Test Accuracy of the model on the test samples: 14.700\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0085\n",
      "Gradient norm for 'f0_f1.weight': 0.1657\n",
      "Gradient norm for 'f1_f2.weight': 1.2185\n",
      "Gradient norm for 'f2_o.weight': 8.6070\n",
      "saving max acc: 14.7\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [12/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.19944\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.22039\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.17059\n",
      "l1_score: 0\n",
      "Time elasped: 32.47383785247803\n",
      "Test Loss: 2.187501072883606\n",
      "Avg spk_count per neuron for all 100 time-steps 12.165608406066895\n",
      "Avg spk per neuron per layer [25.827721875, 22.8347125]\n",
      "Test Accuracy of the model on the test samples: 13.780\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0036\n",
      "Gradient norm for 'f0_f1.weight': 0.2280\n",
      "Gradient norm for 'f1_f2.weight': 1.3443\n",
      "Gradient norm for 'f2_o.weight': 6.4706\n",
      "Epoch [13/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.21685\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.18639\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.17717\n",
      "l1_score: 0\n",
      "Time elasped: 32.48213863372803\n",
      "Test Loss: 2.1864354431629183\n",
      "Avg spk_count per neuron for all 100 time-steps 12.146303176879883\n",
      "Avg spk per neuron per layer [25.796571875, 22.788640625]\n",
      "Test Accuracy of the model on the test samples: 13.360\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0048\n",
      "Gradient norm for 'f0_f1.weight': 0.2234\n",
      "Gradient norm for 'f1_f2.weight': 1.6723\n",
      "Gradient norm for 'f2_o.weight': 9.6847\n",
      "Epoch [14/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.17945\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.21376\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.15822\n",
      "l1_score: 0\n",
      "Time elasped: 32.4344425201416\n",
      "Test Loss: 2.1791738986968996\n",
      "Avg spk_count per neuron for all 100 time-steps 12.24187183380127\n",
      "Avg spk per neuron per layer [26.054240625, 22.913246875]\n",
      "Test Accuracy of the model on the test samples: 14.640\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0026\n",
      "Gradient norm for 'f0_f1.weight': 0.3715\n",
      "Gradient norm for 'f1_f2.weight': 1.5884\n",
      "Gradient norm for 'f2_o.weight': 10.8139\n",
      "Epoch [15/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.18582\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.18817\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.16618\n",
      "l1_score: 0\n",
      "Time elasped: 32.400192737579346\n",
      "Test Loss: 2.186364483833313\n",
      "Avg spk_count per neuron for all 100 time-steps 12.183449745178223\n",
      "Avg spk per neuron per layer [26.0127625, 22.7210375]\n",
      "Test Accuracy of the model on the test samples: 14.800\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0019\n",
      "Gradient norm for 'f0_f1.weight': 0.1299\n",
      "Gradient norm for 'f1_f2.weight': 0.9286\n",
      "Gradient norm for 'f2_o.weight': 6.7669\n",
      "saving max acc: 14.8\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [16/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.14867\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.17051\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.16745\n",
      "l1_score: 0\n",
      "Time elasped: 32.046616554260254\n",
      "Test Loss: 2.1926274359226228\n",
      "Avg spk_count per neuron for all 100 time-steps 12.164231300354004\n",
      "Avg spk per neuron per layer [26.004559375, 22.65236875]\n",
      "Test Accuracy of the model on the test samples: 12.360\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0030\n",
      "Gradient norm for 'f0_f1.weight': 0.1753\n",
      "Gradient norm for 'f1_f2.weight': 0.9984\n",
      "Gradient norm for 'f2_o.weight': 9.7151\n",
      "Epoch [17/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.16783\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.15354\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.18757\n",
      "l1_score: 0\n",
      "Time elasped: 32.82056927680969\n",
      "Test Loss: 2.1890263497829436\n",
      "Avg spk_count per neuron for all 100 time-steps 12.593910217285156\n",
      "Avg spk per neuron per layer [27.4610625, 22.914578125]\n",
      "Test Accuracy of the model on the test samples: 13.220\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0015\n",
      "Gradient norm for 'f0_f1.weight': 0.0954\n",
      "Gradient norm for 'f1_f2.weight': 0.8613\n",
      "Gradient norm for 'f2_o.weight': 5.4190\n",
      "Epoch [18/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.19514\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.16943\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.17406\n",
      "l1_score: 0\n",
      "Time elasped: 32.11387348175049\n",
      "Test Loss: 2.212165528535843\n",
      "Avg spk_count per neuron for all 100 time-steps 12.408044815063477\n",
      "Avg spk per neuron per layer [27.055825, 22.57635625]\n",
      "Test Accuracy of the model on the test samples: 11.260\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0029\n",
      "Gradient norm for 'f0_f1.weight': 0.2457\n",
      "Gradient norm for 'f1_f2.weight': 1.6501\n",
      "Gradient norm for 'f2_o.weight': 12.4894\n",
      "Epoch [19/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.21541\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.18744\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.21197\n",
      "l1_score: 0\n",
      "Time elasped: 32.37272882461548\n",
      "Test Loss: 2.1976171493530274\n",
      "Avg spk_count per neuron for all 100 time-steps 12.332663536071777\n",
      "Avg spk per neuron per layer [26.22910625, 23.10155]\n",
      "Test Accuracy of the model on the test samples: 13.380\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0032\n",
      "Gradient norm for 'f0_f1.weight': 0.3425\n",
      "Gradient norm for 'f1_f2.weight': 2.2101\n",
      "Gradient norm for 'f2_o.weight': 11.0614\n",
      "Epoch [20/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.18484\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.17648\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.17697\n",
      "l1_score: 0\n",
      "Time elasped: 32.39787578582764\n",
      "Test Loss: 2.180153501033783\n",
      "Avg spk_count per neuron for all 100 time-steps 12.193552017211914\n",
      "Avg spk per neuron per layer [25.8053625, 22.968846875]\n",
      "Test Accuracy of the model on the test samples: 14.560\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0012\n",
      "Gradient norm for 'f0_f1.weight': 0.1877\n",
      "Gradient norm for 'f1_f2.weight': 1.1660\n",
      "Gradient norm for 'f2_o.weight': 7.6334\n",
      "[INFO] TIEMPO: 825.5179421901703\n"
     ]
    }
   ],
   "source": [
    "from snn_delays.utils.train_utils import train\n",
    "from snn_delays.utils.test_behavior import tb_save_max_last_acc\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "taimu1 = time.time()\n",
    "\n",
    "tau_m = 'normal'\n",
    "#delay = (48*2,16*2)\n",
    "#delay = (96,32)\n",
    "#delay = None\n",
    "delay = (50, 1)\n",
    "ckpt_dir = 'exp21_STMNIST_memory' \n",
    "\n",
    "snn = SNN(dataset_dict=dataset_dict, structure=(64, 2), connection_type='f',\n",
    "    delay=delay, delay_type='i', tau_m = tau_m,\n",
    "    win=total_time*sequence_length, loss_fn='mem_sum', batch_size=batch_size, device=device,\n",
    "    debug=False)\n",
    "\n",
    "snn.set_network()\n",
    "\n",
    "snn.model_name = f'dvs5_seq{sequence_length}_{delay}'+ snn.model_name\n",
    "\n",
    "snn.to(device)\n",
    "train(snn, train_loader, test_loader, lr, num_epochs, dropout=0.0, \n",
    "    test_behavior=tb_save_max_last_acc, ckpt_dir=ckpt_dir, scheduler=(100, 0.95), test_every=1)\n",
    "\n",
    "print(f'[INFO] TIEMPO: {time.time() - taimu1}', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Delays: tensor([0, 1])\n",
      "\n",
      "[INFO] Delays i: tensor([0, 1])\n",
      "\n",
      "[INFO] Delays h: tensor([0])\n",
      "\n",
      "[INFO] Delays o: tensor([0])\n",
      "0.001\n",
      "Delta t: 1e-05 ms\n",
      "mean of normal: 14.508657488628742\n",
      "training dvs5_seq100_(2, 1)memorytask100_l2_2d1.t7 for 20 epochs...\n",
      "Epoch [1/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.23657\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.23390\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.16834\n",
      "l1_score: 0\n",
      "Time elasped: 35.51646113395691\n",
      "Test Loss: 2.208192455768585\n",
      "Avg spk_count per neuron for all 100 time-steps 10.24219799041748\n",
      "Avg spk per neuron per layer [19.94885, 21.01994375]\n",
      "Test Accuracy of the model on the test samples: 13.340\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0935\n",
      "Gradient norm for 'f0_f1.weight': 0.2520\n",
      "Gradient norm for 'f1_f1.weight': 0.2425\n",
      "Gradient norm for 'f1_f2.weight': 1.6552\n",
      "Gradient norm for 'f2_f2.weight': 1.5989\n",
      "Gradient norm for 'f2_o.weight': 9.1529\n",
      "saving max acc: 13.34\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [2/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.20374\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.21850\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.22395\n",
      "l1_score: 0\n",
      "Time elasped: 36.4575469493866\n",
      "Test Loss: 2.231915068626404\n",
      "Avg spk_count per neuron for all 100 time-steps 10.492958068847656\n",
      "Avg spk per neuron per layer [19.684596875, 22.2872375]\n",
      "Test Accuracy of the model on the test samples: 11.300\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0581\n",
      "Gradient norm for 'f0_f1.weight': 0.2646\n",
      "Gradient norm for 'f1_f1.weight': 0.2572\n",
      "Gradient norm for 'f1_f2.weight': 1.4119\n",
      "Gradient norm for 'f2_f2.weight': 1.4062\n",
      "Gradient norm for 'f2_o.weight': 8.1090\n",
      "Epoch [3/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.22494\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.22800\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.21969\n",
      "l1_score: 0\n",
      "Time elasped: 36.40594530105591\n",
      "Test Loss: 2.203478771448135\n",
      "Avg spk_count per neuron for all 100 time-steps 10.491397857666016\n",
      "Avg spk per neuron per layer [19.122471875, 22.843121875]\n",
      "Test Accuracy of the model on the test samples: 12.580\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0666\n",
      "Gradient norm for 'f0_f1.weight': 0.1426\n",
      "Gradient norm for 'f1_f1.weight': 0.1355\n",
      "Gradient norm for 'f1_f2.weight': 0.9125\n",
      "Gradient norm for 'f2_f2.weight': 0.9586\n",
      "Gradient norm for 'f2_o.weight': 8.5785\n",
      "Epoch [4/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.23706\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.24061\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.20827\n",
      "l1_score: 0\n",
      "Time elasped: 36.08252954483032\n",
      "Test Loss: 2.2040597200393677\n",
      "Avg spk_count per neuron for all 100 time-steps 10.534728050231934\n",
      "Avg spk per neuron per layer [18.952221875, 23.186690625]\n",
      "Test Accuracy of the model on the test samples: 14.480\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0499\n",
      "Gradient norm for 'f0_f1.weight': 0.2977\n",
      "Gradient norm for 'f1_f1.weight': 0.2778\n",
      "Gradient norm for 'f1_f2.weight': 1.9507\n",
      "Gradient norm for 'f2_f2.weight': 2.1049\n",
      "Gradient norm for 'f2_o.weight': 12.8312\n",
      "saving max acc: 14.48\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [5/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.18426\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.24325\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.17389\n",
      "l1_score: 0\n",
      "Time elasped: 36.41534686088562\n",
      "Test Loss: 2.221173197031021\n",
      "Avg spk_count per neuron for all 100 time-steps 10.17790412902832\n",
      "Avg spk per neuron per layer [18.43205625, 22.2795625]\n",
      "Test Accuracy of the model on the test samples: 12.700\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0181\n",
      "Gradient norm for 'f0_f1.weight': 0.1211\n",
      "Gradient norm for 'f1_f1.weight': 0.1133\n",
      "Gradient norm for 'f1_f2.weight': 0.7226\n",
      "Gradient norm for 'f2_f2.weight': 0.7345\n",
      "Gradient norm for 'f2_o.weight': 4.9998\n",
      "Epoch [6/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.17363\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.25378\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.19373\n",
      "l1_score: 0\n",
      "Time elasped: 36.32339525222778\n",
      "Test Loss: 2.193923205137253\n",
      "Avg spk_count per neuron for all 100 time-steps 10.009122848510742\n",
      "Avg spk per neuron per layer [17.884365625, 22.152125]\n",
      "Test Accuracy of the model on the test samples: 12.160\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0342\n",
      "Gradient norm for 'f0_f1.weight': 0.1357\n",
      "Gradient norm for 'f1_f1.weight': 0.1212\n",
      "Gradient norm for 'f1_f2.weight': 0.9959\n",
      "Gradient norm for 'f2_f2.weight': 1.1055\n",
      "Gradient norm for 'f2_o.weight': 8.1051\n",
      "Epoch [7/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.18608\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.15849\n",
      "l1_score: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m snn\u001b[38;5;241m.\u001b[39mmodel_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdvs5_seq\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msequence_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdelay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m snn\u001b[38;5;241m.\u001b[39mmodel_name\n\u001b[0;32m     26\u001b[0m snn\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 27\u001b[0m train(snn, train_loader, test_loader, lr, num_epochs, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, \n\u001b[0;32m     28\u001b[0m     test_behavior\u001b[38;5;241m=\u001b[39mtb_save_max_last_acc, ckpt_dir\u001b[38;5;241m=\u001b[39mckpt_dir, scheduler\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m0.95\u001b[39m), test_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[INFO] TIEMPO: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mtaimu1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Python\\SNNdelays\\snn_delays\\utils\\train_utils.py:83\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(snn, train_loader, test_loader, learning_rate, num_epochs, spk_reg, l1_reg, dropout, lr_tau, scheduler, ckpt_dir, test_behavior, test_every, delay_pruning, weight_pruning, lsm, random_delay_pruning, weight_quantization, k, depth, freeze_taus, verbose)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m], learning_rates \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, num_epochs,\n\u001b[0;32m     79\u001b[0m                                                  current_lr, current_lr_tau), flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m k\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 83\u001b[0m     snn\u001b[38;5;241m.\u001b[39mtrain_step(train_loader,\n\u001b[0;32m     84\u001b[0m                 optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m     85\u001b[0m                 scheduler \u001b[38;5;241m=\u001b[39m scheduler,\n\u001b[0;32m     86\u001b[0m                 spk_reg\u001b[38;5;241m=\u001b[39mspk_reg,\n\u001b[0;32m     87\u001b[0m                 l1_reg\u001b[38;5;241m=\u001b[39ml1_reg,\n\u001b[0;32m     88\u001b[0m                 dropout\u001b[38;5;241m=\u001b[39mdropout,\n\u001b[0;32m     89\u001b[0m                 verbose\u001b[38;5;241m=\u001b[39mverbose)        \n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     snn\u001b[38;5;241m.\u001b[39mtrain_step_tr(train_loader\u001b[38;5;241m=\u001b[39mtrain_loader, optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m     92\u001b[0m                     criterion\u001b[38;5;241m=\u001b[39msnn\u001b[38;5;241m.\u001b[39mcriterion, spk_reg\u001b[38;5;241m=\u001b[39mspk_reg,\n\u001b[0;32m     93\u001b[0m                     depth\u001b[38;5;241m=\u001b[39mdepth, k\u001b[38;5;241m=\u001b[39mk, last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Python\\SNNdelays\\snn_delays\\snn.py:210\u001b[0m, in \u001b[0;36mTraining.train_step\u001b[1;34m(self, train_loader, optimizer, scheduler, spk_reg, l1_reg, dropout, verbose)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;66;03m# Calculate gradients and optimize to update weights\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_amp:\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[1;32mc:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    523\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    524\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    267\u001b[0m     tensors,\n\u001b[0;32m    268\u001b[0m     grad_tensors_,\n\u001b[0;32m    269\u001b[0m     retain_graph,\n\u001b[0;32m    270\u001b[0m     create_graph,\n\u001b[0;32m    271\u001b[0m     inputs,\n\u001b[0;32m    272\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    273\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    274\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from snn_delays.utils.train_utils import train\n",
    "from snn_delays.utils.test_behavior import tb_save_max_last_acc\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "taimu1 = time.time()\n",
    "\n",
    "tau_m = 'normal'\n",
    "#delay = (48*2,16*2)\n",
    "#delay = (96,32)\n",
    "#delay = None\n",
    "delay = (2, 1)\n",
    "ckpt_dir = 'exp21_STMNIST_memory' \n",
    "\n",
    "snn = SNN(dataset_dict=dataset_dict, structure=(64, 2), connection_type='r',\n",
    "    delay=delay, delay_type='i', tau_m = tau_m,\n",
    "    win=total_time*sequence_length, loss_fn='mem_sum', batch_size=batch_size, device=device,\n",
    "    debug=False)\n",
    "\n",
    "snn.set_network()\n",
    "\n",
    "snn.model_name = f'dvs5_seq{sequence_length}_{delay}'+ snn.model_name\n",
    "\n",
    "snn.to(device)\n",
    "train(snn, train_loader, test_loader, lr, num_epochs, dropout=0.0, \n",
    "    test_behavior=tb_save_max_last_acc, ckpt_dir=ckpt_dir, scheduler=(100, 0.95), test_every=1)\n",
    "\n",
    "print(f'[INFO] TIEMPO: {time.time() - taimu1}', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Delays: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59])\n",
      "\n",
      "[INFO] Delays i: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59])\n",
      "\n",
      "[INFO] Delays h: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59])\n",
      "\n",
      "[INFO] Delays o: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59])\n",
      "0.001\n",
      "Delta t: 1e-05 ms\n",
      "mean of normal: 14.508657488628742\n",
      "training dvs5_seq100_(60, 1)memorytask100_l2_60d1.t7 for 20 epochs...\n",
      "Epoch [1/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 6.14971\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.19722\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.19722\n",
      "l1_score: 0\n",
      "Time elasped: 40.43824243545532\n",
      "Test Loss: 2.1972241520881655\n",
      "Avg spk_count per neuron for all 100 time-steps 1.9918889999389648\n",
      "Avg spk per neuron per layer [7.96755625, 0.0]\n",
      "Test Accuracy of the model on the test samples: 12.500\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0000\n",
      "Gradient norm for 'f0_f1.weight': 0.0918\n",
      "Gradient norm for 'f1_f2.weight': 0.1195\n",
      "Gradient norm for 'f2_o.weight': 0.0000\n",
      "saving max acc: 12.5\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [2/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.19722\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.19722\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.19722\n",
      "l1_score: 0\n",
      "Time elasped: 42.511871576309204\n",
      "Test Loss: 2.1972241520881655\n",
      "Avg spk_count per neuron for all 100 time-steps 1.9151546955108643\n",
      "Avg spk per neuron per layer [7.66061875, 0.0]\n",
      "Test Accuracy of the model on the test samples: 12.500\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0000\n",
      "Gradient norm for 'f0_f1.weight': 0.5991\n",
      "Gradient norm for 'f1_f2.weight': 0.5670\n",
      "Gradient norm for 'f2_o.weight': 0.0000\n",
      "saving max acc: 12.5\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [3/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.19722\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.20917\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.19722\n",
      "l1_score: 0\n",
      "Time elasped: 43.48646688461304\n",
      "Test Loss: 2.1972241520881655\n",
      "Avg spk_count per neuron for all 100 time-steps 1.960631251335144\n",
      "Avg spk per neuron per layer [7.842525, 0.0]\n",
      "Test Accuracy of the model on the test samples: 12.500\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0000\n",
      "Gradient norm for 'f0_f1.weight': 0.5963\n",
      "Gradient norm for 'f1_f2.weight': 0.7224\n",
      "Gradient norm for 'f2_o.weight': 0.0000\n",
      "saving max acc: 12.5\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [4/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.19722\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.19722\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.19818\n",
      "l1_score: 0\n",
      "Time elasped: 43.0251681804657\n",
      "Test Loss: 2.1968603670597076\n",
      "Avg spk_count per neuron for all 100 time-steps 1.978136658668518\n",
      "Avg spk per neuron per layer [7.91199375, 0.000553125]\n",
      "Test Accuracy of the model on the test samples: 12.680\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0000\n",
      "Gradient norm for 'f0_f1.weight': 0.3534\n",
      "Gradient norm for 'f1_f2.weight': 0.7388\n",
      "Gradient norm for 'f2_o.weight': 0.0000\n",
      "saving max acc: 12.68\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [5/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.19721\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.19722\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.19756\n",
      "l1_score: 0\n",
      "Time elasped: 44.332172870635986\n",
      "Test Loss: 2.1971440732479097\n",
      "Avg spk_count per neuron for all 100 time-steps 1.8556796312332153\n",
      "Avg spk per neuron per layer [7.422671875, 4.6875e-05]\n",
      "Test Accuracy of the model on the test samples: 12.520\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0000\n",
      "Gradient norm for 'f0_f1.weight': 0.8683\n",
      "Gradient norm for 'f1_f2.weight': 0.9061\n",
      "Gradient norm for 'f2_o.weight': 0.0000\n",
      "Epoch [6/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.19722\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.19903\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.19722\n",
      "l1_score: 0\n",
      "Time elasped: 45.55062437057495\n",
      "Test Loss: 2.1971787929534914\n",
      "Avg spk_count per neuron for all 100 time-steps 1.842252254486084\n",
      "Avg spk per neuron per layer [7.368875, 0.000134375]\n",
      "Test Accuracy of the model on the test samples: 12.380\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0000\n",
      "Gradient norm for 'f0_f1.weight': 0.6801\n",
      "Gradient norm for 'f1_f2.weight': 1.0948\n",
      "Gradient norm for 'f2_o.weight': 0.0000\n",
      "Epoch [7/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.19530\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.19713\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.19788\n",
      "l1_score: 0\n",
      "Time elasped: 45.73906445503235\n",
      "Test Loss: 2.1973788857460024\n",
      "Avg spk_count per neuron for all 100 time-steps 1.9831913709640503\n",
      "Avg spk per neuron per layer [7.9311, 0.001665625]\n",
      "Test Accuracy of the model on the test samples: 12.240\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0000\n",
      "Gradient norm for 'f0_f1.weight': 0.3610\n",
      "Gradient norm for 'f1_f2.weight': 1.2064\n",
      "Gradient norm for 'f2_o.weight': 0.0000\n",
      "Epoch [8/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.19722\n",
      "l1_score: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m snn\u001b[38;5;241m.\u001b[39mmodel_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdvs5_seq\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msequence_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdelay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m snn\u001b[38;5;241m.\u001b[39mmodel_name\n\u001b[0;32m     26\u001b[0m snn\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 27\u001b[0m train(snn, train_loader, test_loader, lr, num_epochs, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, \n\u001b[0;32m     28\u001b[0m     test_behavior\u001b[38;5;241m=\u001b[39mtb_save_max_last_acc, ckpt_dir\u001b[38;5;241m=\u001b[39mckpt_dir, scheduler\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m0.95\u001b[39m), test_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[INFO] TIEMPO: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mtaimu1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Python\\SNNdelays\\snn_delays\\utils\\train_utils.py:83\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(snn, train_loader, test_loader, learning_rate, num_epochs, spk_reg, l1_reg, dropout, lr_tau, scheduler, ckpt_dir, test_behavior, test_every, delay_pruning, weight_pruning, lsm, random_delay_pruning, weight_quantization, k, depth, freeze_taus, verbose)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m], learning_rates \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, num_epochs,\n\u001b[0;32m     79\u001b[0m                                                  current_lr, current_lr_tau), flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m k\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 83\u001b[0m     snn\u001b[38;5;241m.\u001b[39mtrain_step(train_loader,\n\u001b[0;32m     84\u001b[0m                 optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m     85\u001b[0m                 scheduler \u001b[38;5;241m=\u001b[39m scheduler,\n\u001b[0;32m     86\u001b[0m                 spk_reg\u001b[38;5;241m=\u001b[39mspk_reg,\n\u001b[0;32m     87\u001b[0m                 l1_reg\u001b[38;5;241m=\u001b[39ml1_reg,\n\u001b[0;32m     88\u001b[0m                 dropout\u001b[38;5;241m=\u001b[39mdropout,\n\u001b[0;32m     89\u001b[0m                 verbose\u001b[38;5;241m=\u001b[39mverbose)        \n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     snn\u001b[38;5;241m.\u001b[39mtrain_step_tr(train_loader\u001b[38;5;241m=\u001b[39mtrain_loader, optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m     92\u001b[0m                     criterion\u001b[38;5;241m=\u001b[39msnn\u001b[38;5;241m.\u001b[39mcriterion, spk_reg\u001b[38;5;241m=\u001b[39mspk_reg,\n\u001b[0;32m     93\u001b[0m                     depth\u001b[38;5;241m=\u001b[39mdepth, k\u001b[38;5;241m=\u001b[39mk, last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Python\\SNNdelays\\snn_delays\\snn.py:210\u001b[0m, in \u001b[0;36mTraining.train_step\u001b[1;34m(self, train_loader, optimizer, scheduler, spk_reg, l1_reg, dropout, verbose)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;66;03m# Calculate gradients and optimize to update weights\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_amp:\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[1;32mc:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    523\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    524\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    267\u001b[0m     tensors,\n\u001b[0;32m    268\u001b[0m     grad_tensors_,\n\u001b[0;32m    269\u001b[0m     retain_graph,\n\u001b[0;32m    270\u001b[0m     create_graph,\n\u001b[0;32m    271\u001b[0m     inputs,\n\u001b[0;32m    272\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    273\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    274\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from snn_delays.utils.train_utils import train\n",
    "from snn_delays.utils.test_behavior import tb_save_max_last_acc\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "taimu1 = time.time()\n",
    "\n",
    "tau_m = 'normal'\n",
    "#delay = (48*2,16*2)\n",
    "#delay = (96,32)\n",
    "#delay = None\n",
    "delay = (60, 1)\n",
    "ckpt_dir = 'exp21_STMNIST_memory' \n",
    "\n",
    "snn = SNN(dataset_dict=dataset_dict, structure=(64, 2), connection_type='f',\n",
    "    delay=delay, delay_type='iho', tau_m = tau_m,\n",
    "    win=total_time*sequence_length, loss_fn='mem_sum', batch_size=batch_size, device=device,\n",
    "    debug=False)\n",
    "\n",
    "snn.set_network()\n",
    "\n",
    "snn.model_name = f'dvs5_seq{sequence_length}_{delay}'+ snn.model_name\n",
    "\n",
    "snn.to(device)\n",
    "train(snn, train_loader, test_loader, lr, num_epochs, dropout=0.0, \n",
    "    test_behavior=tb_save_max_last_acc, ckpt_dir=ckpt_dir, scheduler=(100, 0.95), test_every=1)\n",
    "\n",
    "print(f'[INFO] TIEMPO: {time.time() - taimu1}', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Delays: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59])\n",
      "\n",
      "[INFO] Delays i: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59])\n",
      "\n",
      "[INFO] Delays h: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59])\n",
      "\n",
      "[INFO] Delays o: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59])\n",
      "0.001\n",
      "Delta t: 1e-05 ms\n",
      "mean of normal: 14.508657488628742\n",
      "training dvs5_seq100_(60, 1)memorytask100_l2_60d1.t7 for 20 epochs...\n",
      "Epoch [1/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.21151\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.20505\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.24020\n",
      "l1_score: 0\n",
      "Time elasped: 38.27680683135986\n",
      "Test Loss: 2.2319489240646364\n",
      "Avg spk_count per neuron for all 100 time-steps 14.423287391662598\n",
      "Avg spk per neuron per layer [29.766146875, 27.927]\n",
      "Test Accuracy of the model on the test samples: 11.000\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.1813\n",
      "Gradient norm for 'f0_f1.weight': 0.0005\n",
      "Gradient norm for 'f1_f2.weight': 0.0047\n",
      "Gradient norm for 'f2_o.weight': 2.4858\n",
      "saving max acc: 11.0\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [2/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.22655\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.23038\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.23277\n",
      "l1_score: 0\n",
      "Time elasped: 43.0621063709259\n",
      "Test Loss: 2.219631177186966\n",
      "Avg spk_count per neuron for all 100 time-steps 13.346650123596191\n",
      "Avg spk per neuron per layer [30.376009375, 23.010590625]\n",
      "Test Accuracy of the model on the test samples: 11.000\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.1109\n",
      "Gradient norm for 'f0_f1.weight': 0.0001\n",
      "Gradient norm for 'f1_f2.weight': 0.0025\n",
      "Gradient norm for 'f2_o.weight': 2.2496\n",
      "saving max acc: 11.0\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [3/20], learning_rates 0.001000, 0.100000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m snn\u001b[38;5;241m.\u001b[39mmodel_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdvs5_seq\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msequence_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdelay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m snn\u001b[38;5;241m.\u001b[39mmodel_name\n\u001b[0;32m     26\u001b[0m snn\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 27\u001b[0m train(snn, train_loader, test_loader, lr, num_epochs, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, \n\u001b[0;32m     28\u001b[0m     test_behavior\u001b[38;5;241m=\u001b[39mtb_save_max_last_acc, ckpt_dir\u001b[38;5;241m=\u001b[39mckpt_dir, scheduler\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m0.95\u001b[39m), test_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[INFO] TIEMPO: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mtaimu1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Python\\SNNdelays\\snn_delays\\utils\\train_utils.py:83\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(snn, train_loader, test_loader, learning_rate, num_epochs, spk_reg, l1_reg, dropout, lr_tau, scheduler, ckpt_dir, test_behavior, test_every, delay_pruning, weight_pruning, lsm, random_delay_pruning, weight_quantization, k, depth, freeze_taus, verbose)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m], learning_rates \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, num_epochs,\n\u001b[0;32m     79\u001b[0m                                                  current_lr, current_lr_tau), flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m k\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 83\u001b[0m     snn\u001b[38;5;241m.\u001b[39mtrain_step(train_loader,\n\u001b[0;32m     84\u001b[0m                 optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m     85\u001b[0m                 scheduler \u001b[38;5;241m=\u001b[39m scheduler,\n\u001b[0;32m     86\u001b[0m                 spk_reg\u001b[38;5;241m=\u001b[39mspk_reg,\n\u001b[0;32m     87\u001b[0m                 l1_reg\u001b[38;5;241m=\u001b[39ml1_reg,\n\u001b[0;32m     88\u001b[0m                 dropout\u001b[38;5;241m=\u001b[39mdropout,\n\u001b[0;32m     89\u001b[0m                 verbose\u001b[38;5;241m=\u001b[39mverbose)        \n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     snn\u001b[38;5;241m.\u001b[39mtrain_step_tr(train_loader\u001b[38;5;241m=\u001b[39mtrain_loader, optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m     92\u001b[0m                     criterion\u001b[38;5;241m=\u001b[39msnn\u001b[38;5;241m.\u001b[39mcriterion, spk_reg\u001b[38;5;241m=\u001b[39mspk_reg,\n\u001b[0;32m     93\u001b[0m                     depth\u001b[38;5;241m=\u001b[39mdepth, k\u001b[38;5;241m=\u001b[39mk, last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Python\\SNNdelays\\snn_delays\\snn.py:210\u001b[0m, in \u001b[0;36mTraining.train_step\u001b[1;34m(self, train_loader, optimizer, scheduler, spk_reg, l1_reg, dropout, verbose)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;66;03m# Calculate gradients and optimize to update weights\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_amp:\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[1;32mc:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    523\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    524\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    267\u001b[0m     tensors,\n\u001b[0;32m    268\u001b[0m     grad_tensors_,\n\u001b[0;32m    269\u001b[0m     retain_graph,\n\u001b[0;32m    270\u001b[0m     create_graph,\n\u001b[0;32m    271\u001b[0m     inputs,\n\u001b[0;32m    272\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    273\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    274\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from snn_delays.utils.train_utils import train\n",
    "from snn_delays.utils.test_behavior import tb_save_max_last_acc\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "taimu1 = time.time()\n",
    "\n",
    "tau_m = 'normal'\n",
    "#delay = (48*2,16*2)\n",
    "#delay = (96,32)\n",
    "#delay = None\n",
    "delay = (60, 1)  \n",
    "ckpt_dir = 'exp21_STMNIST_memory' \n",
    "\n",
    "snn = SNN(dataset_dict=dataset_dict, structure=(64, 2), connection_type='f',\n",
    "    delay=delay, delay_type='iho', tau_m = tau_m,\n",
    "    win=total_time*sequence_length, loss_fn='mem_last', batch_size=batch_size, device=device,\n",
    "    debug=False)\n",
    "\n",
    "snn.set_network()\n",
    "\n",
    "snn.model_name = f'dvs5_seq{sequence_length}_{delay}'+ snn.model_name\n",
    "\n",
    "snn.to(device)\n",
    "train(snn, train_loader, test_loader, lr, num_epochs, dropout=0.0, \n",
    "    test_behavior=tb_save_max_last_acc, ckpt_dir=ckpt_dir, scheduler=(100, 0.95), test_every=1)\n",
    "\n",
    "print(f'[INFO] TIEMPO: {time.time() - taimu1}', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_input': 10, 'num_training_samples': 10000, 'num_output': 9, 'time_ms': 0.001, 'dataset_name': 'memorytask'}\n"
     ]
    }
   ],
   "source": [
    "from snn_delays.datasets.custom_datasets import CustomDataset\n",
    "\n",
    "lbl = [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], \n",
    "         [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]]\n",
    "\n",
    "imgs = [[1, 0, 1, 0, 1, 0, 1, 0, 1, 0],\n",
    "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 1, 1, 1, 1, 1], \n",
    "         [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]]\n",
    "\n",
    "num_samples = 15000\n",
    "\n",
    "data = np.zeros((num_samples, 1, 10))\n",
    "labels = np.zeros((num_samples, 10))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    cl = np.random.randint(4)\n",
    "    data[i] = 0.2*np.random.rand(10) + imgs[cl]\n",
    "    labels[i] = lbl[cl]\n",
    "\n",
    "train_dataset = CustomDataset(data[:10000], labels[:10000])\n",
    "test_dataset = CustomDataset(data[10000:], labels[10000:])\n",
    "\n",
    "dataset_dict = train_dataset.get_train_attributes()\n",
    "\n",
    "target_classes = [1, 3, 8]\n",
    "sequence_length = 30\n",
    "\n",
    "conc_test_dataset = SequentialMemoryRetrievalDataset(test_dataset, sequence_length, target_classes)\n",
    "conc_train_dataset = SequentialMemoryRetrievalDataset(train_dataset, sequence_length, target_classes)\n",
    "\n",
    "train_dataset = MemoryCachedDataset(conc_train_dataset)\n",
    "test_dataset = MemoryCachedDataset(conc_test_dataset)\n",
    "\n",
    "total_time = 1\n",
    "batch_size = 128\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            drop_last=False,\n",
    "                            pin_memory=True,\n",
    "                            num_workers=0)\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            drop_last=False,\n",
    "                            pin_memory=True,\n",
    "                            num_workers=0)\n",
    "\n",
    "dataset_dict[\"num_output\"] = conc_train_dataset.total_combinations\n",
    "dataset_dict[\"num_training_samples\"] = len(conc_train_dataset)\n",
    "dataset_dict[\"time_ms\"] = 1e-3\n",
    "dataset_dict[\"dataset_name\"] = \"memorytask\"\n",
    "\n",
    "print(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Delays: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29])\n",
      "\n",
      "[INFO] Delays i: tensor([0])\n",
      "\n",
      "[INFO] Delays h: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29])\n",
      "\n",
      "[INFO] Delays o: tensor([0])\n",
      "0.001\n",
      "Delta t: 3.3333333333333335e-05 ms\n",
      "mean of normal: 13.304684100858815\n",
      "training dvs5_seq30_(30, 1)memorytask30_l2_30d1.t7 for 20 epochs...\n",
      "Epoch [1/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.19670\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.18870\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.19842\n",
      "l1_score: 0\n",
      "Time elasped: 97.99529337882996\n",
      "Test Loss: 2.1964593648910524\n",
      "Avg spk_count per neuron for all 30 time-steps 3.7133076190948486\n",
      "Avg spk per neuron per layer [8.825028125, 6.028203125]\n",
      "Test Accuracy of the model on the test samples: 11.620\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0040\n",
      "Gradient norm for 'f0_f1.weight': 0.0015\n",
      "Gradient norm for 'f1_f2.weight': 0.0234\n",
      "Gradient norm for 'f2_o.weight': 0.2010\n",
      "saving max acc: 11.62\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [2/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.19957\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.19343\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.18224\n",
      "l1_score: 0\n",
      "Time elasped: 16.199340105056763\n",
      "Test Loss: 2.188773649930954\n",
      "Avg spk_count per neuron for all 30 time-steps 3.6971843242645264\n",
      "Avg spk per neuron per layer [8.360725, 6.4280125]\n",
      "Test Accuracy of the model on the test samples: 13.500\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0130\n",
      "Gradient norm for 'f0_f1.weight': 0.0084\n",
      "Gradient norm for 'f1_f2.weight': 0.0539\n",
      "Gradient norm for 'f2_o.weight': 0.5165\n",
      "saving max acc: 13.5\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [3/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.17951\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.19377\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.18942\n",
      "l1_score: 0\n",
      "Time elasped: 16.95206928253174\n",
      "Test Loss: 2.1780458867549894\n",
      "Avg spk_count per neuron for all 30 time-steps 3.541673421859741\n",
      "Avg spk per neuron per layer [7.72328125, 6.4434125]\n",
      "Test Accuracy of the model on the test samples: 15.780\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0061\n",
      "Gradient norm for 'f0_f1.weight': 0.0107\n",
      "Gradient norm for 'f1_f2.weight': 0.0539\n",
      "Gradient norm for 'f2_o.weight': 0.6783\n",
      "saving max acc: 15.78\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [4/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.15935\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.18774\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.15921\n",
      "l1_score: 0\n",
      "Time elasped: 16.454336643218994\n",
      "Test Loss: 2.1642191469669343\n",
      "Avg spk_count per neuron for all 30 time-steps 3.5495030879974365\n",
      "Avg spk per neuron per layer [7.567528125, 6.630484375]\n",
      "Test Accuracy of the model on the test samples: 17.900\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0100\n",
      "Gradient norm for 'f0_f1.weight': 0.0138\n",
      "Gradient norm for 'f1_f2.weight': 0.0724\n",
      "Gradient norm for 'f2_o.weight': 0.9152\n",
      "saving max acc: 17.9\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [5/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.12941\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.17160\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.13175\n",
      "l1_score: 0\n",
      "Time elasped: 16.58638620376587\n",
      "Test Loss: 2.1428198873996736\n",
      "Avg spk_count per neuron for all 30 time-steps 3.4443295001983643\n",
      "Avg spk per neuron per layer [7.27955625, 6.4977625]\n",
      "Test Accuracy of the model on the test samples: 20.100\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0083\n",
      "Gradient norm for 'f0_f1.weight': 0.0391\n",
      "Gradient norm for 'f1_f2.weight': 0.2055\n",
      "Gradient norm for 'f2_o.weight': 1.5268\n",
      "saving max acc: 20.1\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [6/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.11819\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.11767\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.13166\n",
      "l1_score: 0\n",
      "Time elasped: 17.233098030090332\n",
      "Test Loss: 2.107934612035751\n",
      "Avg spk_count per neuron for all 30 time-steps 3.3290367126464844\n",
      "Avg spk per neuron per layer [7.068328125, 6.24781875]\n",
      "Test Accuracy of the model on the test samples: 26.220\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0089\n",
      "Gradient norm for 'f0_f1.weight': 0.0629\n",
      "Gradient norm for 'f1_f2.weight': 0.2540\n",
      "Gradient norm for 'f2_o.weight': 1.5643\n",
      "saving max acc: 26.22\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [7/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.10657\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.06072\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.07202\n",
      "l1_score: 0\n",
      "Time elasped: 17.378961086273193\n",
      "Test Loss: 2.0809617698192597\n",
      "Avg spk_count per neuron for all 30 time-steps 3.285935163497925\n",
      "Avg spk per neuron per layer [7.0205625, 6.123178125]\n",
      "Test Accuracy of the model on the test samples: 28.760\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0155\n",
      "Gradient norm for 'f0_f1.weight': 0.0748\n",
      "Gradient norm for 'f1_f2.weight': 0.3399\n",
      "Gradient norm for 'f2_o.weight': 3.6626\n",
      "saving max acc: 28.76\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [8/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.02821\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.07602\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.09142\n",
      "l1_score: 0\n",
      "Time elasped: 16.48076033592224\n",
      "Test Loss: 2.092929410934448\n",
      "Avg spk_count per neuron for all 30 time-steps 3.293178081512451\n",
      "Avg spk per neuron per layer [7.037778125, 6.134934375]\n",
      "Test Accuracy of the model on the test samples: 27.420\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0124\n",
      "Gradient norm for 'f0_f1.weight': 0.0468\n",
      "Gradient norm for 'f1_f2.weight': 0.1630\n",
      "Gradient norm for 'f2_o.weight': 1.9433\n",
      "Epoch [9/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.04677\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.06682\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.00187\n",
      "l1_score: 0\n",
      "Time elasped: 16.49551486968994\n",
      "Test Loss: 2.0377852022647858\n",
      "Avg spk_count per neuron for all 30 time-steps 3.276986598968506\n",
      "Avg spk per neuron per layer [7.091353125, 6.01659375]\n",
      "Test Accuracy of the model on the test samples: 34.560\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0316\n",
      "Gradient norm for 'f0_f1.weight': 0.0324\n",
      "Gradient norm for 'f1_f2.weight': 0.1902\n",
      "Gradient norm for 'f2_o.weight': 2.5917\n",
      "saving max acc: 34.56\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [10/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.98409\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.06306\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.04206\n",
      "l1_score: 0\n",
      "Time elasped: 16.571824550628662\n",
      "Test Loss: 2.016733628511429\n",
      "Avg spk_count per neuron for all 30 time-steps 3.302339792251587\n",
      "Avg spk per neuron per layer [7.19665, 6.012709375]\n",
      "Test Accuracy of the model on the test samples: 37.140\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0274\n",
      "Gradient norm for 'f0_f1.weight': 0.0523\n",
      "Gradient norm for 'f1_f2.weight': 0.2757\n",
      "Gradient norm for 'f2_o.weight': 2.3486\n",
      "saving max acc: 37.14\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [11/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.95314\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.98009\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.95523\n",
      "l1_score: 0\n",
      "Time elasped: 16.488875150680542\n",
      "Test Loss: 1.9877310752868653\n",
      "Avg spk_count per neuron for all 30 time-steps 3.327683448791504\n",
      "Avg spk per neuron per layer [7.2654375, 6.045296875]\n",
      "Test Accuracy of the model on the test samples: 40.720\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0087\n",
      "Gradient norm for 'f0_f1.weight': 0.0216\n",
      "Gradient norm for 'f1_f2.weight': 0.1275\n",
      "Gradient norm for 'f2_o.weight': 3.4214\n",
      "saving max acc: 40.72\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [12/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.92057\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.02829\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.93364\n",
      "l1_score: 0\n",
      "Time elasped: 16.553151607513428\n",
      "Test Loss: 1.9725605964660644\n",
      "Avg spk_count per neuron for all 30 time-steps 3.372824192047119\n",
      "Avg spk per neuron per layer [7.368525, 6.122771875]\n",
      "Test Accuracy of the model on the test samples: 42.800\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0059\n",
      "Gradient norm for 'f0_f1.weight': 0.0153\n",
      "Gradient norm for 'f1_f2.weight': 0.1039\n",
      "Gradient norm for 'f2_o.weight': 2.1770\n",
      "saving max acc: 42.8\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [13/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.97433\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.95954\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.96090\n",
      "l1_score: 0\n",
      "Time elasped: 16.764851808547974\n",
      "Test Loss: 1.9440887808799743\n",
      "Avg spk_count per neuron for all 30 time-steps 3.370607614517212\n",
      "Avg spk per neuron per layer [7.382425, 6.10000625]\n",
      "Test Accuracy of the model on the test samples: 47.240\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0050\n",
      "Gradient norm for 'f0_f1.weight': 0.0637\n",
      "Gradient norm for 'f1_f2.weight': 0.4130\n",
      "Gradient norm for 'f2_o.weight': 3.8074\n",
      "saving max acc: 47.24\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [14/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.95026\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.92894\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.97485\n",
      "l1_score: 0\n",
      "Time elasped: 15.876047849655151\n",
      "Test Loss: 1.934510987997055\n",
      "Avg spk_count per neuron for all 30 time-steps 3.4012491703033447\n",
      "Avg spk per neuron per layer [7.472240625, 6.13275625]\n",
      "Test Accuracy of the model on the test samples: 48.180\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0031\n",
      "Gradient norm for 'f0_f1.weight': 0.0233\n",
      "Gradient norm for 'f1_f2.weight': 0.1335\n",
      "Gradient norm for 'f2_o.weight': 3.5151\n",
      "saving max acc: 48.18\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [15/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.91722\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.85915\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.88402\n",
      "l1_score: 0\n",
      "Time elasped: 14.709528684616089\n",
      "Test Loss: 1.9149352490901947\n",
      "Avg spk_count per neuron for all 30 time-steps 3.401000738143921\n",
      "Avg spk per neuron per layer [7.515625, 6.088378125]\n",
      "Test Accuracy of the model on the test samples: 49.920\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0026\n",
      "Gradient norm for 'f0_f1.weight': 0.0611\n",
      "Gradient norm for 'f1_f2.weight': 0.2906\n",
      "Gradient norm for 'f2_o.weight': 2.5144\n",
      "saving max acc: 49.92\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [16/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.84874\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.90587\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.95352\n",
      "l1_score: 0\n",
      "Time elasped: 13.813136339187622\n",
      "Test Loss: 1.9064258456230163\n",
      "Avg spk_count per neuron for all 30 time-steps 3.4074695110321045\n",
      "Avg spk per neuron per layer [7.563309375, 6.06656875]\n",
      "Test Accuracy of the model on the test samples: 49.800\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0006\n",
      "Gradient norm for 'f0_f1.weight': 0.0487\n",
      "Gradient norm for 'f1_f2.weight': 0.2535\n",
      "Gradient norm for 'f2_o.weight': 2.1635\n",
      "Epoch [17/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.94289\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.90723\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.87161\n",
      "l1_score: 0\n",
      "Time elasped: 14.571319580078125\n",
      "Test Loss: 1.9160451680421828\n",
      "Avg spk_count per neuron for all 30 time-steps 3.4314217567443848\n",
      "Avg spk per neuron per layer [7.64626875, 6.07941875]\n",
      "Test Accuracy of the model on the test samples: 49.080\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0026\n",
      "Gradient norm for 'f0_f1.weight': 0.0317\n",
      "Gradient norm for 'f1_f2.weight': 0.1492\n",
      "Gradient norm for 'f2_o.weight': 3.0298\n",
      "Epoch [18/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.89268\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.86233\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.83035\n",
      "l1_score: 0\n",
      "Time elasped: 14.393078565597534\n",
      "Test Loss: 1.8930114150047301\n",
      "Avg spk_count per neuron for all 30 time-steps 3.431624174118042\n",
      "Avg spk per neuron per layer [7.658278125, 6.06821875]\n",
      "Test Accuracy of the model on the test samples: 50.660\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0020\n",
      "Gradient norm for 'f0_f1.weight': 0.0472\n",
      "Gradient norm for 'f1_f2.weight': 0.2334\n",
      "Gradient norm for 'f2_o.weight': 2.8901\n",
      "saving max acc: 50.66\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [19/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.80943\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.91436\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.86759\n",
      "l1_score: 0\n",
      "Time elasped: 14.691579341888428\n",
      "Test Loss: 1.8924178212881089\n",
      "Avg spk_count per neuron for all 30 time-steps 3.4097139835357666\n",
      "Avg spk per neuron per layer [7.591984375, 6.046871875]\n",
      "Test Accuracy of the model on the test samples: 50.400\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0014\n",
      "Gradient norm for 'f0_f1.weight': 0.0729\n",
      "Gradient norm for 'f1_f2.weight': 0.3565\n",
      "Gradient norm for 'f2_o.weight': 2.6292\n",
      "Epoch [20/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.94810\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.85455\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.83437\n",
      "l1_score: 0\n",
      "Time elasped: 17.487770795822144\n",
      "Test Loss: 1.8835926741361617\n",
      "Avg spk_count per neuron for all 30 time-steps 3.421825647354126\n",
      "Avg spk per neuron per layer [7.593721875, 6.09358125]\n",
      "Test Accuracy of the model on the test samples: 51.140\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0018\n",
      "Gradient norm for 'f0_f1.weight': 0.0248\n",
      "Gradient norm for 'f1_f2.weight': 0.1606\n",
      "Gradient norm for 'f2_o.weight': 3.0166\n",
      "saving max acc: 51.14\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "[INFO] TIEMPO: 501.2457540035248\n"
     ]
    }
   ],
   "source": [
    "from snn_delays.utils.train_utils import train\n",
    "from snn_delays.utils.test_behavior import tb_save_max_last_acc\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "taimu1 = time.time()\n",
    "\n",
    "tau_m = 'normal'\n",
    "#delay = (48*2,16*2)\n",
    "#delay = (96,32)\n",
    "#delay = None\n",
    "delay = (30, 1)  \n",
    "ckpt_dir = 'exp21_STMNIST_memory' \n",
    "\n",
    "snn = SNN(dataset_dict=dataset_dict, structure=(64, 2), connection_type='f',\n",
    "    delay=delay, delay_type='h', tau_m = tau_m,\n",
    "    win=total_time*sequence_length, loss_fn='mem_last', batch_size=batch_size, device=device,\n",
    "    debug=False)\n",
    "\n",
    "snn.set_network()\n",
    "\n",
    "snn.model_name = f'dvs5_seq{sequence_length}_{delay}'+ snn.model_name\n",
    "\n",
    "snn.to(device)\n",
    "train(snn, train_loader, test_loader, lr, num_epochs, dropout=0.0, \n",
    "    test_behavior=tb_save_max_last_acc, ckpt_dir=ckpt_dir, scheduler=(100, 0.95), test_every=1)\n",
    "\n",
    "print(f'[INFO] TIEMPO: {time.time() - taimu1}', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Delays: tensor([0])\n",
      "\n",
      "[INFO] Delays i: tensor([0])\n",
      "\n",
      "[INFO] Delays h: tensor([0])\n",
      "\n",
      "[INFO] Delays o: tensor([0])\n",
      "0.001\n",
      "Delta t: 3.3333333333333335e-05 ms\n",
      "mean of normal: 13.304684100858815\n",
      "training dvs5_seq30_Nonememorytask30_l2_1d1.t7 for 20 epochs...\n",
      "Epoch [1/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.18826\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.17129\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.16076\n",
      "l1_score: 0\n",
      "Time elasped: 20.648401737213135\n",
      "Test Loss: 2.1862941086292267\n",
      "Avg spk_count per neuron for all 30 time-steps 3.7816593647003174\n",
      "Avg spk per neuron per layer [7.9062875, 7.22035]\n",
      "Test Accuracy of the model on the test samples: 15.480\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0481\n",
      "Gradient norm for 'f0_f1.weight': 0.0343\n",
      "Gradient norm for 'f1_f1.weight': 0.0580\n",
      "Gradient norm for 'f1_f2.weight': 0.2937\n",
      "Gradient norm for 'f2_f2.weight': 0.2736\n",
      "Gradient norm for 'f2_o.weight': 1.5877\n",
      "saving max acc: 15.48\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [2/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.17195\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.18191\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.11515\n",
      "l1_score: 0\n",
      "Time elasped: 20.999359130859375\n",
      "Test Loss: 2.15152251124382\n",
      "Avg spk_count per neuron for all 30 time-steps 3.9329607486724854\n",
      "Avg spk per neuron per layer [7.86728125, 7.8645625]\n",
      "Test Accuracy of the model on the test samples: 20.700\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0197\n",
      "Gradient norm for 'f0_f1.weight': 0.0298\n",
      "Gradient norm for 'f1_f1.weight': 0.0496\n",
      "Gradient norm for 'f1_f2.weight': 0.2093\n",
      "Gradient norm for 'f2_f2.weight': 0.2099\n",
      "Gradient norm for 'f2_o.weight': 1.1472\n",
      "saving max acc: 20.7\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [3/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.20047\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.13703\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.16051\n",
      "l1_score: 0\n",
      "Time elasped: 20.54591703414917\n",
      "Test Loss: 2.1459882259368896\n",
      "Avg spk_count per neuron for all 30 time-steps 4.122529029846191\n",
      "Avg spk per neuron per layer [8.167946875, 8.32216875]\n",
      "Test Accuracy of the model on the test samples: 20.420\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0183\n",
      "Gradient norm for 'f0_f1.weight': 0.0548\n",
      "Gradient norm for 'f1_f1.weight': 0.0882\n",
      "Gradient norm for 'f1_f2.weight': 0.2681\n",
      "Gradient norm for 'f2_f2.weight': 0.2760\n",
      "Gradient norm for 'f2_o.weight': 1.7772\n",
      "Epoch [4/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.14465\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.09978\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.05165\n",
      "l1_score: 0\n",
      "Time elasped: 20.93773865699768\n",
      "Test Loss: 2.0386238634586333\n",
      "Avg spk_count per neuron for all 30 time-steps 4.587065696716309\n",
      "Avg spk per neuron per layer [8.38766875, 9.96059375]\n",
      "Test Accuracy of the model on the test samples: 32.280\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0149\n",
      "Gradient norm for 'f0_f1.weight': 0.0188\n",
      "Gradient norm for 'f1_f1.weight': 0.0311\n",
      "Gradient norm for 'f1_f2.weight': 0.1860\n",
      "Gradient norm for 'f2_f2.weight': 0.2049\n",
      "Gradient norm for 'f2_o.weight': 1.7451\n",
      "saving max acc: 32.28\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [5/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.00195\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.02518\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.88598\n",
      "l1_score: 0\n",
      "Time elasped: 20.678823947906494\n",
      "Test Loss: 1.9023239463567734\n",
      "Avg spk_count per neuron for all 30 time-steps 4.883108615875244\n",
      "Avg spk per neuron per layer [8.99175625, 10.540678125]\n",
      "Test Accuracy of the model on the test samples: 48.860\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0280\n",
      "Gradient norm for 'f0_f1.weight': 0.0528\n",
      "Gradient norm for 'f1_f1.weight': 0.0966\n",
      "Gradient norm for 'f1_f2.weight': 0.4209\n",
      "Gradient norm for 'f2_f2.weight': 0.4379\n",
      "Gradient norm for 'f2_o.weight': 3.0222\n",
      "saving max acc: 48.86\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [6/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.89971\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.85182\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.79703\n",
      "l1_score: 0\n",
      "Time elasped: 21.43235683441162\n",
      "Test Loss: 1.7945475935935975\n",
      "Avg spk_count per neuron for all 30 time-steps 4.893069267272949\n",
      "Avg spk per neuron per layer [9.2045375, 10.367740625]\n",
      "Test Accuracy of the model on the test samples: 59.460\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0096\n",
      "Gradient norm for 'f0_f1.weight': 0.0142\n",
      "Gradient norm for 'f1_f1.weight': 0.0254\n",
      "Gradient norm for 'f1_f2.weight': 0.1998\n",
      "Gradient norm for 'f2_f2.weight': 0.2155\n",
      "Gradient norm for 'f2_o.weight': 1.5530\n",
      "saving max acc: 59.46\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [7/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.80623\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.82338\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.82196\n",
      "l1_score: 0\n",
      "Time elasped: 20.056244611740112\n",
      "Test Loss: 1.7616123646497726\n",
      "Avg spk_count per neuron for all 30 time-steps 5.080373287200928\n",
      "Avg spk per neuron per layer [9.579959375, 10.741534375]\n",
      "Test Accuracy of the model on the test samples: 63.120\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0443\n",
      "Gradient norm for 'f0_f1.weight': 0.0538\n",
      "Gradient norm for 'f1_f1.weight': 0.1026\n",
      "Gradient norm for 'f1_f2.weight': 0.4051\n",
      "Gradient norm for 'f2_f2.weight': 0.4216\n",
      "Gradient norm for 'f2_o.weight': 3.3330\n",
      "saving max acc: 63.12\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [8/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.73928\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.69619\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.80350\n",
      "l1_score: 0\n",
      "Time elasped: 20.775973558425903\n",
      "Test Loss: 1.766859656572342\n",
      "Avg spk_count per neuron for all 30 time-steps 5.26627779006958\n",
      "Avg spk per neuron per layer [9.737796875, 11.327315625]\n",
      "Test Accuracy of the model on the test samples: 61.340\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0415\n",
      "Gradient norm for 'f0_f1.weight': 0.0433\n",
      "Gradient norm for 'f1_f1.weight': 0.0851\n",
      "Gradient norm for 'f1_f2.weight': 0.3720\n",
      "Gradient norm for 'f2_f2.weight': 0.3752\n",
      "Gradient norm for 'f2_o.weight': 2.8682\n",
      "Epoch [9/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.80289\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.71159\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.68475\n",
      "l1_score: 0\n",
      "Time elasped: 20.53453040122986\n",
      "Test Loss: 1.7479254752397537\n",
      "Avg spk_count per neuron for all 30 time-steps 5.244052886962891\n",
      "Avg spk per neuron per layer [9.83035625, 11.14585625]\n",
      "Test Accuracy of the model on the test samples: 63.700\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0095\n",
      "Gradient norm for 'f0_f1.weight': 0.0347\n",
      "Gradient norm for 'f1_f1.weight': 0.0656\n",
      "Gradient norm for 'f1_f2.weight': 0.2740\n",
      "Gradient norm for 'f2_f2.weight': 0.2835\n",
      "Gradient norm for 'f2_o.weight': 1.8947\n",
      "saving max acc: 63.7\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [10/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.67443\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.74749\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.75271\n",
      "l1_score: 0\n",
      "Time elasped: 20.91457509994507\n",
      "Test Loss: 1.6838579714298247\n",
      "Avg spk_count per neuron for all 30 time-steps 5.333418846130371\n",
      "Avg spk per neuron per layer [9.816740625, 11.516934375]\n",
      "Test Accuracy of the model on the test samples: 69.620\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0169\n",
      "Gradient norm for 'f0_f1.weight': 0.0194\n",
      "Gradient norm for 'f1_f1.weight': 0.0353\n",
      "Gradient norm for 'f1_f2.weight': 0.4184\n",
      "Gradient norm for 'f2_f2.weight': 0.4604\n",
      "Gradient norm for 'f2_o.weight': 2.7530\n",
      "saving max acc: 69.62\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [11/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.69524\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.67495\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.69898\n",
      "l1_score: 0\n",
      "Time elasped: 20.89105463027954\n",
      "Test Loss: 1.6676774829626084\n",
      "Avg spk_count per neuron for all 30 time-steps 5.369929313659668\n",
      "Avg spk per neuron per layer [9.821453125, 11.658265625]\n",
      "Test Accuracy of the model on the test samples: 71.380\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0109\n",
      "Gradient norm for 'f0_f1.weight': 0.0381\n",
      "Gradient norm for 'f1_f1.weight': 0.0736\n",
      "Gradient norm for 'f1_f2.weight': 0.4411\n",
      "Gradient norm for 'f2_f2.weight': 0.4770\n",
      "Gradient norm for 'f2_o.weight': 2.0495\n",
      "saving max acc: 71.38\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [12/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.69047\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.70537\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.75474\n",
      "l1_score: 0\n",
      "Time elasped: 21.594558238983154\n",
      "Test Loss: 1.6801142603158952\n",
      "Avg spk_count per neuron for all 30 time-steps 5.438457012176514\n",
      "Avg spk per neuron per layer [9.73634375, 12.017484375]\n",
      "Test Accuracy of the model on the test samples: 70.340\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0532\n",
      "Gradient norm for 'f0_f1.weight': 0.0517\n",
      "Gradient norm for 'f1_f1.weight': 0.0970\n",
      "Gradient norm for 'f1_f2.weight': 0.5668\n",
      "Gradient norm for 'f2_f2.weight': 0.6584\n",
      "Gradient norm for 'f2_o.weight': 3.7665\n",
      "Epoch [13/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.63416\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.61234\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.70221\n",
      "l1_score: 0\n",
      "Time elasped: 20.799959659576416\n",
      "Test Loss: 1.6534647732973098\n",
      "Avg spk_count per neuron for all 30 time-steps 5.432966232299805\n",
      "Avg spk per neuron per layer [9.74535625, 11.986509375]\n",
      "Test Accuracy of the model on the test samples: 73.720\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0217\n",
      "Gradient norm for 'f0_f1.weight': 0.0415\n",
      "Gradient norm for 'f1_f1.weight': 0.0741\n",
      "Gradient norm for 'f1_f2.weight': 0.4053\n",
      "Gradient norm for 'f2_f2.weight': 0.4302\n",
      "Gradient norm for 'f2_o.weight': 3.7195\n",
      "saving max acc: 73.72\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [14/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.67277\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.64971\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.62233\n",
      "l1_score: 0\n",
      "Time elasped: 20.428079843521118\n",
      "Test Loss: 1.644872561097145\n",
      "Avg spk_count per neuron for all 30 time-steps 5.4639434814453125\n",
      "Avg spk per neuron per layer [9.757596875, 12.098178125]\n",
      "Test Accuracy of the model on the test samples: 74.940\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0187\n",
      "Gradient norm for 'f0_f1.weight': 0.0403\n",
      "Gradient norm for 'f1_f1.weight': 0.0783\n",
      "Gradient norm for 'f1_f2.weight': 0.5631\n",
      "Gradient norm for 'f2_f2.weight': 0.6156\n",
      "Gradient norm for 'f2_o.weight': 3.4613\n",
      "saving max acc: 74.94\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [15/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.65656\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.62320\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.62863\n",
      "l1_score: 0\n",
      "Time elasped: 20.80392098426819\n",
      "Test Loss: 1.6393688112497329\n",
      "Avg spk_count per neuron for all 30 time-steps 5.492506980895996\n",
      "Avg spk per neuron per layer [9.854528125, 12.1155]\n",
      "Test Accuracy of the model on the test samples: 73.920\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0013\n",
      "Gradient norm for 'f0_f1.weight': 0.0039\n",
      "Gradient norm for 'f1_f1.weight': 0.0077\n",
      "Gradient norm for 'f1_f2.weight': 0.0360\n",
      "Gradient norm for 'f2_f2.weight': 0.0390\n",
      "Gradient norm for 'f2_o.weight': 0.2681\n",
      "Epoch [16/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.64622\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.61088\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.64169\n",
      "l1_score: 0\n",
      "Time elasped: 20.456949472427368\n",
      "Test Loss: 1.631011900305748\n",
      "Avg spk_count per neuron for all 30 time-steps 5.5011115074157715\n",
      "Avg spk per neuron per layer [9.862190625, 12.14225625]\n",
      "Test Accuracy of the model on the test samples: 74.940\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0016\n",
      "Gradient norm for 'f0_f1.weight': 0.0030\n",
      "Gradient norm for 'f1_f1.weight': 0.0052\n",
      "Gradient norm for 'f1_f2.weight': 0.0370\n",
      "Gradient norm for 'f2_f2.weight': 0.0385\n",
      "Gradient norm for 'f2_o.weight': 0.3680\n",
      "saving max acc: 74.94\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [17/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.65368\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.59144\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.68470\n",
      "l1_score: 0\n",
      "Time elasped: 22.393908739089966\n",
      "Test Loss: 1.633853369951248\n",
      "Avg spk_count per neuron for all 30 time-steps 5.499377250671387\n",
      "Avg spk per neuron per layer [9.92278125, 12.074728125]\n",
      "Test Accuracy of the model on the test samples: 75.140\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0466\n",
      "Gradient norm for 'f0_f1.weight': 0.0214\n",
      "Gradient norm for 'f1_f1.weight': 0.0422\n",
      "Gradient norm for 'f1_f2.weight': 0.2414\n",
      "Gradient norm for 'f2_f2.weight': 0.2751\n",
      "Gradient norm for 'f2_o.weight': 1.7724\n",
      "saving max acc: 75.14\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [18/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.62871\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.66901\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.62587\n",
      "l1_score: 0\n",
      "Time elasped: 19.974026679992676\n",
      "Test Loss: 1.630870446562767\n",
      "Avg spk_count per neuron for all 30 time-steps 5.549797534942627\n",
      "Avg spk per neuron per layer [9.894165625, 12.305025]\n",
      "Test Accuracy of the model on the test samples: 75.360\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0072\n",
      "Gradient norm for 'f0_f1.weight': 0.0171\n",
      "Gradient norm for 'f1_f1.weight': 0.0337\n",
      "Gradient norm for 'f1_f2.weight': 0.2054\n",
      "Gradient norm for 'f2_f2.weight': 0.2327\n",
      "Gradient norm for 'f2_o.weight': 2.2060\n",
      "saving max acc: 75.36\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [19/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.67459\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.65381\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.69030\n",
      "l1_score: 0\n",
      "Time elasped: 17.997719526290894\n",
      "Test Loss: 1.6312135457992554\n",
      "Avg spk_count per neuron for all 30 time-steps 5.56488561630249\n",
      "Avg spk per neuron per layer [9.851884375, 12.407659375]\n",
      "Test Accuracy of the model on the test samples: 75.280\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0050\n",
      "Gradient norm for 'f0_f1.weight': 0.0020\n",
      "Gradient norm for 'f1_f1.weight': 0.0038\n",
      "Gradient norm for 'f1_f2.weight': 0.0439\n",
      "Gradient norm for 'f2_f2.weight': 0.0541\n",
      "Gradient norm for 'f2_o.weight': 0.5433\n",
      "Epoch [20/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.66692\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.67028\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.60486\n",
      "l1_score: 0\n",
      "Time elasped: 17.671992301940918\n",
      "Test Loss: 1.6311828702688218\n",
      "Avg spk_count per neuron for all 30 time-steps 5.542205333709717\n",
      "Avg spk per neuron per layer [9.8107125, 12.358109375]\n",
      "Test Accuracy of the model on the test samples: 75.360\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0131\n",
      "Gradient norm for 'f0_f1.weight': 0.0078\n",
      "Gradient norm for 'f1_f1.weight': 0.0146\n",
      "Gradient norm for 'f1_f2.weight': 0.1064\n",
      "Gradient norm for 'f2_f2.weight': 0.1188\n",
      "Gradient norm for 'f2_o.weight': 1.7297\n",
      "saving max acc: 75.36\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "[INFO] TIEMPO: 493.0847861766815\n"
     ]
    }
   ],
   "source": [
    "from snn_delays.utils.train_utils import train\n",
    "from snn_delays.utils.test_behavior import tb_save_max_last_acc\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "taimu1 = time.time()\n",
    "\n",
    "tau_m = 'normal'\n",
    "#delay = (48*2,16*2)\n",
    "#delay = (96,32)\n",
    "delay = None\n",
    "#delay = (30, 1)  \n",
    "ckpt_dir = 'exp21_STMNIST_memory' \n",
    "\n",
    "snn = SNN(dataset_dict=dataset_dict, structure=(64, 2), connection_type='r',\n",
    "    delay=delay, delay_type='h', tau_m = tau_m,\n",
    "    win=total_time*sequence_length, loss_fn='mem_last', batch_size=batch_size, device=device,\n",
    "    debug=False)\n",
    "\n",
    "snn.set_network()\n",
    "\n",
    "snn.model_name = f'dvs5_seq{sequence_length}_{delay}'+ snn.model_name\n",
    "\n",
    "snn.to(device)\n",
    "train(snn, train_loader, test_loader, lr, num_epochs, dropout=0.0, \n",
    "    test_behavior=tb_save_max_last_acc, ckpt_dir=ckpt_dir, scheduler=(100, 0.95), test_every=1)\n",
    "\n",
    "print(f'[INFO] TIEMPO: {time.time() - taimu1}', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Delays: tensor([0, 1, 2])\n",
      "\n",
      "[INFO] Delays i: tensor([0])\n",
      "\n",
      "[INFO] Delays h: tensor([0, 1, 2])\n",
      "\n",
      "[INFO] Delays o: tensor([0])\n",
      "0.001\n",
      "Delta t: 3.3333333333333335e-05 ms\n",
      "mean of normal: 13.304684100858815\n",
      "training dvs5_seq30_(3, 1)memorytask30_l2_3d1.t7 for 20 epochs...\n",
      "Epoch [1/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.19557\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.20186\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.19354\n",
      "l1_score: 0\n",
      "Time elasped: 12.638879299163818\n",
      "Test Loss: 2.1995633006095887\n",
      "Avg spk_count per neuron for all 30 time-steps 5.359065532684326\n",
      "Avg spk per neuron per layer [9.040584375, 12.395678125]\n",
      "Test Accuracy of the model on the test samples: 10.900\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0075\n",
      "Gradient norm for 'f0_f1.weight': 0.0005\n",
      "Gradient norm for 'f1_f1.weight': 0.0015\n",
      "Gradient norm for 'f1_f2.weight': 0.0112\n",
      "Gradient norm for 'f2_f2.weight': 0.0144\n",
      "Gradient norm for 'f2_o.weight': 0.2489\n",
      "saving max acc: 10.9\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [2/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.19232\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.19867\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.19626\n",
      "l1_score: 0\n",
      "Time elasped: 13.521333694458008\n",
      "Test Loss: 2.197208023071289\n",
      "Avg spk_count per neuron for all 30 time-steps 4.848240375518799\n",
      "Avg spk per neuron per layer [7.981371875, 11.411590625]\n",
      "Test Accuracy of the model on the test samples: 11.780\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0032\n",
      "Gradient norm for 'f0_f1.weight': 0.0013\n",
      "Gradient norm for 'f1_f1.weight': 0.0039\n",
      "Gradient norm for 'f1_f2.weight': 0.0165\n",
      "Gradient norm for 'f2_f2.weight': 0.0220\n",
      "Gradient norm for 'f2_o.weight': 0.1442\n",
      "saving max acc: 11.78\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [3/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.18548\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.19283\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.18546\n",
      "l1_score: 0\n",
      "Time elasped: 13.640610456466675\n",
      "Test Loss: 2.181896710395813\n",
      "Avg spk_count per neuron for all 30 time-steps 5.200657844543457\n",
      "Avg spk per neuron per layer [9.254696875, 11.547934375]\n",
      "Test Accuracy of the model on the test samples: 15.360\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0179\n",
      "Gradient norm for 'f0_f1.weight': 0.0045\n",
      "Gradient norm for 'f1_f1.weight': 0.0144\n",
      "Gradient norm for 'f1_f2.weight': 0.0478\n",
      "Gradient norm for 'f2_f2.weight': 0.0665\n",
      "Gradient norm for 'f2_o.weight': 0.4848\n",
      "saving max acc: 15.36\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [4/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.18985\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.17449\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.14759\n",
      "l1_score: 0\n",
      "Time elasped: 15.608816385269165\n",
      "Test Loss: 2.174654597043991\n",
      "Avg spk_count per neuron for all 30 time-steps 5.139607906341553\n",
      "Avg spk per neuron per layer [9.9984875, 10.55994375]\n",
      "Test Accuracy of the model on the test samples: 15.140\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0357\n",
      "Gradient norm for 'f0_f1.weight': 0.0051\n",
      "Gradient norm for 'f1_f1.weight': 0.0162\n",
      "Gradient norm for 'f1_f2.weight': 0.0487\n",
      "Gradient norm for 'f2_f2.weight': 0.0572\n",
      "Gradient norm for 'f2_o.weight': 0.2538\n",
      "Epoch [5/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.19837\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.18394\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.16023\n",
      "l1_score: 0\n",
      "Time elasped: 21.360496520996094\n",
      "Test Loss: 2.1670025646686555\n",
      "Avg spk_count per neuron for all 30 time-steps 5.06919527053833\n",
      "Avg spk per neuron per layer [9.866015625, 10.410765625]\n",
      "Test Accuracy of the model on the test samples: 17.380\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0070\n",
      "Gradient norm for 'f0_f1.weight': 0.0063\n",
      "Gradient norm for 'f1_f1.weight': 0.0205\n",
      "Gradient norm for 'f1_f2.weight': 0.0597\n",
      "Gradient norm for 'f2_f2.weight': 0.0742\n",
      "Gradient norm for 'f2_o.weight': 0.8417\n",
      "saving max acc: 17.38\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [6/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.16351\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.12740\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.11733\n",
      "l1_score: 0\n",
      "Time elasped: 20.871419191360474\n",
      "Test Loss: 2.117825525999069\n",
      "Avg spk_count per neuron for all 30 time-steps 5.264767646789551\n",
      "Avg spk per neuron per layer [11.463509375, 9.5955625]\n",
      "Test Accuracy of the model on the test samples: 24.780\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0127\n",
      "Gradient norm for 'f0_f1.weight': 0.0083\n",
      "Gradient norm for 'f1_f1.weight': 0.0304\n",
      "Gradient norm for 'f1_f2.weight': 0.1381\n",
      "Gradient norm for 'f2_f2.weight': 0.1366\n",
      "Gradient norm for 'f2_o.weight': 1.7087\n",
      "saving max acc: 24.78\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [7/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.11148\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 2.12129\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 2.09576\n",
      "l1_score: 0\n",
      "Time elasped: 21.100066900253296\n",
      "Test Loss: 2.0316188275814056\n",
      "Avg spk_count per neuron for all 30 time-steps 5.254612445831299\n",
      "Avg spk per neuron per layer [11.40253125, 9.61591875]\n",
      "Test Accuracy of the model on the test samples: 35.660\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0453\n",
      "Gradient norm for 'f0_f1.weight': 0.0198\n",
      "Gradient norm for 'f1_f1.weight': 0.0637\n",
      "Gradient norm for 'f1_f2.weight': 0.3524\n",
      "Gradient norm for 'f2_f2.weight': 0.3334\n",
      "Gradient norm for 'f2_o.weight': 3.6444\n",
      "saving max acc: 35.66\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [8/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 2.02745\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.96695\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.92147\n",
      "l1_score: 0\n",
      "Time elasped: 20.50830864906311\n",
      "Test Loss: 1.9872283577919005\n",
      "Avg spk_count per neuron for all 30 time-steps 5.147709846496582\n",
      "Avg spk per neuron per layer [10.95175625, 9.639084375]\n",
      "Test Accuracy of the model on the test samples: 39.660\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0353\n",
      "Gradient norm for 'f0_f1.weight': 0.0272\n",
      "Gradient norm for 'f1_f1.weight': 0.0811\n",
      "Gradient norm for 'f1_f2.weight': 0.4503\n",
      "Gradient norm for 'f2_f2.weight': 0.4071\n",
      "Gradient norm for 'f2_o.weight': 5.1943\n",
      "saving max acc: 39.66\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [9/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.91408\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.91286\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.92169\n",
      "l1_score: 0\n",
      "Time elasped: 20.319729566574097\n",
      "Test Loss: 1.9620930224657058\n",
      "Avg spk_count per neuron for all 30 time-steps 5.16888427734375\n",
      "Avg spk per neuron per layer [10.9611625, 9.714375]\n",
      "Test Accuracy of the model on the test samples: 42.640\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0332\n",
      "Gradient norm for 'f0_f1.weight': 0.0260\n",
      "Gradient norm for 'f1_f1.weight': 0.0889\n",
      "Gradient norm for 'f1_f2.weight': 0.3842\n",
      "Gradient norm for 'f2_f2.weight': 0.3982\n",
      "Gradient norm for 'f2_o.weight': 2.6300\n",
      "saving max acc: 42.64\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [10/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.93048\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.89754\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.84569\n",
      "l1_score: 0\n",
      "Time elasped: 21.6019184589386\n",
      "Test Loss: 1.8946390688419341\n",
      "Avg spk_count per neuron for all 30 time-steps 5.096236705780029\n",
      "Avg spk per neuron per layer [11.0532625, 9.331684375]\n",
      "Test Accuracy of the model on the test samples: 52.300\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0620\n",
      "Gradient norm for 'f0_f1.weight': 0.0182\n",
      "Gradient norm for 'f1_f1.weight': 0.0704\n",
      "Gradient norm for 'f1_f2.weight': 0.3614\n",
      "Gradient norm for 'f2_f2.weight': 0.3518\n",
      "Gradient norm for 'f2_o.weight': 2.4905\n",
      "saving max acc: 52.3\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [11/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.84925\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.88575\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.87594\n",
      "l1_score: 0\n",
      "Time elasped: 21.282395839691162\n",
      "Test Loss: 1.8533703625202178\n",
      "Avg spk_count per neuron for all 30 time-steps 5.051924228668213\n",
      "Avg spk per neuron per layer [11.0815125, 9.126184375]\n",
      "Test Accuracy of the model on the test samples: 53.840\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0081\n",
      "Gradient norm for 'f0_f1.weight': 0.0067\n",
      "Gradient norm for 'f1_f1.weight': 0.0246\n",
      "Gradient norm for 'f1_f2.weight': 0.1417\n",
      "Gradient norm for 'f2_f2.weight': 0.1331\n",
      "Gradient norm for 'f2_o.weight': 1.6213\n",
      "saving max acc: 53.84\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [12/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.83801\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.87950\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.88254\n",
      "l1_score: 0\n",
      "Time elasped: 22.11725091934204\n",
      "Test Loss: 1.8156429886817933\n",
      "Avg spk_count per neuron for all 30 time-steps 5.162799835205078\n",
      "Avg spk per neuron per layer [11.475940625, 9.175259375]\n",
      "Test Accuracy of the model on the test samples: 58.580\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0262\n",
      "Gradient norm for 'f0_f1.weight': 0.0095\n",
      "Gradient norm for 'f1_f1.weight': 0.0277\n",
      "Gradient norm for 'f1_f2.weight': 0.1561\n",
      "Gradient norm for 'f2_f2.weight': 0.1379\n",
      "Gradient norm for 'f2_o.weight': 1.4860\n",
      "saving max acc: 58.58\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [13/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.85297\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.79721\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.79183\n",
      "l1_score: 0\n",
      "Time elasped: 21.489700078964233\n",
      "Test Loss: 1.7997570544481278\n",
      "Avg spk_count per neuron for all 30 time-steps 5.214592933654785\n",
      "Avg spk per neuron per layer [11.542771875, 9.3156]\n",
      "Test Accuracy of the model on the test samples: 57.960\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0256\n",
      "Gradient norm for 'f0_f1.weight': 0.0191\n",
      "Gradient norm for 'f1_f1.weight': 0.0666\n",
      "Gradient norm for 'f1_f2.weight': 0.3508\n",
      "Gradient norm for 'f2_f2.weight': 0.3342\n",
      "Gradient norm for 'f2_o.weight': 1.3133\n",
      "Epoch [14/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.76089\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.73174\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.75161\n",
      "l1_score: 0\n",
      "Time elasped: 20.9190616607666\n",
      "Test Loss: 1.7828761219978333\n",
      "Avg spk_count per neuron for all 30 time-steps 5.309699058532715\n",
      "Avg spk per neuron per layer [11.71715, 9.521646875]\n",
      "Test Accuracy of the model on the test samples: 59.760\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0184\n",
      "Gradient norm for 'f0_f1.weight': 0.0034\n",
      "Gradient norm for 'f1_f1.weight': 0.0111\n",
      "Gradient norm for 'f1_f2.weight': 0.0839\n",
      "Gradient norm for 'f2_f2.weight': 0.0834\n",
      "Gradient norm for 'f2_o.weight': 1.7032\n",
      "saving max acc: 59.76\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [15/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.74978\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.72888\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.74693\n",
      "l1_score: 0\n",
      "Time elasped: 20.52953600883484\n",
      "Test Loss: 1.759386521577835\n",
      "Avg spk_count per neuron for all 30 time-steps 5.193508625030518\n",
      "Avg spk per neuron per layer [11.5062875, 9.267746875]\n",
      "Test Accuracy of the model on the test samples: 62.600\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0170\n",
      "Gradient norm for 'f0_f1.weight': 0.0184\n",
      "Gradient norm for 'f1_f1.weight': 0.0657\n",
      "Gradient norm for 'f1_f2.weight': 0.4340\n",
      "Gradient norm for 'f2_f2.weight': 0.4045\n",
      "Gradient norm for 'f2_o.weight': 2.4569\n",
      "saving max acc: 62.6\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [16/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.78751\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.78360\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.72770\n",
      "l1_score: 0\n",
      "Time elasped: 20.62533450126648\n",
      "Test Loss: 1.7525642186403274\n",
      "Avg spk_count per neuron for all 30 time-steps 5.274437427520752\n",
      "Avg spk per neuron per layer [11.59126875, 9.50648125]\n",
      "Test Accuracy of the model on the test samples: 64.080\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0645\n",
      "Gradient norm for 'f0_f1.weight': 0.0578\n",
      "Gradient norm for 'f1_f1.weight': 0.1885\n",
      "Gradient norm for 'f1_f2.weight': 0.5775\n",
      "Gradient norm for 'f2_f2.weight': 0.5230\n",
      "Gradient norm for 'f2_o.weight': 3.0830\n",
      "saving max acc: 64.08\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [17/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.74562\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.76252\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.75792\n",
      "l1_score: 0\n",
      "Time elasped: 22.941617965698242\n",
      "Test Loss: 1.7326810002326964\n",
      "Avg spk_count per neuron for all 30 time-steps 5.270052433013916\n",
      "Avg spk per neuron per layer [11.801409375, 9.2788]\n",
      "Test Accuracy of the model on the test samples: 64.160\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0225\n",
      "Gradient norm for 'f0_f1.weight': 0.0075\n",
      "Gradient norm for 'f1_f1.weight': 0.0243\n",
      "Gradient norm for 'f1_f2.weight': 0.2474\n",
      "Gradient norm for 'f2_f2.weight': 0.2245\n",
      "Gradient norm for 'f2_o.weight': 2.8014\n",
      "saving max acc: 64.16\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Epoch [18/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.72877\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.71776\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.69085\n",
      "l1_score: 0\n",
      "Time elasped: 21.900474071502686\n",
      "Test Loss: 1.7550524026155472\n",
      "Avg spk_count per neuron for all 30 time-steps 5.323523998260498\n",
      "Avg spk per neuron per layer [11.6781125, 9.615984375]\n",
      "Test Accuracy of the model on the test samples: 63.460\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0105\n",
      "Gradient norm for 'f0_f1.weight': 0.0022\n",
      "Gradient norm for 'f1_f1.weight': 0.0051\n",
      "Gradient norm for 'f1_f2.weight': 0.0688\n",
      "Gradient norm for 'f2_f2.weight': 0.0636\n",
      "Gradient norm for 'f2_o.weight': 1.0957\n",
      "Epoch [19/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.72618\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.76019\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.72312\n",
      "l1_score: 0\n",
      "Time elasped: 20.90855383872986\n",
      "Test Loss: 1.7467559546232223\n",
      "Avg spk_count per neuron for all 30 time-steps 5.312290668487549\n",
      "Avg spk per neuron per layer [11.705990625, 9.543171875]\n",
      "Test Accuracy of the model on the test samples: 63.820\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0107\n",
      "Gradient norm for 'f0_f1.weight': 0.0033\n",
      "Gradient norm for 'f1_f1.weight': 0.0123\n",
      "Gradient norm for 'f1_f2.weight': 0.0934\n",
      "Gradient norm for 'f2_f2.weight': 0.0827\n",
      "Gradient norm for 'f2_o.weight': 0.6845\n",
      "Epoch [20/20], learning_rates 0.001000, 0.100000\n",
      "Step [26/78], Loss: 1.78657\n",
      "l1_score: 0\n",
      "Step [52/78], Loss: 1.67947\n",
      "l1_score: 0\n",
      "Step [78/78], Loss: 1.80601\n",
      "l1_score: 0\n",
      "Time elasped: 21.50566005706787\n",
      "Test Loss: 1.7388664573431014\n",
      "Avg spk_count per neuron for all 30 time-steps 5.30336856842041\n",
      "Avg spk per neuron per layer [11.75691875, 9.45655625]\n",
      "Test Accuracy of the model on the test samples: 64.580\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0071\n",
      "Gradient norm for 'f0_f1.weight': 0.0032\n",
      "Gradient norm for 'f1_f1.weight': 0.0107\n",
      "Gradient norm for 'f1_f2.weight': 0.0820\n",
      "Gradient norm for 'f2_f2.weight': 0.0769\n",
      "Gradient norm for 'f2_o.weight': 0.5669\n",
      "saving max acc: 64.58\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp21_STMNIST_memory\n",
      "[INFO] TIEMPO: 475.2918019294739\n"
     ]
    }
   ],
   "source": [
    "from snn_delays.utils.train_utils import train\n",
    "from snn_delays.utils.test_behavior import tb_save_max_last_acc\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "taimu1 = time.time()\n",
    "\n",
    "tau_m = 'normal'\n",
    "#delay = (48*2,16*2)\n",
    "#delay = (96,32)\n",
    "#delay = None\n",
    "delay = (3, 1)  \n",
    "ckpt_dir = 'exp21_STMNIST_memory' \n",
    "\n",
    "snn = SNN(dataset_dict=dataset_dict, structure=(64, 2), connection_type='r',\n",
    "    delay=delay, delay_type='h', tau_m = tau_m,\n",
    "    win=total_time*sequence_length, loss_fn='mem_last', batch_size=batch_size, device=device,\n",
    "    debug=False)\n",
    "\n",
    "snn.set_network()\n",
    "\n",
    "snn.model_name = f'dvs5_seq{sequence_length}_{delay}'+ snn.model_name\n",
    "\n",
    "snn.to(device)\n",
    "train(snn, train_loader, test_loader, lr, num_epochs, dropout=0.0, \n",
    "    test_behavior=tb_save_max_last_acc, ckpt_dir=ckpt_dir, scheduler=(100, 0.95), test_every=1)\n",
    "\n",
    "print(f'[INFO] TIEMPO: {time.time() - taimu1}', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepsnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
