{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b592c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "from snn_delays.snn import SNN\n",
    "from snn_delays.utils.dataset_loader import DatasetLoader\n",
    "from snn_delays.utils.train_utils import train, get_device\n",
    "from snn_delays.utils.test_behavior import tb_save_max_last_acc\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "# for reproducibility\n",
    "torch.manual_seed(10)\n",
    "\n",
    "'''\n",
    "Remarks:\n",
    "- experimenting with crop_to: this add different time-axis compression, should help with the generalization problem\n",
    "'''\n",
    "\n",
    "dataset = 'shd'\n",
    "total_time = 250\n",
    "batch_size = 256\n",
    "\n",
    "# DATASET\n",
    "DL = DatasetLoader(dataset=dataset,\n",
    "                  caching='memory',\n",
    "                  num_workers=0,\n",
    "                  batch_size=batch_size,\n",
    "                  total_time=total_time,\n",
    "                  crop_to=1e6)\n",
    "train_loader, test_loader, dataset_dict = DL.get_dataloaders()\n",
    "          \n",
    "num_epochs = 50\n",
    "\n",
    "lr = 1e-3\n",
    "# SNN CON DELAYS\n",
    "taimu1 = time.time()\n",
    "\n",
    "tau_m = 'normal'\n",
    "delay = (48,16)\n",
    "ckpt_dir = 'exp3_shd50_rnn' \n",
    "\n",
    "snn = SNN(dataset_dict=dataset_dict, structure=(64, 2), connection_type='f',\n",
    "    delay=delay, delay_type='h', tau_m = tau_m,\n",
    "    win=total_time, loss_fn='mem_sum', batch_size=batch_size, device=device,\n",
    "    debug=False)\n",
    "\n",
    "snn.set_network()\n",
    "\n",
    "snn.to(device)\n",
    "train(snn, train_loader, test_loader, lr, num_epochs, dropout=0.0, \n",
    "    test_behavior=tb_save_max_last_acc, ckpt_dir=ckpt_dir, scheduler=(100, 0.95), test_every=1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
