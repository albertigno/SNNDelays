{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda:0\n",
      "[CropTime(min=0, max=1000000.0), ToFrame(sensor_size=(700, 1, 1), time_window=None, event_count=None, n_time_bins=50, n_event_bins=None, overlap=0, include_incomplete=False)]\n",
      "\n",
      "[INFO] Delays: tensor([0])\n",
      "\n",
      "[INFO] Delays i: tensor([0])\n",
      "\n",
      "[INFO] Delays h: tensor([0])\n",
      "\n",
      "[INFO] Delays o: tensor([0])\n",
      "1000.0\n",
      "Delta t: 20.0 ms\n",
      "mean of normal: -0.541324854612918\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "from snn_delays.snn import SNN\n",
    "from snn_delays.utils.dataset_loader import DatasetLoader\n",
    "from snn_delays.utils.train_utils import train, get_device\n",
    "from snn_delays.utils.test_behavior import tb_save_max_last_acc\n",
    "\n",
    "'''\n",
    "SHD dataset as in ablation study\n",
    "'''\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "# for reproducibility\n",
    "torch.manual_seed(10)\n",
    "\n",
    "dataset = 'shd'\n",
    "total_time = 50\n",
    "batch_size = 1024\n",
    "\n",
    "# DATASET\n",
    "DL = DatasetLoader(dataset=dataset,\n",
    "                  caching='memory',\n",
    "                  num_workers=0,\n",
    "                  batch_size=batch_size,\n",
    "                  total_time=total_time,\n",
    "                  crop_to=1e6)\n",
    "train_loader, test_loader, dataset_dict = DL.get_dataloaders()\n",
    "          \n",
    "num_epochs = 50\n",
    "\n",
    "lr = 1e-3\n",
    "# SNN CON DELAYS\n",
    "taimu1 = time.time()\n",
    "\n",
    "tau_m = 'normal'\n",
    "delay = None\n",
    "ckpt_dir = 'exp3_shd50_rnn' \n",
    "\n",
    "mask = 1.0*torch.eye(64)\n",
    "\n",
    "snn = SNN(dataset_dict=dataset_dict, structure=(64, 2), connection_type='r',\n",
    "    delay=delay, delay_type='h', tau_m = tau_m,\n",
    "    win=total_time, loss_fn='mem_sum', batch_size=batch_size, device=device,\n",
    "    debug=False, mask=mask)\n",
    "snn.input2spike_th = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0504, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "        [-0.0000, -0.0376, -0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "        [-0.0000, -0.0000, -0.0302,  ..., -0.0000, -0.0000, -0.0000],\n",
      "        ...,\n",
      "        [-0.0000, -0.0000, -0.0000,  ..., -0.0825, -0.0000, -0.0000],\n",
      "        [-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.1040, -0.0000],\n",
      "        [-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.1179]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='input', ylabel='output'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from snn_delays.utils.visualization_utils import plot_param\n",
    "\n",
    "print(snn.f1_f1.linear.weight.data)\n",
    "\n",
    "plot_param(snn.f1_f1.linear, mode='2D', vminmax=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training shd50_SNN_l2_1d1.t7 for 50 epochs...\n",
      "Epoch [1/50], learning_rates 0.001000, 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [2/7], Loss: 3.23462\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 3.24044\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 3.32782\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 3.23250\n",
      "l1_score: 0\n",
      "Time elasped: 37.763875246047974\n",
      "Test Loss: 4.791606903076172\n",
      "Avg spk_count per neuron for all 50 time-steps 4.326743125915527\n",
      "Avg spk per neuron per layer [8.803410722173146, 8.503561174911662]\n",
      "Test Accuracy of the model on the test samples: 6.228\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0001\n",
      "Gradient norm for 'tau_m_2': 0.0009\n",
      "Gradient norm for 'tau_m_o': 0.0813\n",
      "Gradient norm for 'f0_f1.weight': 0.0598\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0018\n",
      "Gradient norm for 'f1_f2.weight': 0.1759\n",
      "Gradient norm for 'f2_f2.weight': 0.1856\n",
      "Gradient norm for 'f2_o.weight': 2.0149\n",
      "saving max acc: 6.22791519434629\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [2/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 3.12987\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 3.13360\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 3.10890\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 3.10860\n",
      "l1_score: 0\n",
      "Time elasped: 3.8903298377990723\n",
      "Test Loss: 4.623334527015686\n",
      "Avg spk_count per neuron for all 50 time-steps 4.520813465118408\n",
      "Avg spk per neuron per layer [9.161564156360424, 8.921688659452297]\n",
      "Test Accuracy of the model on the test samples: 7.686\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0001\n",
      "Gradient norm for 'tau_m_2': 0.0009\n",
      "Gradient norm for 'tau_m_o': 0.0393\n",
      "Gradient norm for 'f0_f1.weight': 0.0347\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0010\n",
      "Gradient norm for 'f1_f2.weight': 0.1722\n",
      "Gradient norm for 'f2_f2.weight': 0.1689\n",
      "Gradient norm for 'f2_o.weight': 1.3345\n",
      "saving max acc: 7.6855123674911665\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [3/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 3.07733\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 3.02069\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 3.07751\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 3.01213\n",
      "l1_score: 0\n",
      "Time elasped: 4.1004438400268555\n",
      "Test Loss: 4.491535186767578\n",
      "Avg spk_count per neuron for all 50 time-steps 4.485577583312988\n",
      "Avg spk per neuron per layer [9.133509551678445, 8.808800795053003]\n",
      "Test Accuracy of the model on the test samples: 8.657\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0001\n",
      "Gradient norm for 'tau_m_2': 0.0007\n",
      "Gradient norm for 'tau_m_o': 0.0326\n",
      "Gradient norm for 'f0_f1.weight': 0.0302\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0009\n",
      "Gradient norm for 'f1_f2.weight': 0.1106\n",
      "Gradient norm for 'f2_f2.weight': 0.1036\n",
      "Gradient norm for 'f2_o.weight': 1.2718\n",
      "saving max acc: 8.657243816254416\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [4/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 2.94954\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 2.96494\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 2.94132\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 2.93283\n",
      "l1_score: 0\n",
      "Time elasped: 4.038825988769531\n",
      "Test Loss: 4.338253617286682\n",
      "Avg spk_count per neuron for all 50 time-steps 4.454056739807129\n",
      "Avg spk per neuron per layer [9.131604737190813, 8.68462207376325]\n",
      "Test Accuracy of the model on the test samples: 13.383\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0001\n",
      "Gradient norm for 'tau_m_2': 0.0006\n",
      "Gradient norm for 'tau_m_o': 0.0515\n",
      "Gradient norm for 'f0_f1.weight': 0.0248\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0008\n",
      "Gradient norm for 'f1_f2.weight': 0.1072\n",
      "Gradient norm for 'f2_f2.weight': 0.1043\n",
      "Gradient norm for 'f2_o.weight': 1.1496\n",
      "saving max acc: 13.383392226148409\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [5/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 2.87612\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 2.84429\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 2.84730\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 2.80061\n",
      "l1_score: 0\n",
      "Time elasped: 3.9239680767059326\n",
      "Test Loss: 4.197967052459717\n",
      "Avg spk_count per neuron for all 50 time-steps 4.617563724517822\n",
      "Avg spk per neuron per layer [9.364834087897526, 9.105420439487633]\n",
      "Test Accuracy of the model on the test samples: 15.504\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0002\n",
      "Gradient norm for 'tau_m_2': 0.0014\n",
      "Gradient norm for 'tau_m_o': 0.0570\n",
      "Gradient norm for 'f0_f1.weight': 0.0596\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0020\n",
      "Gradient norm for 'f1_f2.weight': 0.3434\n",
      "Gradient norm for 'f2_f2.weight': 0.3142\n",
      "Gradient norm for 'f2_o.weight': 3.8085\n",
      "saving max acc: 15.503533568904594\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [6/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 2.77515\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 2.75551\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 2.68745\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 2.63419\n",
      "l1_score: 0\n",
      "Time elasped: 3.8921658992767334\n",
      "Test Loss: 4.032161355018616\n",
      "Avg spk_count per neuron for all 50 time-steps 4.8607587814331055\n",
      "Avg spk per neuron per layer [9.6875, 9.755535004416961]\n",
      "Test Accuracy of the model on the test samples: 19.567\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0002\n",
      "Gradient norm for 'tau_m_2': 0.0013\n",
      "Gradient norm for 'tau_m_o': 0.0477\n",
      "Gradient norm for 'f0_f1.weight': 0.0548\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0022\n",
      "Gradient norm for 'f1_f2.weight': 0.2079\n",
      "Gradient norm for 'f2_f2.weight': 0.2007\n",
      "Gradient norm for 'f2_o.weight': 1.6572\n",
      "saving max acc: 19.56713780918728\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [7/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 2.63873\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 2.63870\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 2.56567\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 2.53527\n",
      "l1_score: 0\n",
      "Time elasped: 4.201525688171387\n",
      "Test Loss: 3.898730993270874\n",
      "Avg spk_count per neuron for all 50 time-steps 4.914003849029541\n",
      "Avg spk per neuron per layer [9.757902219522968, 9.898113129416961]\n",
      "Test Accuracy of the model on the test samples: 25.442\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0002\n",
      "Gradient norm for 'tau_m_2': 0.0014\n",
      "Gradient norm for 'tau_m_o': 0.0782\n",
      "Gradient norm for 'f0_f1.weight': 0.0869\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0030\n",
      "Gradient norm for 'f1_f2.weight': 0.3466\n",
      "Gradient norm for 'f2_f2.weight': 0.3230\n",
      "Gradient norm for 'f2_o.weight': 2.7450\n",
      "saving max acc: 25.441696113074205\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [8/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 2.46783\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 2.44169\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 2.39092\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 2.30609\n",
      "l1_score: 0\n",
      "Time elasped: 4.201746940612793\n",
      "Test Loss: 3.6534159183502197\n",
      "Avg spk_count per neuron for all 50 time-steps 4.960393905639648\n",
      "Avg spk per neuron per layer [9.716362080388693, 10.125213946554771]\n",
      "Test Accuracy of the model on the test samples: 27.297\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0004\n",
      "Gradient norm for 'tau_m_2': 0.0016\n",
      "Gradient norm for 'tau_m_o': 0.0669\n",
      "Gradient norm for 'f0_f1.weight': 0.0870\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0031\n",
      "Gradient norm for 'f1_f2.weight': 0.4201\n",
      "Gradient norm for 'f2_f2.weight': 0.3888\n",
      "Gradient norm for 'f2_o.weight': 3.3212\n",
      "saving max acc: 27.296819787985864\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [9/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 2.27695\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 2.22897\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 2.10993\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 2.23215\n",
      "l1_score: 0\n",
      "Time elasped: 3.964508056640625\n",
      "Test Loss: 3.458506464958191\n",
      "Avg spk_count per neuron for all 50 time-steps 5.0349907875061035\n",
      "Avg spk per neuron per layer [9.822548586572438, 10.317413869257951]\n",
      "Test Accuracy of the model on the test samples: 33.878\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0006\n",
      "Gradient norm for 'tau_m_2': 0.0022\n",
      "Gradient norm for 'tau_m_o': 0.0805\n",
      "Gradient norm for 'f0_f1.weight': 0.1317\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0039\n",
      "Gradient norm for 'f1_f2.weight': 0.4259\n",
      "Gradient norm for 'f2_f2.weight': 0.4308\n",
      "Gradient norm for 'f2_o.weight': 3.1942\n",
      "saving max acc: 33.87809187279152\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [10/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 2.20670\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 2.04242\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 1.98905\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 2.00131\n",
      "l1_score: 0\n",
      "Time elasped: 3.948443651199341\n",
      "Test Loss: 3.3909919261932373\n",
      "Avg spk_count per neuron for all 50 time-steps 4.955656051635742\n",
      "Avg spk per neuron per layer [9.602646035777385, 10.219978467314487]\n",
      "Test Accuracy of the model on the test samples: 37.633\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0006\n",
      "Gradient norm for 'tau_m_2': 0.0037\n",
      "Gradient norm for 'tau_m_o': 0.1308\n",
      "Gradient norm for 'f0_f1.weight': 0.2500\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0090\n",
      "Gradient norm for 'f1_f2.weight': 1.0314\n",
      "Gradient norm for 'f2_f2.weight': 0.9301\n",
      "Gradient norm for 'f2_o.weight': 8.4868\n",
      "saving max acc: 37.63250883392226\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [11/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 1.96967\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 1.89652\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 1.85401\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 1.82736\n",
      "l1_score: 0\n",
      "Time elasped: 4.020061254501343\n",
      "Test Loss: 2.9491639733314514\n",
      "Avg spk_count per neuron for all 50 time-steps 4.971524238586426\n",
      "Avg spk per neuron per layer [9.75236031360424, 10.13373730123675]\n",
      "Test Accuracy of the model on the test samples: 44.965\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0007\n",
      "Gradient norm for 'tau_m_2': 0.0037\n",
      "Gradient norm for 'tau_m_o': 0.1504\n",
      "Gradient norm for 'f0_f1.weight': 0.1377\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0076\n",
      "Gradient norm for 'f1_f2.weight': 0.5620\n",
      "Gradient norm for 'f2_f2.weight': 0.5853\n",
      "Gradient norm for 'f2_o.weight': 3.7922\n",
      "saving max acc: 44.96466431095406\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [12/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 1.76298\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 1.70254\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 1.62963\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 1.53588\n",
      "l1_score: 0\n",
      "Time elasped: 4.06905198097229\n",
      "Test Loss: 2.8563771843910217\n",
      "Avg spk_count per neuron for all 50 time-steps 5.087702751159668\n",
      "Avg spk per neuron per layer [9.955540525618375, 10.395269710689046]\n",
      "Test Accuracy of the model on the test samples: 45.495\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0008\n",
      "Gradient norm for 'tau_m_2': 0.0034\n",
      "Gradient norm for 'tau_m_o': 0.1901\n",
      "Gradient norm for 'f0_f1.weight': 0.2001\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0084\n",
      "Gradient norm for 'f1_f2.weight': 0.8277\n",
      "Gradient norm for 'f2_f2.weight': 0.7722\n",
      "Gradient norm for 'f2_o.weight': 5.8770\n",
      "saving max acc: 45.49469964664311\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [13/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 1.55803\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 1.48272\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 1.35956\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 1.33921\n",
      "l1_score: 0\n",
      "Time elasped: 3.976360559463501\n",
      "Test Loss: 2.6329041123390198\n",
      "Avg spk_count per neuron for all 50 time-steps 5.119578838348389\n",
      "Avg spk per neuron per layer [9.797406415636042, 10.68090906581272]\n",
      "Test Accuracy of the model on the test samples: 49.293\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0005\n",
      "Gradient norm for 'tau_m_2': 0.0033\n",
      "Gradient norm for 'tau_m_o': 0.1775\n",
      "Gradient norm for 'f0_f1.weight': 0.1627\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0069\n",
      "Gradient norm for 'f1_f2.weight': 0.7478\n",
      "Gradient norm for 'f2_f2.weight': 0.7035\n",
      "Gradient norm for 'f2_o.weight': 5.3100\n",
      "saving max acc: 49.293286219081274\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [14/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 1.34444\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 1.33567\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 1.28613\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 1.21589\n",
      "l1_score: 0\n",
      "Time elasped: 4.040679693222046\n",
      "Test Loss: 2.3586403131484985\n",
      "Avg spk_count per neuron for all 50 time-steps 5.21756649017334\n",
      "Avg spk per neuron per layer [9.872439542844523, 10.997826026943462]\n",
      "Test Accuracy of the model on the test samples: 53.799\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0006\n",
      "Gradient norm for 'tau_m_2': 0.0037\n",
      "Gradient norm for 'tau_m_o': 0.2495\n",
      "Gradient norm for 'f0_f1.weight': 0.1771\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0054\n",
      "Gradient norm for 'f1_f2.weight': 0.8454\n",
      "Gradient norm for 'f2_f2.weight': 0.7783\n",
      "Gradient norm for 'f2_o.weight': 5.9297\n",
      "saving max acc: 53.79858657243816\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [15/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 1.23901\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 1.17246\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 1.14988\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 1.22667\n",
      "l1_score: 0\n",
      "Time elasped: 3.9812607765197754\n",
      "Test Loss: 2.1934614777565002\n",
      "Avg spk_count per neuron for all 50 time-steps 5.202398777008057\n",
      "Avg spk per neuron per layer [9.818773465106007, 10.990821002650177]\n",
      "Test Accuracy of the model on the test samples: 55.654\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0010\n",
      "Gradient norm for 'tau_m_2': 0.0053\n",
      "Gradient norm for 'tau_m_o': 0.3282\n",
      "Gradient norm for 'f0_f1.weight': 0.2960\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0106\n",
      "Gradient norm for 'f1_f2.weight': 1.3506\n",
      "Gradient norm for 'f2_f2.weight': 1.2655\n",
      "Gradient norm for 'f2_o.weight': 9.0069\n",
      "saving max acc: 55.65371024734982\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [16/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 1.04353\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 1.17309\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 1.06237\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 1.10771\n",
      "l1_score: 0\n",
      "Time elasped: 3.9497153759002686\n",
      "Test Loss: 2.346467912197113\n",
      "Avg spk_count per neuron for all 50 time-steps 5.323825359344482\n",
      "Avg spk per neuron per layer [10.012615945229681, 11.282685512367491]\n",
      "Test Accuracy of the model on the test samples: 52.871\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0006\n",
      "Gradient norm for 'tau_m_2': 0.0039\n",
      "Gradient norm for 'tau_m_o': 0.3084\n",
      "Gradient norm for 'f0_f1.weight': 0.2613\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0117\n",
      "Gradient norm for 'f1_f2.weight': 1.1999\n",
      "Gradient norm for 'f2_f2.weight': 1.1325\n",
      "Gradient norm for 'f2_o.weight': 8.5388\n",
      "Epoch [17/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 1.07893\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 1.09323\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 1.02492\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.96994\n",
      "l1_score: 0\n",
      "Time elasped: 3.9424381256103516\n",
      "Test Loss: 1.9526153802871704\n",
      "Avg spk_count per neuron for all 50 time-steps 5.361528396606445\n",
      "Avg spk per neuron per layer [10.202358933303888, 11.24375414090106]\n",
      "Test Accuracy of the model on the test samples: 58.083\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0016\n",
      "Gradient norm for 'tau_m_2': 0.0076\n",
      "Gradient norm for 'tau_m_o': 0.2982\n",
      "Gradient norm for 'f0_f1.weight': 0.3168\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0175\n",
      "Gradient norm for 'f1_f2.weight': 1.4811\n",
      "Gradient norm for 'f2_f2.weight': 1.5124\n",
      "Gradient norm for 'f2_o.weight': 8.9446\n",
      "saving max acc: 58.08303886925795\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [18/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.91928\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.98208\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.95685\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.92245\n",
      "l1_score: 0\n",
      "Time elasped: 4.151191473007202\n",
      "Test Loss: 1.9945573806762695\n",
      "Avg spk_count per neuron for all 50 time-steps 5.603443145751953\n",
      "Avg spk per neuron per layer [10.3164269545053, 12.097345682420494]\n",
      "Test Accuracy of the model on the test samples: 60.822\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0011\n",
      "Gradient norm for 'tau_m_2': 0.0058\n",
      "Gradient norm for 'tau_m_o': 0.2440\n",
      "Gradient norm for 'f0_f1.weight': 0.3868\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0167\n",
      "Gradient norm for 'f1_f2.weight': 1.6550\n",
      "Gradient norm for 'f2_f2.weight': 1.5585\n",
      "Gradient norm for 'f2_o.weight': 9.0019\n",
      "saving max acc: 60.82155477031802\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [19/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.82760\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.78591\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.85186\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.85886\n",
      "l1_score: 0\n",
      "Time elasped: 4.05158805847168\n",
      "Test Loss: 1.859715223312378\n",
      "Avg spk_count per neuron for all 50 time-steps 5.587400436401367\n",
      "Avg spk per neuron per layer [10.371086848498233, 11.978515625]\n",
      "Test Accuracy of the model on the test samples: 62.367\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0011\n",
      "Gradient norm for 'tau_m_2': 0.0069\n",
      "Gradient norm for 'tau_m_o': 0.3782\n",
      "Gradient norm for 'f0_f1.weight': 0.3194\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0157\n",
      "Gradient norm for 'f1_f2.weight': 1.4927\n",
      "Gradient norm for 'f2_f2.weight': 1.4481\n",
      "Gradient norm for 'f2_o.weight': 9.8476\n",
      "saving max acc: 62.36749116607774\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [20/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.79567\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.77157\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.71358\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.74052\n",
      "l1_score: 0\n",
      "Time elasped: 3.9711813926696777\n",
      "Test Loss: 1.940038800239563\n",
      "Avg spk_count per neuron for all 50 time-steps 5.627586364746094\n",
      "Avg spk per neuron per layer [10.452704008392226, 12.057641342756185]\n",
      "Test Accuracy of the model on the test samples: 61.882\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0014\n",
      "Gradient norm for 'tau_m_2': 0.0052\n",
      "Gradient norm for 'tau_m_o': 0.2441\n",
      "Gradient norm for 'f0_f1.weight': 0.2825\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0121\n",
      "Gradient norm for 'f1_f2.weight': 1.4022\n",
      "Gradient norm for 'f2_f2.weight': 1.3428\n",
      "Gradient norm for 'f2_o.weight': 7.2698\n",
      "Epoch [21/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.64101\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.73088\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.74224\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.68737\n",
      "l1_score: 0\n",
      "Time elasped: 4.000652313232422\n",
      "Test Loss: 1.8115098476409912\n",
      "Avg spk_count per neuron for all 50 time-steps 5.594790458679199\n",
      "Avg spk per neuron per layer [10.380742049469964, 11.998419556095406]\n",
      "Test Accuracy of the model on the test samples: 65.636\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0017\n",
      "Gradient norm for 'tau_m_2': 0.0062\n",
      "Gradient norm for 'tau_m_o': 0.2381\n",
      "Gradient norm for 'f0_f1.weight': 0.2660\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0120\n",
      "Gradient norm for 'f1_f2.weight': 1.3264\n",
      "Gradient norm for 'f2_f2.weight': 1.4008\n",
      "Gradient norm for 'f2_o.weight': 7.1926\n",
      "saving max acc: 65.63604240282686\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [22/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.65083\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.56626\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.60023\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.55707\n",
      "l1_score: 0\n",
      "Time elasped: 4.086035251617432\n",
      "Test Loss: 1.4961104989051819\n",
      "Avg spk_count per neuron for all 50 time-steps 5.557136058807373\n",
      "Avg spk per neuron per layer [10.349084860865725, 11.879458370141343]\n",
      "Test Accuracy of the model on the test samples: 68.949\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0009\n",
      "Gradient norm for 'tau_m_2': 0.0041\n",
      "Gradient norm for 'tau_m_o': 0.2032\n",
      "Gradient norm for 'f0_f1.weight': 0.2451\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0097\n",
      "Gradient norm for 'f1_f2.weight': 1.0313\n",
      "Gradient norm for 'f2_f2.weight': 0.9650\n",
      "Gradient norm for 'f2_o.weight': 6.0514\n",
      "saving max acc: 68.94876325088339\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [23/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.61899\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.60193\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.62165\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.53088\n",
      "l1_score: 0\n",
      "Time elasped: 4.008541584014893\n",
      "Test Loss: 1.8814256191253662\n",
      "Avg spk_count per neuron for all 50 time-steps 5.6216511726379395\n",
      "Avg spk per neuron per layer [10.299670108215548, 12.186934076855124]\n",
      "Test Accuracy of the model on the test samples: 66.784\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0014\n",
      "Gradient norm for 'tau_m_2': 0.0047\n",
      "Gradient norm for 'tau_m_o': 0.2722\n",
      "Gradient norm for 'f0_f1.weight': 0.2385\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0118\n",
      "Gradient norm for 'f1_f2.weight': 1.1091\n",
      "Gradient norm for 'f2_f2.weight': 1.0354\n",
      "Gradient norm for 'f2_o.weight': 6.5931\n",
      "Epoch [24/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.57921\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.52844\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.54680\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.56498\n",
      "l1_score: 0\n",
      "Time elasped: 4.006978750228882\n",
      "Test Loss: 1.789336383342743\n",
      "Avg spk_count per neuron for all 50 time-steps 5.596457004547119\n",
      "Avg spk per neuron per layer [10.184760103798586, 12.201068352473499]\n",
      "Test Accuracy of the model on the test samples: 65.504\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0012\n",
      "Gradient norm for 'tau_m_2': 0.0048\n",
      "Gradient norm for 'tau_m_o': 0.2749\n",
      "Gradient norm for 'f0_f1.weight': 0.3268\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0119\n",
      "Gradient norm for 'f1_f2.weight': 1.3010\n",
      "Gradient norm for 'f2_f2.weight': 1.2121\n",
      "Gradient norm for 'f2_o.weight': 6.8640\n",
      "Epoch [25/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.51033\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.47634\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.44517\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.46570\n",
      "l1_score: 0\n",
      "Time elasped: 3.9172873497009277\n",
      "Test Loss: 1.7018189430236816\n",
      "Avg spk_count per neuron for all 50 time-steps 5.704467296600342\n",
      "Avg spk per neuron per layer [10.501276777826854, 12.316592590547703]\n",
      "Test Accuracy of the model on the test samples: 69.435\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0010\n",
      "Gradient norm for 'tau_m_2': 0.0055\n",
      "Gradient norm for 'tau_m_o': 0.2499\n",
      "Gradient norm for 'f0_f1.weight': 0.2131\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0082\n",
      "Gradient norm for 'f1_f2.weight': 1.3962\n",
      "Gradient norm for 'f2_f2.weight': 1.2654\n",
      "Gradient norm for 'f2_o.weight': 7.4198\n",
      "saving max acc: 69.43462897526501\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [26/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.44874\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.43033\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.50017\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.50758\n",
      "l1_score: 0\n",
      "Time elasped: 4.022467374801636\n",
      "Test Loss: 1.8691550493240356\n",
      "Avg spk_count per neuron for all 50 time-steps 5.7234206199646\n",
      "Avg spk per neuron per layer [10.528710247349823, 12.364972117932862]\n",
      "Test Accuracy of the model on the test samples: 67.005\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0015\n",
      "Gradient norm for 'tau_m_2': 0.0066\n",
      "Gradient norm for 'tau_m_o': 0.2407\n",
      "Gradient norm for 'f0_f1.weight': 0.4298\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0157\n",
      "Gradient norm for 'f1_f2.weight': 1.6131\n",
      "Gradient norm for 'f2_f2.weight': 1.5112\n",
      "Gradient norm for 'f2_o.weight': 8.1122\n",
      "Epoch [27/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.48474\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.36309\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.49078\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.47100\n",
      "l1_score: 0\n",
      "Time elasped: 4.284723520278931\n",
      "Test Loss: 1.683386206626892\n",
      "Avg spk_count per neuron for all 50 time-steps 5.5988311767578125\n",
      "Avg spk per neuron per layer [10.251118043286219, 12.144206879416961]\n",
      "Test Accuracy of the model on the test samples: 67.668\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0008\n",
      "Gradient norm for 'tau_m_2': 0.0044\n",
      "Gradient norm for 'tau_m_o': 0.1895\n",
      "Gradient norm for 'f0_f1.weight': 0.2455\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0088\n",
      "Gradient norm for 'f1_f2.weight': 1.0873\n",
      "Gradient norm for 'f2_f2.weight': 1.0285\n",
      "Gradient norm for 'f2_o.weight': 6.3299\n",
      "Epoch [28/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.40702\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.39083\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.38971\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.49414\n",
      "l1_score: 0\n",
      "Time elasped: 4.094369411468506\n",
      "Test Loss: 1.8297943472862244\n",
      "Avg spk_count per neuron for all 50 time-steps 5.693294048309326\n",
      "Avg spk per neuron per layer [10.493243429770319, 12.279931813162545]\n",
      "Test Accuracy of the model on the test samples: 68.595\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0022\n",
      "Gradient norm for 'tau_m_2': 0.0074\n",
      "Gradient norm for 'tau_m_o': 0.4115\n",
      "Gradient norm for 'f0_f1.weight': 0.4791\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0190\n",
      "Gradient norm for 'f1_f2.weight': 1.7217\n",
      "Gradient norm for 'f2_f2.weight': 1.6855\n",
      "Gradient norm for 'f2_o.weight': 9.1122\n",
      "Epoch [29/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.39646\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.31518\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.41956\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.49895\n",
      "l1_score: 0\n",
      "Time elasped: 4.167971611022949\n",
      "Test Loss: 1.9574198722839355\n",
      "Avg spk_count per neuron for all 50 time-steps 5.74609899520874\n",
      "Avg spk per neuron per layer [10.487211517226148, 12.497184187279151]\n",
      "Test Accuracy of the model on the test samples: 66.034\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0013\n",
      "Gradient norm for 'tau_m_2': 0.0064\n",
      "Gradient norm for 'tau_m_o': 0.3444\n",
      "Gradient norm for 'f0_f1.weight': 0.3641\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0146\n",
      "Gradient norm for 'f1_f2.weight': 1.5557\n",
      "Gradient norm for 'f2_f2.weight': 1.3920\n",
      "Gradient norm for 'f2_o.weight': 8.7978\n",
      "Epoch [30/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.41536\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.45045\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.39028\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.42452\n",
      "l1_score: 0\n",
      "Time elasped: 4.349467992782593\n",
      "Test Loss: 1.5506643652915955\n",
      "Avg spk_count per neuron for all 50 time-steps 5.736788749694824\n",
      "Avg spk per neuron per layer [10.518896311837455, 12.428258889134275]\n",
      "Test Accuracy of the model on the test samples: 69.788\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0016\n",
      "Gradient norm for 'tau_m_2': 0.0043\n",
      "Gradient norm for 'tau_m_o': 0.2992\n",
      "Gradient norm for 'f0_f1.weight': 0.3940\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0110\n",
      "Gradient norm for 'f1_f2.weight': 1.3931\n",
      "Gradient norm for 'f2_f2.weight': 1.3038\n",
      "Gradient norm for 'f2_o.weight': 8.5381\n",
      "saving max acc: 69.78798586572438\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [31/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.35073\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.32579\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.40487\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.31021\n",
      "l1_score: 0\n",
      "Time elasped: 4.1426873207092285\n",
      "Test Loss: 1.9402247667312622\n",
      "Avg spk_count per neuron for all 50 time-steps 5.705404281616211\n",
      "Avg spk per neuron per layer [10.509965768551236, 12.311651115282686]\n",
      "Test Accuracy of the model on the test samples: 68.772\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0011\n",
      "Gradient norm for 'tau_m_2': 0.0039\n",
      "Gradient norm for 'tau_m_o': 0.1681\n",
      "Gradient norm for 'f0_f1.weight': 0.2323\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0092\n",
      "Gradient norm for 'f1_f2.weight': 0.8834\n",
      "Gradient norm for 'f2_f2.weight': 0.8386\n",
      "Gradient norm for 'f2_o.weight': 4.9596\n",
      "Epoch [32/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.32302\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.32678\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.32091\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.33001\n",
      "l1_score: 0\n",
      "Time elasped: 4.123334884643555\n",
      "Test Loss: 1.4445472955703735\n",
      "Avg spk_count per neuron for all 50 time-steps 5.692798614501953\n",
      "Avg spk per neuron per layer [10.40234375, 12.368850761925795]\n",
      "Test Accuracy of the model on the test samples: 73.940\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0012\n",
      "Gradient norm for 'tau_m_2': 0.0047\n",
      "Gradient norm for 'tau_m_o': 0.1770\n",
      "Gradient norm for 'f0_f1.weight': 0.2807\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0085\n",
      "Gradient norm for 'f1_f2.weight': 1.0095\n",
      "Gradient norm for 'f2_f2.weight': 0.9690\n",
      "Gradient norm for 'f2_o.weight': 5.7783\n",
      "saving max acc: 73.93992932862191\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [33/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.34053\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.29610\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.29553\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.29472\n",
      "l1_score: 0\n",
      "Time elasped: 3.998903751373291\n",
      "Test Loss: 1.633838713169098\n",
      "Avg spk_count per neuron for all 50 time-steps 5.69479513168335\n",
      "Avg spk per neuron per layer [10.46308386704947, 12.316095682420494]\n",
      "Test Accuracy of the model on the test samples: 69.567\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0009\n",
      "Gradient norm for 'tau_m_2': 0.0040\n",
      "Gradient norm for 'tau_m_o': 0.2096\n",
      "Gradient norm for 'f0_f1.weight': 0.3003\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0090\n",
      "Gradient norm for 'f1_f2.weight': 1.1302\n",
      "Gradient norm for 'f2_f2.weight': 1.0499\n",
      "Gradient norm for 'f2_o.weight': 5.4433\n",
      "Epoch [34/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.25955\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.27890\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.29781\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.27751\n",
      "l1_score: 0\n",
      "Time elasped: 3.9776833057403564\n",
      "Test Loss: 1.7047231793403625\n",
      "Avg spk_count per neuron for all 50 time-steps 5.751994609832764\n",
      "Avg spk per neuron per layer [10.702655697879859, 12.305322438162545]\n",
      "Test Accuracy of the model on the test samples: 71.201\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0008\n",
      "Gradient norm for 'tau_m_2': 0.0036\n",
      "Gradient norm for 'tau_m_o': 0.1456\n",
      "Gradient norm for 'f0_f1.weight': 0.2078\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0092\n",
      "Gradient norm for 'f1_f2.weight': 0.7561\n",
      "Gradient norm for 'f2_f2.weight': 0.7395\n",
      "Gradient norm for 'f2_o.weight': 4.5098\n",
      "Epoch [35/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.22245\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.24066\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.24730\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.24142\n",
      "l1_score: 0\n",
      "Time elasped: 4.029043912887573\n",
      "Test Loss: 1.3212895095348358\n",
      "Avg spk_count per neuron for all 50 time-steps 5.735011577606201\n",
      "Avg spk per neuron per layer [10.501656360424029, 12.438390293727915]\n",
      "Test Accuracy of the model on the test samples: 72.836\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0012\n",
      "Gradient norm for 'tau_m_2': 0.0048\n",
      "Gradient norm for 'tau_m_o': 0.1262\n",
      "Gradient norm for 'f0_f1.weight': 0.2680\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0089\n",
      "Gradient norm for 'f1_f2.weight': 0.9011\n",
      "Gradient norm for 'f2_f2.weight': 0.8484\n",
      "Gradient norm for 'f2_o.weight': 4.2909\n",
      "Epoch [36/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.22523\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.25026\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.22542\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.26646\n",
      "l1_score: 0\n",
      "Time elasped: 4.0506720542907715\n",
      "Test Loss: 1.4239557683467865\n",
      "Avg spk_count per neuron for all 50 time-steps 5.791360855102539\n",
      "Avg spk per neuron per layer [10.683635159010601, 12.481807641342757]\n",
      "Test Accuracy of the model on the test samples: 73.012\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0012\n",
      "Gradient norm for 'tau_m_2': 0.0053\n",
      "Gradient norm for 'tau_m_o': 0.2606\n",
      "Gradient norm for 'f0_f1.weight': 0.3207\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0110\n",
      "Gradient norm for 'f1_f2.weight': 1.1390\n",
      "Gradient norm for 'f2_f2.weight': 1.0704\n",
      "Gradient norm for 'f2_o.weight': 7.6351\n",
      "Epoch [37/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.22146\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.20204\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.19316\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.24461\n",
      "l1_score: 0\n",
      "Time elasped: 3.980678081512451\n",
      "Test Loss: 1.748432457447052\n",
      "Avg spk_count per neuron for all 50 time-steps 5.806024551391602\n",
      "Avg spk per neuron per layer [10.772561009275618, 12.45153765459364]\n",
      "Test Accuracy of the model on the test samples: 73.189\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0009\n",
      "Gradient norm for 'tau_m_2': 0.0040\n",
      "Gradient norm for 'tau_m_o': 0.1347\n",
      "Gradient norm for 'f0_f1.weight': 0.2271\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0077\n",
      "Gradient norm for 'f1_f2.weight': 0.9428\n",
      "Gradient norm for 'f2_f2.weight': 0.8479\n",
      "Gradient norm for 'f2_o.weight': 4.1790\n",
      "Epoch [38/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.19896\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.13714\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.28340\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.19675\n",
      "l1_score: 0\n",
      "Time elasped: 4.030809164047241\n",
      "Test Loss: 1.4835467338562012\n",
      "Avg spk_count per neuron for all 50 time-steps 5.75722599029541\n",
      "Avg spk per neuron per layer [10.642226148409893, 12.386677340989399]\n",
      "Test Accuracy of the model on the test samples: 72.659\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0010\n",
      "Gradient norm for 'tau_m_2': 0.0050\n",
      "Gradient norm for 'tau_m_o': 0.2277\n",
      "Gradient norm for 'f0_f1.weight': 0.3558\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0121\n",
      "Gradient norm for 'f1_f2.weight': 1.3782\n",
      "Gradient norm for 'f2_f2.weight': 1.2616\n",
      "Gradient norm for 'f2_o.weight': 6.7935\n",
      "Epoch [39/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.23023\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.22390\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.21250\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.24255\n",
      "l1_score: 0\n",
      "Time elasped: 4.163712501525879\n",
      "Test Loss: 1.579514592885971\n",
      "Avg spk_count per neuron for all 50 time-steps 5.8147687911987305\n",
      "Avg spk per neuron per layer [10.62261898189046, 12.636456492932862]\n",
      "Test Accuracy of the model on the test samples: 73.631\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0012\n",
      "Gradient norm for 'tau_m_2': 0.0060\n",
      "Gradient norm for 'tau_m_o': 0.2858\n",
      "Gradient norm for 'f0_f1.weight': 0.2633\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0111\n",
      "Gradient norm for 'f1_f2.weight': 1.2799\n",
      "Gradient norm for 'f2_f2.weight': 1.2275\n",
      "Gradient norm for 'f2_o.weight': 8.3377\n",
      "Epoch [40/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.21589\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.17169\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.20889\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.20359\n",
      "l1_score: 0\n",
      "Time elasped: 4.056252956390381\n",
      "Test Loss: 1.4184092283248901\n",
      "Avg spk_count per neuron for all 50 time-steps 5.794142246246338\n",
      "Avg spk per neuron per layer [10.594129582597173, 12.58243843860424]\n",
      "Test Accuracy of the model on the test samples: 73.763\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0018\n",
      "Gradient norm for 'tau_m_2': 0.0088\n",
      "Gradient norm for 'tau_m_o': 0.1381\n",
      "Gradient norm for 'f0_f1.weight': 0.2984\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0128\n",
      "Gradient norm for 'f1_f2.weight': 1.1818\n",
      "Gradient norm for 'f2_f2.weight': 1.1531\n",
      "Gradient norm for 'f2_o.weight': 5.6801\n",
      "Epoch [41/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.21557\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.14558\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.19869\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.21135\n",
      "l1_score: 0\n",
      "Time elasped: 4.03394341468811\n",
      "Test Loss: 1.5567300915718079\n",
      "Avg spk_count per neuron for all 50 time-steps 5.88214635848999\n",
      "Avg spk per neuron per layer [10.751614951413428, 12.776971068904594]\n",
      "Test Accuracy of the model on the test samples: 74.470\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0005\n",
      "Gradient norm for 'tau_m_2': 0.0040\n",
      "Gradient norm for 'tau_m_o': 0.1322\n",
      "Gradient norm for 'f0_f1.weight': 0.1754\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0069\n",
      "Gradient norm for 'f1_f2.weight': 0.8423\n",
      "Gradient norm for 'f2_f2.weight': 0.7788\n",
      "Gradient norm for 'f2_o.weight': 4.6480\n",
      "saving max acc: 74.46996466431095\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [42/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.17123\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.14509\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.14496\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.20232\n",
      "l1_score: 0\n",
      "Time elasped: 4.1909873485565186\n",
      "Test Loss: 1.6466879844665527\n",
      "Avg spk_count per neuron for all 50 time-steps 5.843825817108154\n",
      "Avg spk per neuron per layer [10.771836351590107, 12.603467314487633]\n",
      "Test Accuracy of the model on the test samples: 74.558\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0012\n",
      "Gradient norm for 'tau_m_2': 0.0051\n",
      "Gradient norm for 'tau_m_o': 0.1817\n",
      "Gradient norm for 'f0_f1.weight': 0.2048\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0068\n",
      "Gradient norm for 'f1_f2.weight': 0.9320\n",
      "Gradient norm for 'f2_f2.weight': 0.8502\n",
      "Gradient norm for 'f2_o.weight': 6.1465\n",
      "saving max acc: 74.5583038869258\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Epoch [43/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.19437\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.13747\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.20913\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.17544\n",
      "l1_score: 0\n",
      "Time elasped: 4.230032920837402\n",
      "Test Loss: 1.5753595530986786\n",
      "Avg spk_count per neuron for all 50 time-steps 5.881988048553467\n",
      "Avg spk per neuron per layer [10.727473498233216, 12.80047758392226]\n",
      "Test Accuracy of the model on the test samples: 74.382\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0011\n",
      "Gradient norm for 'tau_m_2': 0.0052\n",
      "Gradient norm for 'tau_m_o': 0.1220\n",
      "Gradient norm for 'f0_f1.weight': 0.2425\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0094\n",
      "Gradient norm for 'f1_f2.weight': 1.0032\n",
      "Gradient norm for 'f2_f2.weight': 0.9558\n",
      "Gradient norm for 'f2_o.weight': 4.9098\n",
      "Epoch [44/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.18412\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.14382\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.18383\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.15863\n",
      "l1_score: 0\n",
      "Time elasped: 4.024541139602661\n",
      "Test Loss: 1.5661892294883728\n",
      "Avg spk_count per neuron for all 50 time-steps 5.88682222366333\n",
      "Avg spk per neuron per layer [10.582003643992932, 12.965285446113073]\n",
      "Test Accuracy of the model on the test samples: 74.205\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0008\n",
      "Gradient norm for 'tau_m_2': 0.0039\n",
      "Gradient norm for 'tau_m_o': 0.1550\n",
      "Gradient norm for 'f0_f1.weight': 0.1782\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0061\n",
      "Gradient norm for 'f1_f2.weight': 0.9794\n",
      "Gradient norm for 'f2_f2.weight': 0.9078\n",
      "Gradient norm for 'f2_o.weight': 5.5994\n",
      "Epoch [45/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.12219\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.14806\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.13860\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.16735\n",
      "l1_score: 0\n",
      "Time elasped: 3.982135772705078\n",
      "Test Loss: 1.7548909783363342\n",
      "Avg spk_count per neuron for all 50 time-steps 5.82293176651001\n",
      "Avg spk per neuron per layer [10.582990558745584, 12.708735920936396]\n",
      "Test Accuracy of the model on the test samples: 72.747\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0008\n",
      "Gradient norm for 'tau_m_2': 0.0062\n",
      "Gradient norm for 'tau_m_o': 0.2108\n",
      "Gradient norm for 'f0_f1.weight': 0.2501\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0080\n",
      "Gradient norm for 'f1_f2.weight': 1.0090\n",
      "Gradient norm for 'f2_f2.weight': 0.9484\n",
      "Gradient norm for 'f2_o.weight': 6.1044\n",
      "Epoch [46/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.11994\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.17427\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.13120\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.17469\n",
      "l1_score: 0\n",
      "Time elasped: 4.164396286010742\n",
      "Test Loss: 1.7722306847572327\n",
      "Avg spk_count per neuron for all 50 time-steps 5.8512864112854\n",
      "Avg spk per neuron per layer [10.694718970848056, 12.710426788869258]\n",
      "Test Accuracy of the model on the test samples: 74.028\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0014\n",
      "Gradient norm for 'tau_m_2': 0.0062\n",
      "Gradient norm for 'tau_m_o': 0.1071\n",
      "Gradient norm for 'f0_f1.weight': 0.2737\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0093\n",
      "Gradient norm for 'f1_f2.weight': 1.0174\n",
      "Gradient norm for 'f2_f2.weight': 0.9628\n",
      "Gradient norm for 'f2_o.weight': 4.5540\n",
      "Epoch [47/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.12911\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.12396\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.11692\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.11400\n",
      "l1_score: 0\n",
      "Time elasped: 4.183710098266602\n",
      "Test Loss: 1.7138463258743286\n",
      "Avg spk_count per neuron for all 50 time-steps 5.827873229980469\n",
      "Avg spk per neuron per layer [10.598470627208481, 12.71302175353357]\n",
      "Test Accuracy of the model on the test samples: 72.880\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0007\n",
      "Gradient norm for 'tau_m_2': 0.0030\n",
      "Gradient norm for 'tau_m_o': 0.0799\n",
      "Gradient norm for 'f0_f1.weight': 0.1403\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0047\n",
      "Gradient norm for 'f1_f2.weight': 0.5266\n",
      "Gradient norm for 'f2_f2.weight': 0.5104\n",
      "Gradient norm for 'f2_o.weight': 2.7967\n",
      "Epoch [48/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.11305\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.13077\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.10852\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.11251\n",
      "l1_score: 0\n",
      "Time elasped: 4.053751230239868\n",
      "Test Loss: 1.7827197313308716\n",
      "Avg spk_count per neuron for all 50 time-steps 5.789519786834717\n",
      "Avg spk per neuron per layer [10.662592480123674, 12.495486417844523]\n",
      "Test Accuracy of the model on the test samples: 72.792\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0008\n",
      "Gradient norm for 'tau_m_2': 0.0035\n",
      "Gradient norm for 'tau_m_o': 0.1155\n",
      "Gradient norm for 'f0_f1.weight': 0.1732\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0060\n",
      "Gradient norm for 'f1_f2.weight': 0.7107\n",
      "Gradient norm for 'f2_f2.weight': 0.6625\n",
      "Gradient norm for 'f2_o.weight': 3.8947\n",
      "Epoch [49/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.11633\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.12502\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.16585\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.14225\n",
      "l1_score: 0\n",
      "Time elasped: 4.014241695404053\n",
      "Test Loss: 1.6741458773612976\n",
      "Avg spk_count per neuron for all 50 time-steps 5.879746437072754\n",
      "Avg spk per neuron per layer [10.605862135600706, 12.913123895759718]\n",
      "Test Accuracy of the model on the test samples: 72.173\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0014\n",
      "Gradient norm for 'tau_m_2': 0.0056\n",
      "Gradient norm for 'tau_m_o': 0.2058\n",
      "Gradient norm for 'f0_f1.weight': 0.3172\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0125\n",
      "Gradient norm for 'f1_f2.weight': 1.1983\n",
      "Gradient norm for 'f2_f2.weight': 1.1222\n",
      "Gradient norm for 'f2_o.weight': 5.6047\n",
      "Epoch [50/50], learning_rates 0.001000, 0.100000\n",
      "Step [2/7], Loss: 0.12123\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.11032\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.15883\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.10293\n",
      "l1_score: 0\n",
      "Time elasped: 3.993340253829956\n",
      "Test Loss: 1.414250135421753\n",
      "Avg spk_count per neuron for all 50 time-steps 5.8814287185668945\n",
      "Avg spk per neuron per layer [10.779579836572438, 12.746135159010601]\n",
      "Test Accuracy of the model on the test samples: 74.293\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50_rnn\n",
      "Gradient norm for 'tau_m_1': 0.0006\n",
      "Gradient norm for 'tau_m_2': 0.0020\n",
      "Gradient norm for 'tau_m_o': 0.1014\n",
      "Gradient norm for 'f0_f1.weight': 0.1496\n",
      "Gradient norm for 'f1_f1.linear.weight': 0.0061\n",
      "Gradient norm for 'f1_f2.weight': 0.5957\n",
      "Gradient norm for 'f2_f2.weight': 0.5382\n",
      "Gradient norm for 'f2_o.weight': 2.8338\n"
     ]
    }
   ],
   "source": [
    "snn.to(device)\n",
    "train(snn, train_loader, test_loader, lr, num_epochs, dropout=0.0, \n",
    "    test_behavior=tb_save_max_last_acc, ckpt_dir=ckpt_dir, scheduler=(100, 0.95), test_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0881, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "        [-0.0000,  0.0075, -0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "        [-0.0000, -0.0000, -0.0290,  ..., -0.0000, -0.0000, -0.0000],\n",
      "        ...,\n",
      "        [-0.0000, -0.0000, -0.0000,  ..., -0.0883, -0.0000, -0.0000],\n",
      "        [-0.0000, -0.0000, -0.0000,  ..., -0.0000,  0.0364, -0.0000],\n",
      "        [-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.1238]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='input', ylabel='output'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(snn.f1_f1.linear.weight.data)\n",
    "plot_param(snn.f1_f1.linear, mode='2D', vminmax=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepsnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
