{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda:0\n",
      "[CropTime(min=0, max=1000000.0), ToFrame(sensor_size=(700, 1, 1), time_window=None, event_count=None, n_time_bins=50, n_event_bins=None, overlap=0, include_incomplete=False)]\n",
      "<class 'list'>\n",
      "\n",
      "[INFO] Delays: tensor([0])\n",
      "\n",
      "[INFO] Delays i: tensor([0])\n",
      "\n",
      "[INFO] Delays h: tensor([0])\n",
      "\n",
      "[INFO] Delays o: tensor([0])\n",
      "1000.0\n",
      "Delta t: 20.0 ms\n",
      "mean of normal: -0.541324854612918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SNN(\n",
       "  (criterion): CrossEntropyLoss()\n",
       "  (f0_f1): Linear(in_features=700, out_features=64, bias=False)\n",
       "  (f1_f2): Linear(in_features=192, out_features=64, bias=False)\n",
       "  (f2_o): Linear(in_features=64, out_features=20, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "from snn_delays.snn import SNN\n",
    "from snn_delays.utils.dataset_loader import DatasetLoader\n",
    "from snn_delays.utils.train_utils import train, get_device\n",
    "from snn_delays.utils.test_behavior import tb_save_max_last_acc\n",
    "\n",
    "'''\n",
    "SHD dataset as in ablation study\n",
    "'''\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "# for reproducibility\n",
    "torch.manual_seed(10)\n",
    "\n",
    "dataset = 'shd'\n",
    "total_time = 50\n",
    "batch_size = 1024\n",
    "\n",
    "# DATASET\n",
    "DL = DatasetLoader(dataset=dataset,\n",
    "                  caching='memory',\n",
    "                  num_workers=0,\n",
    "                  batch_size=batch_size,\n",
    "                  total_time=total_time,\n",
    "                  crop_to=1e6)\n",
    "train_loader, test_loader, dataset_dict = DL.get_dataloaders()\n",
    "          \n",
    "num_epochs = 50\n",
    "\n",
    "lr = 1e-3\n",
    "# SNN CON DELAYS\n",
    "taimu1 = time.time()\n",
    "\n",
    "tau_m = 'normal'\n",
    "ckpt_dir = 'exp3_shd50_rnn' \n",
    "\n",
    "snn = SNN(dataset_dict=dataset_dict, structure=(64, 2), connection_type='mf',\n",
    "    delay=None, delay_type='', tau_m = tau_m,\n",
    "    win=total_time, loss_fn='mem_sum', batch_size=batch_size, device=device,\n",
    "    debug=False)\n",
    "\n",
    "snn.multi_proj = 3\n",
    "\n",
    "snn.set_network()\n",
    "\n",
    "snn.to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 4.205689907073975\n",
      "Avg spk_count per neuron for all 50 time-steps 3.1771316528320312\n",
      "Avg spk per neuron per layer [7.587005615234375, 5.12152099609375]\n",
      "Test Accuracy of the model on the test samples: 3.613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a, b = snn.test(test_loader, only_one_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training shd50_l2_1d1.t7 for 50 epochs...\n",
      "Epoch [1/50], learning_rates 0.001000, 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [2/7], Loss: 4.13771\n",
      "l1_score: 0\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1063, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1160, in get_records\n",
      "    res = list(stack_data.FrameInfo.stack_data(etb, options=options))[tb_offset:]\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\stack_data\\core.py\", line 565, in stack_data\n",
      "    yield from collapse_repeated(\n",
      "  File \"c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\stack_data\\utils.py\", line 84, in collapse_repeated\n",
      "    yield from map(mapper, original_group)\n",
      "  File \"c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\stack_data\\core.py\", line 555, in mapper\n",
      "    return cls(f, options)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\stack_data\\core.py\", line 520, in __init__\n",
      "    self.executing = Source.executing(frame_or_tb)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\executing\\executing.py\", line 369, in executing\n",
      "    args = find(source=cls.for_frame(frame), retry_cache=True)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\executing\\executing.py\", line 252, in for_frame\n",
      "    return cls.for_filename(frame.f_code.co_filename, frame.f_globals or {}, use_cache)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\executing\\executing.py\", line 270, in for_filename\n",
      "    result = source_cache[filename] = cls._for_filename_and_lines(filename, lines)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\executing\\executing.py\", line 281, in _for_filename_and_lines\n",
      "    result = source_cache[(filename, lines)] = cls(filename, lines)\n",
      "                                               ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\stack_data\\core.py\", line 79, in __init__\n",
      "    super(Source, self).__init__(*args, **kwargs)\n",
      "  File \"c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\executing\\executing.py\", line 228, in __init__\n",
      "    self.tree = ast.parse(ast_text, filename=filename)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\ast.py\", line 52, in parse\n",
      "    return compile(source, filename, mode, flags,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "MemoryError\n"
     ]
    }
   ],
   "source": [
    "train(snn, train_loader, test_loader, lr, num_epochs, dropout=0.0, \n",
    "    test_behavior=tb_save_max_last_acc, ckpt_dir=ckpt_dir, scheduler=(100, 0.95), test_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 192])\n",
      "torch.Size([1024, 192])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1024, 64)\n",
    "print(x.repeat(1, 3).shape)\n",
    "print(x.repeat(1, 3).view(1024, -1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6131, 0.1452, 0.7860, 0.9258],\n",
       "        [0.0528, 0.9084, 0.4363, 0.9647],\n",
       "        [0.1770, 0.9467, 0.0742, 0.7290],\n",
       "        [0.0121, 0.6393, 0.0876, 0.3102],\n",
       "        [0.8581, 0.3634, 0.9454, 0.9337],\n",
       "        [0.5624, 0.9277, 0.4248, 0.9033],\n",
       "        [0.9952, 0.3456, 0.8911, 0.0317],\n",
       "        [0.9378, 0.7023, 0.0194, 0.6718],\n",
       "        [0.4343, 0.8132, 0.6807, 0.2210],\n",
       "        [0.7399, 0.4589, 0.8210, 0.1687]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(10, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6131, 0.1452, 0.7860, 0.9258, 0.6131, 0.1452, 0.7860, 0.9258, 0.6131,\n",
       "         0.1452, 0.7860, 0.9258],\n",
       "        [0.0528, 0.9084, 0.4363, 0.9647, 0.0528, 0.9084, 0.4363, 0.9647, 0.0528,\n",
       "         0.9084, 0.4363, 0.9647],\n",
       "        [0.1770, 0.9467, 0.0742, 0.7290, 0.1770, 0.9467, 0.0742, 0.7290, 0.1770,\n",
       "         0.9467, 0.0742, 0.7290],\n",
       "        [0.0121, 0.6393, 0.0876, 0.3102, 0.0121, 0.6393, 0.0876, 0.3102, 0.0121,\n",
       "         0.6393, 0.0876, 0.3102],\n",
       "        [0.8581, 0.3634, 0.9454, 0.9337, 0.8581, 0.3634, 0.9454, 0.9337, 0.8581,\n",
       "         0.3634, 0.9454, 0.9337],\n",
       "        [0.5624, 0.9277, 0.4248, 0.9033, 0.5624, 0.9277, 0.4248, 0.9033, 0.5624,\n",
       "         0.9277, 0.4248, 0.9033],\n",
       "        [0.9952, 0.3456, 0.8911, 0.0317, 0.9952, 0.3456, 0.8911, 0.0317, 0.9952,\n",
       "         0.3456, 0.8911, 0.0317],\n",
       "        [0.9378, 0.7023, 0.0194, 0.6718, 0.9378, 0.7023, 0.0194, 0.6718, 0.9378,\n",
       "         0.7023, 0.0194, 0.6718],\n",
       "        [0.4343, 0.8132, 0.6807, 0.2210, 0.4343, 0.8132, 0.6807, 0.2210, 0.4343,\n",
       "         0.8132, 0.6807, 0.2210],\n",
       "        [0.7399, 0.4589, 0.8210, 0.1687, 0.7399, 0.4589, 0.8210, 0.1687, 0.7399,\n",
       "         0.4589, 0.8210, 0.1687]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.repeat(1, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepsnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
