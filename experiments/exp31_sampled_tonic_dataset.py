{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tonic import MemoryCachedDataset\n",
    "from torch.utils.data import Dataset, Subset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Custom dataset for digit concatenation from a filtered dataset\n",
    "class SubDataset(Dataset):\n",
    "    def __init__(self, base_dataset, samples_per_class, target_classes):\n",
    "        self.base_dataset = base_dataset\n",
    "        indices = [i for i, (img, label) in enumerate(base_dataset) if np.argmax(label) in target_classes]\n",
    "        \n",
    "        self.filtered_dataset = Subset(base_dataset, indices)\n",
    "\n",
    "        self.indices = list(range(len(self.filtered_dataset)))  # Indices of the base dataset\n",
    "        \n",
    "        self.target_classes = target_classes\n",
    "        #self.pairs = [(i, j) for i in self.indices for j in self.indices]  # All possible pairs of indices\n",
    "        self.samples_per_class = samples_per_class\n",
    "        #self.pairs = list(product(self.indices, repeat=sequence_length))\n",
    "        self.num_classes = len(target_classes) # 0 is not a class \n",
    "        \n",
    "    def __len__(self):\n",
    "        # Number of pairs\n",
    "        #return len(self.pairs)\n",
    "        return len(self.base_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the indices for the current pair\n",
    "        #indices = self.pairs[idx]\n",
    "        # Retrieve the images and labels from the base dataset\n",
    "\n",
    "        images = []\n",
    "        all_labels = []\n",
    "        retrieval_labels = []\n",
    "\n",
    "        for i in range(self.sequence_length-2):\n",
    "            img, label = self.filtered_dataset[np.random.choice(self.indices)]\n",
    "            images.append(img)\n",
    "            all_labels.append(self.target_classes.index(np.argmax(label)))\n",
    "\n",
    "        # inserts zeroes randomly ()\n",
    "        idx_frst_zero = np.random.randint(self.sequence_length//2)\n",
    "        img, _ = self.zeros_dataset[np.random.choice(self.zeros_indices)]\n",
    "        images.insert(idx_frst_zero, img)\n",
    "        retrieval_labels.append(all_labels[idx_frst_zero])\n",
    "\n",
    "        idx_scnd_zero = np.random.randint(idx_frst_zero+2, self.sequence_length-1)\n",
    "        img, _ = self.zeros_dataset[np.random.choice(self.zeros_indices)]\n",
    "        images.insert(idx_scnd_zero, img)\n",
    "        retrieval_labels.append(all_labels[idx_scnd_zero-1])\n",
    "\n",
    "        # Concatenate the images along the width (you can adjust as needed)\n",
    "        concatenated_img = np.concatenate(images, axis=0)\n",
    "        \n",
    "        # Concatenate the labels one-hot\n",
    "        encoded_label = sum(l * (self.num_classes ** i) for i, l in enumerate(reversed(retrieval_labels)))\n",
    "        concatenated_label = np.zeros(self.total_combinations)\n",
    "        concatenated_label[encoded_label] = 1.0\n",
    "\n",
    "        return concatenated_img, concatenated_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset, Subset\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "from snn_delays.config import DATASET_PATH\n",
    "import os\n",
    "\n",
    "class SubDataset(Dataset):\n",
    "    def __init__(self, base_dataset, samples_per_class, target_classes, save_path='indexes'):\n",
    "\n",
    "        save_indices_path= os.path.join(DATASET_PATH, save_path)\n",
    "        self.base_dataset = base_dataset\n",
    "        self.samples_per_class = samples_per_class\n",
    "        self.target_classes = target_classes\n",
    "        self.num_classes = len(target_classes)\n",
    "        \n",
    "        class_counts = defaultdict(int)\n",
    "        indices = []\n",
    "        \n",
    "        for i, (_, label) in enumerate(base_dataset):\n",
    "            class_idx = np.argmax(label)\n",
    "            if class_idx in target_classes and class_counts[class_idx] < samples_per_class:\n",
    "                indices.append(i)\n",
    "                class_counts[class_idx] += 1\n",
    "                \n",
    "        self.filtered_dataset = Subset(base_dataset, indices)\n",
    "        self.indices = indices\n",
    "        \n",
    "        if save_indices_path:\n",
    "            with open(save_indices_path, 'wb') as f:\n",
    "                pickle.dump(self.indices, f)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.filtered_dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self.filtered_dataset):\n",
    "            raise IndexError(\"Index out of range for SubDataset\")\n",
    "        \n",
    "        img, label = self.filtered_dataset[idx]\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda:0\n",
      "[CropTime(min=0, max=1000000.0), ToFrame(sensor_size=(700, 1, 1), time_window=None, event_count=None, n_time_bins=50, n_event_bins=None, overlap=0, include_incomplete=False)]\n"
     ]
    }
   ],
   "source": [
    "from snn_delays.snn import SNN\n",
    "from snn_delays.utils.dataset_loader import DatasetLoader\n",
    "from snn_delays.utils.train_utils import train, get_device\n",
    "from snn_delays.utils.test_behavior import tb_save_max_last_acc\n",
    "import torch\n",
    "\n",
    "device = get_device()\n",
    "torch.manual_seed(10)\n",
    "\n",
    "dataset = 'shd'\n",
    "total_time = 50\n",
    "batch_size = 32\n",
    "\n",
    "# DATASET\n",
    "DL = DatasetLoader(dataset=dataset,\n",
    "                   caching='memory',\n",
    "                   num_workers=0,\n",
    "                   batch_size=batch_size,\n",
    "                   total_time=total_time,\n",
    "                   crop_to=1e6)\n",
    "\n",
    "_, __, dataset_dict = DL.get_dataloaders()\n",
    "\n",
    "target_classes = [x for x in range(20)]\n",
    "test_dataset = DL._dataset.test_dataset\n",
    "train_dataset = DL._dataset.train_dataset\n",
    "\n",
    "sub_train_dataset = SubDataset(train_dataset, 10, target_classes, f'{dataset}_10_train')\n",
    "sub_test_dataset = SubDataset(test_dataset, 10, target_classes, f'{dataset}_10_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 50, 1, 700])\n",
      "torch.Size([32, 50, 1, 700])\n",
      "torch.Size([32, 50, 1, 700])\n",
      "torch.Size([32, 50, 1, 700])\n",
      "torch.Size([32, 50, 1, 700])\n",
      "torch.Size([32, 50, 1, 700])\n",
      "torch.Size([8, 50, 1, 700])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MemoryCachedDataset(sub_train_dataset)\n",
    "test_dataset = MemoryCachedDataset(sub_test_dataset)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            drop_last=False,\n",
    "                            pin_memory=True,\n",
    "                            num_workers=0)\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            drop_last=False,\n",
    "                            pin_memory=True,\n",
    "                            num_workers=0)\n",
    "\n",
    "for x, y in train_loader:\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Delays: tensor([ 0, 16, 32])\n",
      "\n",
      "[INFO] Delays i: tensor([0])\n",
      "\n",
      "[INFO] Delays h: tensor([ 0, 16, 32])\n",
      "\n",
      "[INFO] Delays o: tensor([0])\n",
      "1000.0\n",
      "Delta t: 20.0 ms\n",
      "mean of normal: -0.541324854612918\n",
      "training shd50_l2_48d16.t7 for 100 epochs...\n",
      "Epoch [1/100], learning_rates 0.001000, 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [2/6], Loss: 3.00106\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 3.10128\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 3.08916\n",
      "l1_score: 0\n",
      "Time elasped: 2.447533369064331\n",
      "Epoch [2/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 2.93791\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 2.90847\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 2.89381\n",
      "l1_score: 0\n",
      "Time elasped: 2.561569929122925\n",
      "Epoch [3/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 2.79530\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 2.88531\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 2.81564\n",
      "l1_score: 0\n",
      "Time elasped: 2.387892007827759\n",
      "Epoch [4/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 2.65524\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 2.57609\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 2.76876\n",
      "l1_score: 0\n",
      "Time elasped: 2.4930062294006348\n",
      "Epoch [5/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 2.57873\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 2.69775\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 2.61444\n",
      "l1_score: 0\n",
      "Time elasped: 2.6294474601745605\n",
      "Test Loss: 2.561345168522426\n",
      "Avg spk_count per neuron for all 50 time-steps 3.668085813522339\n",
      "Avg spk per neuron per layer [8.5559375, 6.11640625]\n",
      "Test Accuracy of the model on the test samples: 25.000\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "saving max acc: 25.0\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "Epoch [6/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 2.52875\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 2.45869\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 2.43699\n",
      "l1_score: 0\n",
      "Time elasped: 2.2872025966644287\n",
      "Epoch [7/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 2.09935\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 2.12418\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 2.23348\n",
      "l1_score: 0\n",
      "Time elasped: 2.3397696018218994\n",
      "Epoch [8/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 1.95245\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 1.65259\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 1.83700\n",
      "l1_score: 0\n",
      "Time elasped: 2.4721150398254395\n",
      "Epoch [9/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 1.82942\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 1.74783\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 1.55843\n",
      "l1_score: 0\n",
      "Time elasped: 2.4320759773254395\n",
      "Epoch [10/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 1.35177\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 1.68585\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 1.84079\n",
      "l1_score: 0\n",
      "Time elasped: 2.462721586227417\n",
      "Test Loss: 1.927668639591762\n",
      "Avg spk_count per neuron for all 50 time-steps 4.610859394073486\n",
      "Avg spk per neuron per layer [10.270390625, 8.173046875]\n",
      "Test Accuracy of the model on the test samples: 39.000\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "saving max acc: 39.0\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "Epoch [11/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 1.14435\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 1.43842\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 1.40436\n",
      "l1_score: 0\n",
      "Time elasped: 2.3106799125671387\n",
      "Epoch [12/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 1.12537\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 1.31081\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 1.40453\n",
      "l1_score: 0\n",
      "Time elasped: 2.238522529602051\n",
      "Epoch [13/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 1.14429\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.91031\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 1.60744\n",
      "l1_score: 0\n",
      "Time elasped: 2.3665771484375\n",
      "Epoch [14/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 1.04413\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 1.14665\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 1.25376\n",
      "l1_score: 0\n",
      "Time elasped: 2.2200582027435303\n",
      "Epoch [15/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.98202\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 1.20252\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.86798\n",
      "l1_score: 0\n",
      "Time elasped: 2.3091869354248047\n",
      "Test Loss: 1.6171397311346871\n",
      "Avg spk_count per neuron for all 50 time-steps 4.550175666809082\n",
      "Avg spk per neuron per layer [10.148984375, 8.05171875]\n",
      "Test Accuracy of the model on the test samples: 47.000\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "saving max acc: 47.0\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "Epoch [16/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.90663\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.59603\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.83271\n",
      "l1_score: 0\n",
      "Time elasped: 2.3168461322784424\n",
      "Epoch [17/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.48980\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.39336\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.56318\n",
      "l1_score: 0\n",
      "Time elasped: 2.286810874938965\n",
      "Epoch [18/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.48087\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.70852\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.39081\n",
      "l1_score: 0\n",
      "Time elasped: 2.2594521045684814\n",
      "Epoch [19/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.73943\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.73110\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.56254\n",
      "l1_score: 0\n",
      "Time elasped: 2.297611713409424\n",
      "Epoch [20/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.50138\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.29552\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.43301\n",
      "l1_score: 0\n",
      "Time elasped: 2.2986979484558105\n",
      "Test Loss: 2.1013867344175066\n",
      "Avg spk_count per neuron for all 50 time-steps 4.858710765838623\n",
      "Avg spk per neuron per layer [10.805078125, 8.629765625]\n",
      "Test Accuracy of the model on the test samples: 51.000\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "saving max acc: 51.0\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "Epoch [21/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.43761\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.40907\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 1.08431\n",
      "l1_score: 0\n",
      "Time elasped: 2.276763916015625\n",
      "Epoch [22/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.25833\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.27312\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.42514\n",
      "l1_score: 0\n",
      "Time elasped: 2.2402288913726807\n",
      "Epoch [23/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.34842\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.15161\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.07979\n",
      "l1_score: 0\n",
      "Time elasped: 2.204056739807129\n",
      "Epoch [24/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.37346\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.11490\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.36927\n",
      "l1_score: 0\n",
      "Time elasped: 2.2930967807769775\n",
      "Epoch [25/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.15721\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.31925\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.14258\n",
      "l1_score: 0\n",
      "Time elasped: 2.2416038513183594\n",
      "Test Loss: 2.68425406728472\n",
      "Avg spk_count per neuron for all 50 time-steps 4.667089939117432\n",
      "Avg spk per neuron per layer [10.033984375, 8.634375]\n",
      "Test Accuracy of the model on the test samples: 45.000\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "Epoch [26/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.22560\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.17699\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.28596\n",
      "l1_score: 0\n",
      "Time elasped: 2.2393712997436523\n",
      "Epoch [27/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.07791\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.33584\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.07665\n",
      "l1_score: 0\n",
      "Time elasped: 2.208467960357666\n",
      "Epoch [28/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.12969\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.10112\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.12303\n",
      "l1_score: 0\n",
      "Time elasped: 2.243429183959961\n",
      "Epoch [29/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.19896\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.35821\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.11711\n",
      "l1_score: 0\n",
      "Time elasped: 2.3011646270751953\n",
      "Epoch [30/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.29056\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.05403\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.31287\n",
      "l1_score: 0\n",
      "Time elasped: 2.2870514392852783\n",
      "Test Loss: 2.2245590005602156\n",
      "Avg spk_count per neuron for all 50 time-steps 4.63162088394165\n",
      "Avg spk per neuron per layer [9.99625, 8.530234375]\n",
      "Test Accuracy of the model on the test samples: 48.000\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "Epoch [31/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.28165\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.03393\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.05792\n",
      "l1_score: 0\n",
      "Time elasped: 2.3583178520202637\n",
      "Epoch [32/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.24633\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.04022\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.06392\n",
      "l1_score: 0\n",
      "Time elasped: 2.2476966381073\n",
      "Epoch [33/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.04176\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.02871\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.01563\n",
      "l1_score: 0\n",
      "Time elasped: 2.262040138244629\n",
      "Epoch [34/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.28828\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.02785\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.05257\n",
      "l1_score: 0\n",
      "Time elasped: 2.268293619155884\n",
      "Epoch [35/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.01185\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.03457\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.16495\n",
      "l1_score: 0\n",
      "Time elasped: 2.3540775775909424\n",
      "Test Loss: 1.8868563686098372\n",
      "Avg spk_count per neuron for all 50 time-steps 4.625195026397705\n",
      "Avg spk per neuron per layer [9.990859375, 8.509921875]\n",
      "Test Accuracy of the model on the test samples: 52.500\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "saving max acc: 52.5\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "Epoch [36/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.03072\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.02467\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.09032\n",
      "l1_score: 0\n",
      "Time elasped: 2.427452802658081\n",
      "Epoch [37/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.01376\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.05197\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.04421\n",
      "l1_score: 0\n",
      "Time elasped: 2.3760881423950195\n",
      "Epoch [38/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.03182\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.03057\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.02077\n",
      "l1_score: 0\n",
      "Time elasped: 2.296607255935669\n",
      "Epoch [39/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00418\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00237\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.01323\n",
      "l1_score: 0\n",
      "Time elasped: 2.2077176570892334\n",
      "Epoch [40/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.01598\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00324\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00162\n",
      "l1_score: 0\n",
      "Time elasped: 2.1801412105560303\n",
      "Test Loss: 1.9573613405227661\n",
      "Avg spk_count per neuron for all 50 time-steps 4.6650390625\n",
      "Avg spk per neuron per layer [9.9871875, 8.67296875]\n",
      "Test Accuracy of the model on the test samples: 55.000\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "saving max acc: 55.0\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "Epoch [41/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00116\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00276\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.01126\n",
      "l1_score: 0\n",
      "Time elasped: 2.242811679840088\n",
      "Epoch [42/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00105\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00441\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.02154\n",
      "l1_score: 0\n",
      "Time elasped: 2.3236656188964844\n",
      "Epoch [43/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00239\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00186\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00733\n",
      "l1_score: 0\n",
      "Time elasped: 2.2591476440429688\n",
      "Epoch [44/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00970\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00502\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00161\n",
      "l1_score: 0\n",
      "Time elasped: 2.2606592178344727\n",
      "Epoch [45/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00223\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00117\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00076\n",
      "l1_score: 0\n",
      "Time elasped: 2.211010694503784\n",
      "Test Loss: 1.8827508006777083\n",
      "Avg spk_count per neuron for all 50 time-steps 4.698554515838623\n",
      "Avg spk per neuron per layer [9.95921875, 8.835]\n",
      "Test Accuracy of the model on the test samples: 57.500\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "saving max acc: 57.5\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "Epoch [46/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00218\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00138\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00210\n",
      "l1_score: 0\n",
      "Time elasped: 2.224036693572998\n",
      "Epoch [47/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00146\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00184\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00147\n",
      "l1_score: 0\n",
      "Time elasped: 2.2326698303222656\n",
      "Epoch [48/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00088\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00231\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00079\n",
      "l1_score: 0\n",
      "Time elasped: 2.251460075378418\n",
      "Epoch [49/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00128\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00063\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00145\n",
      "l1_score: 0\n",
      "Time elasped: 2.4327924251556396\n",
      "Epoch [50/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00061\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00052\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00167\n",
      "l1_score: 0\n",
      "Time elasped: 2.2972822189331055\n",
      "Test Loss: 2.0142606667109897\n",
      "Avg spk_count per neuron for all 50 time-steps 4.696581840515137\n",
      "Avg spk per neuron per layer [9.963203125, 8.823125]\n",
      "Test Accuracy of the model on the test samples: 57.000\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "Epoch [51/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00081\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00140\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00075\n",
      "l1_score: 0\n",
      "Time elasped: 2.2473671436309814\n",
      "Epoch [52/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00102\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00081\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00075\n",
      "l1_score: 0\n",
      "Time elasped: 2.252636671066284\n",
      "Epoch [53/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00089\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00115\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00055\n",
      "l1_score: 0\n",
      "Time elasped: 2.190600872039795\n",
      "Epoch [54/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00086\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00064\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00092\n",
      "l1_score: 0\n",
      "Time elasped: 2.3554325103759766\n",
      "Epoch [55/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00046\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00129\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00088\n",
      "l1_score: 0\n",
      "Time elasped: 2.245213508605957\n",
      "Test Loss: 2.00545380796705\n",
      "Avg spk_count per neuron for all 50 time-steps 4.708456993103027\n",
      "Avg spk per neuron per layer [9.971171875, 8.86265625]\n",
      "Test Accuracy of the model on the test samples: 56.000\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "Epoch [56/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00046\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00031\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00071\n",
      "l1_score: 0\n",
      "Time elasped: 2.263556957244873\n",
      "Epoch [57/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00033\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00089\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00070\n",
      "l1_score: 0\n",
      "Time elasped: 2.2269816398620605\n",
      "Epoch [58/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00097\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00043\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00041\n",
      "l1_score: 0\n",
      "Time elasped: 2.214815378189087\n",
      "Epoch [59/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00041\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00085\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00042\n",
      "l1_score: 0\n",
      "Time elasped: 2.2774906158447266\n",
      "Epoch [60/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00043\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00031\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00047\n",
      "l1_score: 0\n",
      "Time elasped: 2.223644971847534\n",
      "Test Loss: 1.974116223199027\n",
      "Avg spk_count per neuron for all 50 time-steps 4.713085651397705\n",
      "Avg spk per neuron per layer [9.971875, 8.88046875]\n",
      "Test Accuracy of the model on the test samples: 57.000\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "Epoch [61/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00043\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00052\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00090\n",
      "l1_score: 0\n",
      "Time elasped: 2.427313804626465\n",
      "Epoch [62/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00070\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00070\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00037\n",
      "l1_score: 0\n",
      "Time elasped: 2.232630968093872\n",
      "Epoch [63/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00035\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00062\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00057\n",
      "l1_score: 0\n",
      "Time elasped: 2.303191661834717\n",
      "Epoch [64/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00061\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00035\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00037\n",
      "l1_score: 0\n",
      "Time elasped: 2.20953106880188\n",
      "Epoch [65/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00039\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00035\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00056\n",
      "l1_score: 0\n",
      "Time elasped: 2.2562787532806396\n",
      "Test Loss: 2.302672420229231\n",
      "Avg spk_count per neuron for all 50 time-steps 4.719941139221191\n",
      "Avg spk per neuron per layer [9.97125, 8.908515625]\n",
      "Test Accuracy of the model on the test samples: 55.000\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "Epoch [66/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00019\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00034\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00031\n",
      "l1_score: 0\n",
      "Time elasped: 2.2915451526641846\n",
      "Epoch [67/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00035\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00065\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00053\n",
      "l1_score: 0\n",
      "Time elasped: 2.235975742340088\n",
      "Epoch [68/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00029\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00026\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00050\n",
      "l1_score: 0\n",
      "Time elasped: 2.1802101135253906\n",
      "Epoch [69/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00035\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00035\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00020\n",
      "l1_score: 0\n",
      "Time elasped: 2.204104423522949\n",
      "Epoch [70/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00042\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00055\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00019\n",
      "l1_score: 0\n",
      "Time elasped: 2.2239089012145996\n",
      "Test Loss: 1.9082603284290858\n",
      "Avg spk_count per neuron for all 50 time-steps 4.726171970367432\n",
      "Avg spk per neuron per layer [9.97984375, 8.92484375]\n",
      "Test Accuracy of the model on the test samples: 54.500\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "Epoch [71/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00040\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00045\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00031\n",
      "l1_score: 0\n",
      "Time elasped: 2.3966894149780273\n",
      "Epoch [72/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00011\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00032\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00025\n",
      "l1_score: 0\n",
      "Time elasped: 2.3154916763305664\n",
      "Epoch [73/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00031\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00045\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00027\n",
      "l1_score: 0\n",
      "Time elasped: 2.8044633865356445\n",
      "Epoch [74/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00030\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00026\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00027\n",
      "l1_score: 0\n",
      "Time elasped: 2.519643783569336\n",
      "Epoch [75/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00034\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00033\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00031\n",
      "l1_score: 0\n",
      "Time elasped: 2.829141139984131\n",
      "Test Loss: 2.019083176340376\n",
      "Avg spk_count per neuron for all 50 time-steps 4.728359222412109\n",
      "Avg spk per neuron per layer [9.978359375, 8.935078125]\n",
      "Test Accuracy of the model on the test samples: 53.500\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "Epoch [76/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00029\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00048\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00035\n",
      "l1_score: 0\n",
      "Time elasped: 3.1956677436828613\n",
      "Epoch [77/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00040\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00056\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00024\n",
      "l1_score: 0\n",
      "Time elasped: 2.9208831787109375\n",
      "Epoch [78/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00027\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00029\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00028\n",
      "l1_score: 0\n",
      "Time elasped: 2.771188259124756\n",
      "Epoch [79/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00022\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00023\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00035\n",
      "l1_score: 0\n",
      "Time elasped: 2.7808823585510254\n",
      "Epoch [80/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00025\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00016\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00021\n",
      "l1_score: 0\n",
      "Time elasped: 2.963055372238159\n",
      "Test Loss: 2.1965714522770474\n",
      "Avg spk_count per neuron for all 50 time-steps 4.731328010559082\n",
      "Avg spk per neuron per layer [9.98015625, 8.94515625]\n",
      "Test Accuracy of the model on the test samples: 54.000\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "Epoch [81/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00040\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00033\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00029\n",
      "l1_score: 0\n",
      "Time elasped: 3.150355100631714\n",
      "Epoch [82/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00017\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00048\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00025\n",
      "l1_score: 0\n",
      "Time elasped: 2.9289276599884033\n",
      "Epoch [83/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00017\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00033\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00023\n",
      "l1_score: 0\n",
      "Time elasped: 3.177034378051758\n",
      "Epoch [84/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00015\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00041\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00027\n",
      "l1_score: 0\n",
      "Time elasped: 3.1842856407165527\n",
      "Epoch [85/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00020\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00021\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00034\n",
      "l1_score: 0\n",
      "Time elasped: 2.5870018005371094\n",
      "Test Loss: 2.019523322582245\n",
      "Avg spk_count per neuron for all 50 time-steps 4.735038757324219\n",
      "Avg spk per neuron per layer [9.981640625, 8.958515625]\n",
      "Test Accuracy of the model on the test samples: 54.000\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "Epoch [86/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00043\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00023\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00020\n",
      "l1_score: 0\n",
      "Time elasped: 2.8801157474517822\n",
      "Epoch [87/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00033\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00029\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00021\n",
      "l1_score: 0\n",
      "Time elasped: 2.6765260696411133\n",
      "Epoch [88/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00019\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00023\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00022\n",
      "l1_score: 0\n",
      "Time elasped: 2.829007863998413\n",
      "Epoch [89/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00013\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00020\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00025\n",
      "l1_score: 0\n",
      "Time elasped: 2.3869829177856445\n",
      "Epoch [90/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00017\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00015\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00029\n",
      "l1_score: 0\n",
      "Time elasped: 2.356074571609497\n",
      "Test Loss: 2.3306431600025723\n",
      "Avg spk_count per neuron for all 50 time-steps 4.738945007324219\n",
      "Avg spk per neuron per layer [9.981484375, 8.974296875]\n",
      "Test Accuracy of the model on the test samples: 54.500\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "Epoch [91/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00013\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00017\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00034\n",
      "l1_score: 0\n",
      "Time elasped: 2.382641553878784\n",
      "Epoch [92/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00034\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00017\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00023\n",
      "l1_score: 0\n",
      "Time elasped: 2.3415451049804688\n",
      "Epoch [93/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00015\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00028\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00021\n",
      "l1_score: 0\n",
      "Time elasped: 2.4826548099517822\n",
      "Epoch [94/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00020\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00027\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00021\n",
      "l1_score: 0\n",
      "Time elasped: 2.3882803916931152\n",
      "Epoch [95/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00020\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00019\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00034\n",
      "l1_score: 0\n",
      "Time elasped: 2.363952875137329\n",
      "Test Loss: 2.0609178372791837\n",
      "Avg spk_count per neuron for all 50 time-steps 4.744160175323486\n",
      "Avg spk per neuron per layer [9.9859375, 8.990703125]\n",
      "Test Accuracy of the model on the test samples: 54.500\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "Epoch [96/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00011\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00015\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00017\n",
      "l1_score: 0\n",
      "Time elasped: 2.387328863143921\n",
      "Epoch [97/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00015\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00013\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00021\n",
      "l1_score: 0\n",
      "Time elasped: 2.603947877883911\n",
      "Epoch [98/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00023\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00022\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00015\n",
      "l1_score: 0\n",
      "Time elasped: 2.4535112380981445\n",
      "Epoch [99/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00019\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00013\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00023\n",
      "l1_score: 0\n",
      "Time elasped: 2.4103140830993652\n",
      "Epoch [100/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00029\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00019\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00014\n",
      "l1_score: 0\n",
      "Time elasped: 2.3721659183502197\n",
      "Test Loss: 1.9324407407215662\n",
      "Avg spk_count per neuron for all 50 time-steps 4.746288776397705\n",
      "Avg spk per neuron per layer [9.98734375, 8.9978125]\n",
      "Test Accuracy of the model on the test samples: 54.500\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n"
     ]
    }
   ],
   "source": [
    "ckpt_dir = 'default' \n",
    "dataset_dict['num_training_samples'] = 200\n",
    "\n",
    "snn = SNN(dataset_dict=dataset_dict, structure=(64, 2), connection_type='f',\n",
    "    delay=(48,16), delay_type='h', tau_m = 'normal',\n",
    "    win=total_time, loss_fn='mem_sum', batch_size=batch_size, device=device,\n",
    "    debug=False)\n",
    "\n",
    "snn.set_network()\n",
    "\n",
    "snn.to(device)\n",
    "\n",
    "num_epochs = 100\n",
    "train(snn, train_loader, test_loader, 1e-3, num_epochs, dropout=0.0, \n",
    "    test_behavior=tb_save_max_last_acc, ckpt_dir=ckpt_dir, scheduler=(100, 0.95), test_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'streamlit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstreamlit\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mst\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'streamlit'"
     ]
    }
   ],
   "source": [
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepsnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
