{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset, Subset, DataLoader\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "from snn_delays.config import DATASET_PATH\n",
    "import os\n",
    "from tonic import MemoryCachedDataset\n",
    "\n",
    "class SubDataset(Dataset):\n",
    "    def __init__(self, base_dataset, samples_per_class, target_classes, save_path='indexes'):\n",
    "\n",
    "        save_indices_path= os.path.join(DATASET_PATH, save_path)\n",
    "        self.base_dataset = base_dataset\n",
    "        self.samples_per_class = samples_per_class\n",
    "        self.target_classes = target_classes\n",
    "        self.num_classes = len(target_classes)\n",
    "\n",
    "        if os.path.exists(save_indices_path):\n",
    "            with open(save_indices_path, 'rb') as f:\n",
    "                indices = pickle.load(f)\n",
    "        \n",
    "        else:\n",
    "            class_counts = defaultdict(int)\n",
    "            indices = []\n",
    "            \n",
    "            for i, (_, label) in enumerate(base_dataset):\n",
    "                class_idx = np.argmax(label)\n",
    "                if class_idx in target_classes and class_counts[class_idx] < samples_per_class:\n",
    "                    indices.append(i)\n",
    "                    class_counts[class_idx] += 1\n",
    "            with open(save_indices_path, 'wb') as f:\n",
    "                pickle.dump(indices, f)\n",
    "    \n",
    "        self.filtered_dataset = Subset(base_dataset, indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filtered_dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self.filtered_dataset):\n",
    "            raise IndexError(\"Index out of range for SubDataset\")\n",
    "        \n",
    "        img, label = self.filtered_dataset[idx]\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda:0\n",
      "[CropTime(min=0, max=1000000.0), ToFrame(sensor_size=(700, 1, 1), time_window=None, event_count=None, n_time_bins=50, n_event_bins=None, overlap=0, include_incomplete=False)]\n"
     ]
    }
   ],
   "source": [
    "from snn_delays.snn import SNN\n",
    "from snn_delays.utils.dataset_loader import DatasetLoader\n",
    "from snn_delays.utils.train_utils import train, get_device\n",
    "from snn_delays.utils.test_behavior import tb_save_max_last_acc\n",
    "import torch\n",
    "\n",
    "device = get_device()\n",
    "torch.manual_seed(10)\n",
    "\n",
    "dataset = 'shd'\n",
    "total_time = 50\n",
    "batch_size = 32\n",
    "\n",
    "# DATASET\n",
    "DL = DatasetLoader(dataset=dataset,\n",
    "                   caching='memory',\n",
    "                   num_workers=0,\n",
    "                   batch_size=batch_size,\n",
    "                   total_time=total_time,\n",
    "                   crop_to=1e6)\n",
    "\n",
    "_, __, dataset_dict = DL.get_dataloaders()\n",
    "\n",
    "target_classes = [x for x in range(20)]\n",
    "test_dataset = DL._dataset.test_dataset\n",
    "train_dataset = DL._dataset.train_dataset\n",
    "\n",
    "sub_train_dataset = SubDataset(train_dataset, 10, target_classes, f'{dataset}_10_train')\n",
    "sub_test_dataset = SubDataset(test_dataset, 10, target_classes, f'{dataset}_10_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 50, 1, 700])\n",
      "torch.Size([32, 50, 1, 700])\n",
      "torch.Size([32, 50, 1, 700])\n",
      "torch.Size([32, 50, 1, 700])\n",
      "torch.Size([32, 50, 1, 700])\n",
      "torch.Size([32, 50, 1, 700])\n",
      "torch.Size([8, 50, 1, 700])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MemoryCachedDataset(sub_train_dataset)\n",
    "test_dataset = MemoryCachedDataset(sub_test_dataset)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            drop_last=False,\n",
    "                            pin_memory=True,\n",
    "                            num_workers=0)\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            drop_last=False,\n",
    "                            pin_memory=True,\n",
    "                            num_workers=0)\n",
    "\n",
    "for x, y in train_loader:\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Delays: tensor([ 0, 16, 32])\n",
      "\n",
      "[INFO] Delays i: tensor([0])\n",
      "\n",
      "[INFO] Delays h: tensor([ 0, 16, 32])\n",
      "\n",
      "[INFO] Delays o: tensor([0])\n",
      "1000.0\n",
      "Delta t: 20.0 ms\n",
      "mean of normal: -0.541324854612918\n",
      "training shd50_l2_48d16.t7 for 100 epochs...\n",
      "Epoch [1/100], learning_rates 0.001000, 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [2/6], Loss: 3.00106\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 3.10128\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 3.08916\n",
      "l1_score: 0\n",
      "Time elasped: 1.5265278816223145\n",
      "Epoch [2/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 2.93791\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 2.90847\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 2.89381\n",
      "l1_score: 0\n",
      "Time elasped: 1.4291386604309082\n",
      "Epoch [3/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 2.79530\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 2.88531\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 2.81564\n",
      "l1_score: 0\n",
      "Time elasped: 1.472402572631836\n",
      "Epoch [4/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 2.65524\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 2.57609\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 2.76876\n",
      "l1_score: 0\n",
      "Time elasped: 1.469801425933838\n",
      "Epoch [5/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 2.57873\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 2.69775\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 2.61444\n",
      "l1_score: 0\n",
      "Time elasped: 1.4423315525054932\n",
      "Test Loss: 2.561345168522426\n",
      "Avg spk_count per neuron for all 50 time-steps 3.668085813522339\n",
      "Avg spk per neuron per layer [8.5559375, 6.11640625]\n",
      "Test Accuracy of the model on the test samples: 25.000\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "saving max acc: 25.0\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "Epoch [6/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 2.52875\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 2.45869\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 2.43699\n",
      "l1_score: 0\n",
      "Time elasped: 1.4670350551605225\n",
      "Epoch [7/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 2.09935\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 2.12418\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 2.23348\n",
      "l1_score: 0\n",
      "Time elasped: 1.4661319255828857\n",
      "Epoch [8/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 1.95245\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 1.65259\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 1.83700\n",
      "l1_score: 0\n",
      "Time elasped: 1.4588048458099365\n",
      "Epoch [9/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 1.82942\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 1.74783\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 1.55843\n",
      "l1_score: 0\n",
      "Time elasped: 1.4478778839111328\n",
      "Epoch [10/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 1.35177\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 1.68585\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 1.84079\n",
      "l1_score: 0\n",
      "Time elasped: 1.479100227355957\n",
      "Test Loss: 1.927668639591762\n",
      "Avg spk_count per neuron for all 50 time-steps 4.610859394073486\n",
      "Avg spk per neuron per layer [10.270390625, 8.173046875]\n",
      "Test Accuracy of the model on the test samples: 39.000\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "saving max acc: 39.0\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "Epoch [11/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 1.14435\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 1.43842\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 1.40436\n",
      "l1_score: 0\n",
      "Time elasped: 1.795879602432251\n",
      "Epoch [12/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 1.12537\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 1.31081\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 1.40453\n",
      "l1_score: 0\n",
      "Time elasped: 1.631371259689331\n",
      "Epoch [13/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 1.14429\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.91031\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 1.60744\n",
      "l1_score: 0\n",
      "Time elasped: 1.5748264789581299\n",
      "Epoch [14/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 1.04413\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 1.14665\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 1.25376\n",
      "l1_score: 0\n",
      "Time elasped: 1.5712392330169678\n",
      "Epoch [15/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.98202\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 1.20252\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.86798\n",
      "l1_score: 0\n",
      "Time elasped: 1.530543565750122\n",
      "Test Loss: 1.6171397311346871\n",
      "Avg spk_count per neuron for all 50 time-steps 4.550175666809082\n",
      "Avg spk per neuron per layer [10.148984375, 8.05171875]\n",
      "Test Accuracy of the model on the test samples: 47.000\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "saving max acc: 47.0\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "Epoch [16/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.90663\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.59603\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.83271\n",
      "l1_score: 0\n",
      "Time elasped: 1.6004645824432373\n",
      "Epoch [17/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.48980\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.39336\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.56318\n",
      "l1_score: 0\n",
      "Time elasped: 1.6319727897644043\n",
      "Epoch [18/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.48087\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.70852\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.39081\n",
      "l1_score: 0\n",
      "Time elasped: 1.5824458599090576\n",
      "Epoch [19/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.73943\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.73110\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.56254\n",
      "l1_score: 0\n",
      "Time elasped: 1.5043926239013672\n",
      "Epoch [20/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.50138\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.29552\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.43301\n",
      "l1_score: 0\n",
      "Time elasped: 1.6467552185058594\n",
      "Test Loss: 2.1013867344175066\n",
      "Avg spk_count per neuron for all 50 time-steps 4.858710765838623\n",
      "Avg spk per neuron per layer [10.805078125, 8.629765625]\n",
      "Test Accuracy of the model on the test samples: 51.000\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "saving max acc: 51.0\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "Epoch [21/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.43761\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.40907\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 1.08431\n",
      "l1_score: 0\n",
      "Time elasped: 2.2773935794830322\n",
      "Epoch [22/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.25833\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.27312\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.42514\n",
      "l1_score: 0\n",
      "Time elasped: 2.204976797103882\n",
      "Epoch [23/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.34842\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.15161\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.07979\n",
      "l1_score: 0\n",
      "Time elasped: 2.129171848297119\n",
      "Epoch [24/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.37346\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.11490\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.36927\n",
      "l1_score: 0\n",
      "Time elasped: 2.136199712753296\n",
      "Epoch [25/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.15721\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.31925\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.14258\n",
      "l1_score: 0\n",
      "Time elasped: 2.30423903465271\n",
      "Test Loss: 2.68425406728472\n",
      "Avg spk_count per neuron for all 50 time-steps 4.667089939117432\n",
      "Avg spk per neuron per layer [10.033984375, 8.634375]\n",
      "Test Accuracy of the model on the test samples: 45.000\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "Epoch [26/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.22560\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.17699\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.28596\n",
      "l1_score: 0\n",
      "Time elasped: 2.2717418670654297\n",
      "Epoch [27/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.07791\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.33584\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.07665\n",
      "l1_score: 0\n",
      "Time elasped: 2.2681612968444824\n",
      "Epoch [28/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.12969\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.10112\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.12303\n",
      "l1_score: 0\n",
      "Time elasped: 2.3778891563415527\n",
      "Epoch [29/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.19896\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.35821\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.11711\n",
      "l1_score: 0\n",
      "Time elasped: 2.3719499111175537\n",
      "Epoch [30/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.29056\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.05403\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.31287\n",
      "l1_score: 0\n",
      "Time elasped: 2.172450542449951\n",
      "Test Loss: 2.2245590005602156\n",
      "Avg spk_count per neuron for all 50 time-steps 4.63162088394165\n",
      "Avg spk per neuron per layer [9.99625, 8.530234375]\n",
      "Test Accuracy of the model on the test samples: 48.000\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "Epoch [31/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.28165\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.03393\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.05792\n",
      "l1_score: 0\n",
      "Time elasped: 2.253842830657959\n",
      "Epoch [32/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.24633\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.04022\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.06392\n",
      "l1_score: 0\n",
      "Time elasped: 2.329033851623535\n",
      "Epoch [33/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.04176\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.02871\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.01563\n",
      "l1_score: 0\n",
      "Time elasped: 2.3840901851654053\n",
      "Epoch [34/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.28828\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.02785\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.05257\n",
      "l1_score: 0\n",
      "Time elasped: 2.449845552444458\n",
      "Epoch [35/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.01185\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.03457\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.16495\n",
      "l1_score: 0\n",
      "Time elasped: 2.3561437129974365\n",
      "Test Loss: 1.8868563686098372\n",
      "Avg spk_count per neuron for all 50 time-steps 4.625195026397705\n",
      "Avg spk per neuron per layer [9.990859375, 8.509921875]\n",
      "Test Accuracy of the model on the test samples: 52.500\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "saving max acc: 52.5\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "Epoch [36/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.03072\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.02467\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.09032\n",
      "l1_score: 0\n",
      "Time elasped: 1.9240310192108154\n",
      "Epoch [37/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.01376\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.05197\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.04421\n",
      "l1_score: 0\n",
      "Time elasped: 1.9199857711791992\n",
      "Epoch [38/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.03182\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.03057\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.02077\n",
      "l1_score: 0\n",
      "Time elasped: 1.9101340770721436\n",
      "Epoch [39/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00418\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00237\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.01323\n",
      "l1_score: 0\n",
      "Time elasped: 1.9887540340423584\n",
      "Epoch [40/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.01598\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00324\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00162\n",
      "l1_score: 0\n",
      "Time elasped: 2.4190900325775146\n",
      "Test Loss: 1.9573613405227661\n",
      "Avg spk_count per neuron for all 50 time-steps 4.6650390625\n",
      "Avg spk per neuron per layer [9.9871875, 8.67296875]\n",
      "Test Accuracy of the model on the test samples: 55.000\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "saving max acc: 55.0\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "Epoch [41/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00116\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00276\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.01126\n",
      "l1_score: 0\n",
      "Time elasped: 2.148120164871216\n",
      "Epoch [42/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00105\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00441\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.02154\n",
      "l1_score: 0\n",
      "Time elasped: 2.1577353477478027\n",
      "Epoch [43/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00239\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00186\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00733\n",
      "l1_score: 0\n",
      "Time elasped: 2.061429262161255\n",
      "Epoch [44/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00970\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00502\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00161\n",
      "l1_score: 0\n",
      "Time elasped: 2.2231459617614746\n",
      "Epoch [45/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00223\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00117\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00076\n",
      "l1_score: 0\n",
      "Time elasped: 2.0763394832611084\n",
      "Test Loss: 1.8827508006777083\n",
      "Avg spk_count per neuron for all 50 time-steps 4.698554515838623\n",
      "Avg spk per neuron per layer [9.95921875, 8.835]\n",
      "Test Accuracy of the model on the test samples: 57.500\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "saving max acc: 57.5\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "Epoch [46/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00218\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00138\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00210\n",
      "l1_score: 0\n",
      "Time elasped: 2.1401336193084717\n",
      "Epoch [47/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00146\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00184\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00147\n",
      "l1_score: 0\n",
      "Time elasped: 2.134284496307373\n",
      "Epoch [48/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00088\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00231\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00079\n",
      "l1_score: 0\n",
      "Time elasped: 2.128117799758911\n",
      "Epoch [49/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00128\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00063\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00145\n",
      "l1_score: 0\n",
      "Time elasped: 2.075610399246216\n",
      "Epoch [50/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00061\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00052\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00167\n",
      "l1_score: 0\n",
      "Time elasped: 2.158311128616333\n",
      "Test Loss: 2.0142606667109897\n",
      "Avg spk_count per neuron for all 50 time-steps 4.696581840515137\n",
      "Avg spk per neuron per layer [9.963203125, 8.823125]\n",
      "Test Accuracy of the model on the test samples: 57.000\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "Epoch [51/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00081\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00140\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00075\n",
      "l1_score: 0\n",
      "Time elasped: 2.1161811351776123\n",
      "Epoch [52/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00102\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00081\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00075\n",
      "l1_score: 0\n",
      "Time elasped: 2.1290152072906494\n",
      "Epoch [53/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00089\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00115\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00055\n",
      "l1_score: 0\n",
      "Time elasped: 2.0962369441986084\n",
      "Epoch [54/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00086\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00064\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00092\n",
      "l1_score: 0\n",
      "Time elasped: 2.1440064907073975\n",
      "Epoch [55/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00046\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00129\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00088\n",
      "l1_score: 0\n",
      "Time elasped: 2.1607749462127686\n",
      "Test Loss: 2.00545380796705\n",
      "Avg spk_count per neuron for all 50 time-steps 4.708456993103027\n",
      "Avg spk per neuron per layer [9.971171875, 8.86265625]\n",
      "Test Accuracy of the model on the test samples: 56.000\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "Epoch [56/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00046\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00031\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00071\n",
      "l1_score: 0\n",
      "Time elasped: 2.1427764892578125\n",
      "Epoch [57/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00033\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00089\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00070\n",
      "l1_score: 0\n",
      "Time elasped: 2.0925545692443848\n",
      "Epoch [58/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00097\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00043\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00041\n",
      "l1_score: 0\n",
      "Time elasped: 2.1789097785949707\n",
      "Epoch [59/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00041\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00085\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00042\n",
      "l1_score: 0\n",
      "Time elasped: 2.3012218475341797\n",
      "Epoch [60/100], learning_rates 0.001000, 0.100000\n",
      "Step [2/6], Loss: 0.00043\n",
      "l1_score: 0\n",
      "Step [4/6], Loss: 0.00031\n",
      "l1_score: 0\n",
      "Step [6/6], Loss: 0.00047\n",
      "l1_score: 0\n",
      "Time elasped: 2.476149559020996\n",
      "Test Loss: 1.974116223199027\n",
      "Avg spk_count per neuron for all 50 time-steps 4.713085651397705\n",
      "Avg spk per neuron per layer [9.971875, 8.88046875]\n",
      "Test Accuracy of the model on the test samples: 57.000\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\default\n",
      "Epoch [61/100], learning_rates 0.001000, 0.100000\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ckpt_dir = 'default' \n",
    "dataset_dict['num_training_samples'] = 200\n",
    "\n",
    "snn = SNN(dataset_dict=dataset_dict, structure=(64, 2), connection_type='f',\n",
    "    delay=(48,16), delay_type='h', tau_m = 'normal',\n",
    "    win=total_time, loss_fn='mem_sum', batch_size=batch_size, device=device,\n",
    "    debug=False)\n",
    "\n",
    "snn.set_network()\n",
    "\n",
    "snn.to(device)\n",
    "\n",
    "num_epochs = 100\n",
    "train(snn, train_loader, test_loader, 1e-3, num_epochs, dropout=0.0, \n",
    "    test_behavior=tb_save_max_last_acc, ckpt_dir=ckpt_dir, scheduler=(100, 0.95), test_every=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda:0\n",
      "[CropTime(min=0, max=1000000.0), ToFrame(sensor_size=(700, 1, 1), time_window=None, event_count=None, n_time_bins=50, n_event_bins=None, overlap=0, include_incomplete=False)]\n"
     ]
    }
   ],
   "source": [
    "from snn_delays.snn import SNN\n",
    "from snn_delays.utils.dataset_loader import DatasetLoader\n",
    "from snn_delays.utils.train_utils import train, get_device\n",
    "from snn_delays.utils.test_behavior import tb_save_max_last_acc\n",
    "import torch\n",
    "\n",
    "device = get_device()\n",
    "torch.manual_seed(10)\n",
    "\n",
    "dataset = 'ssc'\n",
    "total_time = 50\n",
    "batch_size = 32\n",
    "\n",
    "# DATASET\n",
    "DL = DatasetLoader(dataset=dataset,\n",
    "                   caching='memory',\n",
    "                   num_workers=0,\n",
    "                   batch_size=batch_size,\n",
    "                   total_time=total_time,\n",
    "                   crop_to=1e6)\n",
    "\n",
    "_, __, dataset_dict = DL.get_dataloaders()\n",
    "\n",
    "target_classes = [x for x in range(35)]\n",
    "test_dataset = DL._dataset.test_dataset\n",
    "train_dataset = DL._dataset.train_dataset\n",
    "\n",
    "sub_train_dataset = SubDataset(train_dataset, 10, target_classes, f'{dataset}_10_train')\n",
    "sub_test_dataset = SubDataset(test_dataset, 10, target_classes, f'{dataset}_10_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 50, 1, 700])\n",
      "torch.Size([32, 50, 1, 700])\n",
      "torch.Size([32, 50, 1, 700])\n",
      "torch.Size([32, 50, 1, 700])\n",
      "torch.Size([32, 50, 1, 700])\n",
      "torch.Size([32, 50, 1, 700])\n",
      "torch.Size([32, 50, 1, 700])\n",
      "torch.Size([32, 50, 1, 700])\n",
      "torch.Size([32, 50, 1, 700])\n",
      "torch.Size([32, 50, 1, 700])\n",
      "torch.Size([30, 50, 1, 700])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MemoryCachedDataset(sub_train_dataset)\n",
    "test_dataset = MemoryCachedDataset(sub_test_dataset)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            drop_last=False,\n",
    "                            pin_memory=True,\n",
    "                            num_workers=0)\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            drop_last=False,\n",
    "                            pin_memory=True,\n",
    "                            num_workers=0)\n",
    "\n",
    "for x, y in train_loader:\n",
    "    print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Delays: tensor([ 0, 16, 32])\n",
      "\n",
      "[INFO] Delays i: tensor([0])\n",
      "\n",
      "[INFO] Delays h: tensor([ 0, 16, 32])\n",
      "\n",
      "[INFO] Delays o: tensor([0])\n",
      "1000.0\n",
      "Delta t: 20.0 ms\n",
      "mean of normal: -0.541324854612918\n",
      "training ssc50_l2_48d16.t7 for 100 epochs...\n",
      "Epoch [1/100], learning_rates 0.001000, 0.100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [3/10], Loss: 3.57200\n",
      "l1_score: 0\n",
      "Step [6/10], Loss: 3.59528\n",
      "l1_score: 0\n",
      "Step [9/10], Loss: 3.55838\n",
      "l1_score: 0\n",
      "Time elasped: 3.1420552730560303\n",
      "Epoch [2/100], learning_rates 0.001000, 0.100000\n",
      "Step [3/10], Loss: 3.51128\n",
      "l1_score: 0\n",
      "Step [6/10], Loss: 3.54426\n",
      "l1_score: 0\n",
      "Step [9/10], Loss: 3.54864\n",
      "l1_score: 0\n",
      "Time elasped: 2.3222508430480957\n",
      "Epoch [3/100], learning_rates 0.001000, 0.100000\n",
      "Step [3/10], Loss: 3.50547\n",
      "l1_score: 0\n",
      "Step [6/10], Loss: 3.59255\n",
      "l1_score: 0\n",
      "Step [9/10], Loss: 3.49924\n",
      "l1_score: 0\n",
      "Time elasped: 2.454049587249756\n",
      "Epoch [4/100], learning_rates 0.001000, 0.100000\n",
      "Step [3/10], Loss: 3.43836\n",
      "l1_score: 0\n",
      "Step [6/10], Loss: 3.52880\n",
      "l1_score: 0\n",
      "Step [9/10], Loss: 3.53652\n",
      "l1_score: 0\n",
      "Time elasped: 2.59633207321167\n",
      "Epoch [5/100], learning_rates 0.001000, 0.100000\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ckpt_dir = 'default' \n",
    "dataset_dict['num_training_samples'] = 350\n",
    "\n",
    "snn = SNN(dataset_dict=dataset_dict, structure=(64, 2), connection_type='f',\n",
    "    delay=(48,16), delay_type='h', tau_m = 'normal',\n",
    "    win=total_time, loss_fn='mem_sum', batch_size=batch_size, device=device,\n",
    "    debug=False)\n",
    "\n",
    "snn.set_network()\n",
    "\n",
    "snn.to(device)\n",
    "\n",
    "num_epochs = 100\n",
    "train(snn, train_loader, test_loader, 1e-3, num_epochs, dropout=0.0, \n",
    "    test_behavior=tb_save_max_last_acc, ckpt_dir=ckpt_dir, scheduler=(100, 0.95), test_every=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepsnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
