{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda:0\n",
      "[CropTime(min=0, max=1000000.0), ToFrame(sensor_size=(700, 1, 1), time_window=None, event_count=None, n_time_bins=50, n_event_bins=None, overlap=0, include_incomplete=False)]\n",
      "\n",
      "[INFO] Delays: tensor([ 0, 16, 32])\n",
      "\n",
      "[INFO] Delays i: tensor([0])\n",
      "\n",
      "[INFO] Delays h: tensor([ 0, 16, 32])\n",
      "\n",
      "[INFO] Delays o: tensor([0])\n",
      "1000.0\n",
      "Delta t: 20.0 ms\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "from snn_delays.snn import SNN\n",
    "from snn_delays.utils.dataset_loader import DatasetLoader\n",
    "from snn_delays.utils.train_utils import train, get_device\n",
    "from snn_delays.utils.test_behavior import tb_save_max_last_acc\n",
    "from snn_delays.utils.visualization_utils import plot_distributions, plot_param\n",
    "device = get_device()\n",
    "\n",
    "# for reproducibility\n",
    "torch.manual_seed(10)\n",
    "\n",
    "dataset = 'shd'\n",
    "total_time = 50\n",
    "batch_size = 1024\n",
    "\n",
    "# DATASET\n",
    "DL = DatasetLoader(dataset=dataset,\n",
    "                  caching='memory',\n",
    "                  num_workers=0,\n",
    "                  batch_size=batch_size,\n",
    "                  total_time=total_time,\n",
    "                  crop_to=1e6)\n",
    "train_loader, test_loader, dataset_dict = DL.get_dataloaders()\n",
    "          \n",
    "num_epochs = 50\n",
    "\n",
    "lr = 5e-4\n",
    "# SNN CON DELAYS\n",
    "taimu1 = time.time()\n",
    "\n",
    "#tau_m = 'normal'\n",
    "tau_m = 20.0\n",
    "delay = (48,16)\n",
    "#delay = None\n",
    "#delay = (3, 1)\n",
    "ckpt_dir = 'exp3_shd50'\n",
    "\n",
    "snn = SNN(dataset_dict=dataset_dict, structure=(64, 2), connection_type='f',\n",
    "    delay=delay, delay_type='h', tau_m = tau_m,\n",
    "    win=total_time, loss_fn='mem_sum', batch_size=batch_size, device=device,\n",
    "    debug=False)\n",
    "\n",
    "snn.input2spike_th = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "delta_t = (1e3/total_time) # in miliseconds\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "transform = lambda x: -delta_t/np.log(sigmoid(x))\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(3):\n",
    "  plt.subplot(3, 1, i+1)\n",
    "  plot_param(snn.tau_params[i], transform=transform)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training shd50_SNN_l2_48d16.t7 for 50 epochs...\n",
      "Epoch [1/50], learning_rates 0.000500, 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "c:\\Users\\Alberto\\anaconda3\\envs\\deepsnn\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [2/7], Loss: 3.32567\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 3.09674\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 3.14490\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 3.13538\n",
      "l1_score: 0\n",
      "Time elasped: 46.39951014518738\n",
      "Test Loss: 4.622810244560242\n",
      "Avg spk_count per neuron for all 50 time-steps 3.058150291442871\n",
      "Avg spk per neuron per layer [7.424366442137809, 4.808234871908128]\n",
      "Test Accuracy of the model on the test samples: 5.565\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0001\n",
      "Gradient norm for 'tau_m_2': 0.0016\n",
      "Gradient norm for 'tau_m_o': 0.0249\n",
      "Gradient norm for 'f0_f1.weight': 0.0779\n",
      "Gradient norm for 'f1_f2.weight': 0.2749\n",
      "Gradient norm for 'f2_o.weight': 1.1561\n",
      "saving max acc: 5.565371024734982\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [2/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 3.04143\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 3.04005\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 3.00884\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 3.00219\n",
      "l1_score: 0\n",
      "Time elasped: 3.2117536067962646\n",
      "Test Loss: 4.434291481971741\n",
      "Avg spk_count per neuron for all 50 time-steps 3.1589088439941406\n",
      "Avg spk per neuron per layer [7.86504113295053, 4.770594081272085]\n",
      "Test Accuracy of the model on the test samples: 9.717\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0001\n",
      "Gradient norm for 'tau_m_2': 0.0019\n",
      "Gradient norm for 'tau_m_o': 0.0248\n",
      "Gradient norm for 'f0_f1.weight': 0.0578\n",
      "Gradient norm for 'f1_f2.weight': 0.3152\n",
      "Gradient norm for 'f2_o.weight': 1.2949\n",
      "saving max acc: 9.717314487632509\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [3/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 2.95035\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 2.92366\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 2.93945\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 2.88422\n",
      "l1_score: 0\n",
      "Time elasped: 3.1649279594421387\n",
      "Test Loss: 4.298185229301453\n",
      "Avg spk_count per neuron for all 50 time-steps 3.4149250984191895\n",
      "Avg spk per neuron per layer [8.537978964222615, 5.121721786660777]\n",
      "Test Accuracy of the model on the test samples: 17.314\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0001\n",
      "Gradient norm for 'tau_m_2': 0.0012\n",
      "Gradient norm for 'tau_m_o': 0.0188\n",
      "Gradient norm for 'f0_f1.weight': 0.0355\n",
      "Gradient norm for 'f1_f2.weight': 0.1976\n",
      "Gradient norm for 'f2_o.weight': 0.7584\n",
      "saving max acc: 17.314487632508833\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [4/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 2.80963\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 2.79670\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 2.83389\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 2.76414\n",
      "l1_score: 0\n",
      "Time elasped: 3.1436922550201416\n",
      "Test Loss: 4.061419486999512\n",
      "Avg spk_count per neuron for all 50 time-steps 3.659341812133789\n",
      "Avg spk per neuron per layer [9.056730344522968, 5.5806371466431095]\n",
      "Test Accuracy of the model on the test samples: 22.571\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0001\n",
      "Gradient norm for 'tau_m_2': 0.0012\n",
      "Gradient norm for 'tau_m_o': 0.0302\n",
      "Gradient norm for 'f0_f1.weight': 0.0334\n",
      "Gradient norm for 'f1_f2.weight': 0.1763\n",
      "Gradient norm for 'f2_o.weight': 0.6448\n",
      "saving max acc: 22.570671378091873\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [5/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 2.67413\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 2.66646\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 2.60742\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 2.64210\n",
      "l1_score: 0\n",
      "Time elasped: 3.278069496154785\n",
      "Test Loss: 3.869382619857788\n",
      "Avg spk_count per neuron for all 50 time-steps 3.8133058547973633\n",
      "Avg spk per neuron per layer [9.233298365724382, 6.019924635600707]\n",
      "Test Accuracy of the model on the test samples: 29.859\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0001\n",
      "Gradient norm for 'tau_m_2': 0.0024\n",
      "Gradient norm for 'tau_m_o': 0.0505\n",
      "Gradient norm for 'f0_f1.weight': 0.0625\n",
      "Gradient norm for 'f1_f2.weight': 0.4239\n",
      "Gradient norm for 'f2_o.weight': 1.4842\n",
      "saving max acc: 29.858657243816253\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [6/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 2.49680\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 2.52984\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 2.47277\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 2.41258\n",
      "l1_score: 0\n",
      "Time elasped: 3.6231696605682373\n",
      "Test Loss: 3.549950957298279\n",
      "Avg spk_count per neuron for all 50 time-steps 4.23173189163208\n",
      "Avg spk per neuron per layer [9.881376987632509, 7.045549911660777]\n",
      "Test Accuracy of the model on the test samples: 35.292\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0002\n",
      "Gradient norm for 'tau_m_2': 0.0036\n",
      "Gradient norm for 'tau_m_o': 0.0696\n",
      "Gradient norm for 'f0_f1.weight': 0.1410\n",
      "Gradient norm for 'f1_f2.weight': 0.7606\n",
      "Gradient norm for 'f2_o.weight': 2.1377\n",
      "saving max acc: 35.291519434628974\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [7/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 2.39420\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 2.27648\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 2.25597\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 2.25995\n",
      "l1_score: 0\n",
      "Time elasped: 3.163822889328003\n",
      "Test Loss: 3.269623041152954\n",
      "Avg spk_count per neuron for all 50 time-steps 4.642522811889648\n",
      "Avg spk per neuron per layer [10.465727142226148, 8.104364509717314]\n",
      "Test Accuracy of the model on the test samples: 42.889\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0002\n",
      "Gradient norm for 'tau_m_2': 0.0032\n",
      "Gradient norm for 'tau_m_o': 0.0635\n",
      "Gradient norm for 'f0_f1.weight': 0.1003\n",
      "Gradient norm for 'f1_f2.weight': 0.5930\n",
      "Gradient norm for 'f2_o.weight': 1.4145\n",
      "saving max acc: 42.8886925795053\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [8/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 2.13661\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 2.14744\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 2.07254\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 1.98703\n",
      "l1_score: 0\n",
      "Time elasped: 3.133058786392212\n",
      "Test Loss: 2.93011212348938\n",
      "Avg spk_count per neuron for all 50 time-steps 4.836384296417236\n",
      "Avg spk per neuron per layer [10.420218639575971, 8.925318849381625]\n",
      "Test Accuracy of the model on the test samples: 50.133\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0003\n",
      "Gradient norm for 'tau_m_2': 0.0021\n",
      "Gradient norm for 'tau_m_o': 0.1031\n",
      "Gradient norm for 'f0_f1.weight': 0.0855\n",
      "Gradient norm for 'f1_f2.weight': 0.4216\n",
      "Gradient norm for 'f2_o.weight': 1.6953\n",
      "saving max acc: 50.13250883392226\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [9/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 1.90687\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 1.91253\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 1.81734\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 1.79717\n",
      "l1_score: 0\n",
      "Time elasped: 3.220548152923584\n",
      "Test Loss: 2.6288340091705322\n",
      "Avg spk_count per neuron for all 50 time-steps 5.0654988288879395\n",
      "Avg spk per neuron per layer [10.473401612190813, 9.788593197879859]\n",
      "Test Accuracy of the model on the test samples: 55.389\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0003\n",
      "Gradient norm for 'tau_m_2': 0.0038\n",
      "Gradient norm for 'tau_m_o': 0.1019\n",
      "Gradient norm for 'f0_f1.weight': 0.1465\n",
      "Gradient norm for 'f1_f2.weight': 0.6973\n",
      "Gradient norm for 'f2_o.weight': 2.2623\n",
      "saving max acc: 55.3886925795053\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [10/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 1.66181\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 1.65045\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 1.52940\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 1.50753\n",
      "l1_score: 0\n",
      "Time elasped: 2.9176111221313477\n",
      "Test Loss: 2.328938663005829\n",
      "Avg spk_count per neuron for all 50 time-steps 5.366010665893555\n",
      "Avg spk per neuron per layer [10.741490448321555, 10.722552727473499]\n",
      "Test Accuracy of the model on the test samples: 60.557\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0003\n",
      "Gradient norm for 'tau_m_2': 0.0027\n",
      "Gradient norm for 'tau_m_o': 0.1151\n",
      "Gradient norm for 'f0_f1.weight': 0.1013\n",
      "Gradient norm for 'f1_f2.weight': 0.5141\n",
      "Gradient norm for 'f2_o.weight': 1.8599\n",
      "saving max acc: 60.5565371024735\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [11/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 1.36159\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 1.35370\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 1.27210\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 1.27173\n",
      "l1_score: 0\n",
      "Time elasped: 3.3415472507476807\n",
      "Test Loss: 1.9055644273757935\n",
      "Avg spk_count per neuron for all 50 time-steps 5.626163005828857\n",
      "Avg spk per neuron per layer [10.909079615724382, 11.59557199646643]\n",
      "Test Accuracy of the model on the test samples: 65.504\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0003\n",
      "Gradient norm for 'tau_m_2': 0.0029\n",
      "Gradient norm for 'tau_m_o': 0.1169\n",
      "Gradient norm for 'f0_f1.weight': 0.1285\n",
      "Gradient norm for 'f1_f2.weight': 0.6528\n",
      "Gradient norm for 'f2_o.weight': 2.3099\n",
      "saving max acc: 65.50353356890459\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [12/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 1.19559\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 1.12711\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 1.12589\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 1.07199\n",
      "l1_score: 0\n",
      "Time elasped: 3.176962375640869\n",
      "Test Loss: 1.7019086480140686\n",
      "Avg spk_count per neuron for all 50 time-steps 5.705780506134033\n",
      "Avg spk per neuron per layer [10.801436892667844, 12.021684518551236]\n",
      "Test Accuracy of the model on the test samples: 66.343\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0005\n",
      "Gradient norm for 'tau_m_2': 0.0051\n",
      "Gradient norm for 'tau_m_o': 0.1499\n",
      "Gradient norm for 'f0_f1.weight': 0.2086\n",
      "Gradient norm for 'f1_f2.weight': 0.9842\n",
      "Gradient norm for 'f2_o.weight': 3.5119\n",
      "saving max acc: 66.34275618374558\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [13/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 1.00454\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.93858\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.88931\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.88912\n",
      "l1_score: 0\n",
      "Time elasped: 2.90529727935791\n",
      "Test Loss: 1.5060830414295197\n",
      "Avg spk_count per neuron for all 50 time-steps 5.8658623695373535\n",
      "Avg spk per neuron per layer [10.985872625883392, 12.477577020759718]\n",
      "Test Accuracy of the model on the test samples: 68.728\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0003\n",
      "Gradient norm for 'tau_m_2': 0.0021\n",
      "Gradient norm for 'tau_m_o': 0.1348\n",
      "Gradient norm for 'f0_f1.weight': 0.1292\n",
      "Gradient norm for 'f1_f2.weight': 0.5052\n",
      "Gradient norm for 'f2_o.weight': 2.3698\n",
      "saving max acc: 68.7279151943463\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [14/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.79076\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.82494\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.79071\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.77656\n",
      "l1_score: 0\n",
      "Time elasped: 3.4284727573394775\n",
      "Test Loss: 1.3307858407497406\n",
      "Avg spk_count per neuron for all 50 time-steps 5.888723850250244\n",
      "Avg spk per neuron per layer [10.961786384717314, 12.593108160335689]\n",
      "Test Accuracy of the model on the test samples: 71.466\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0004\n",
      "Gradient norm for 'tau_m_2': 0.0044\n",
      "Gradient norm for 'tau_m_o': 0.1446\n",
      "Gradient norm for 'f0_f1.weight': 0.1959\n",
      "Gradient norm for 'f1_f2.weight': 0.9103\n",
      "Gradient norm for 'f2_o.weight': 3.3343\n",
      "saving max acc: 71.46643109540636\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [15/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.73284\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.71008\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.61515\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.65871\n",
      "l1_score: 0\n",
      "Time elasped: 3.4909939765930176\n",
      "Test Loss: 1.2754932641983032\n",
      "Avg spk_count per neuron for all 50 time-steps 5.944363594055176\n",
      "Avg spk per neuron per layer [11.012981724823321, 12.764472449204947]\n",
      "Test Accuracy of the model on the test samples: 71.820\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0003\n",
      "Gradient norm for 'tau_m_2': 0.0021\n",
      "Gradient norm for 'tau_m_o': 0.1148\n",
      "Gradient norm for 'f0_f1.weight': 0.1218\n",
      "Gradient norm for 'f1_f2.weight': 0.4484\n",
      "Gradient norm for 'f2_o.weight': 2.0216\n",
      "saving max acc: 71.81978798586573\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [16/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.62532\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.61973\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.55833\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.60571\n",
      "l1_score: 0\n",
      "Time elasped: 3.8127634525299072\n",
      "Test Loss: 1.1261124312877655\n",
      "Avg spk_count per neuron for all 50 time-steps 5.984952926635742\n",
      "Avg spk per neuron per layer [11.0977183635159, 12.842093639575971]\n",
      "Test Accuracy of the model on the test samples: 73.807\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0007\n",
      "Gradient norm for 'tau_m_2': 0.0053\n",
      "Gradient norm for 'tau_m_o': 0.1752\n",
      "Gradient norm for 'f0_f1.weight': 0.2621\n",
      "Gradient norm for 'f1_f2.weight': 1.0267\n",
      "Gradient norm for 'f2_o.weight': 3.7961\n",
      "saving max acc: 73.80742049469964\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [17/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.55935\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.54853\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.54623\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.49115\n",
      "l1_score: 0\n",
      "Time elasped: 3.078465700149536\n",
      "Test Loss: 1.0789175033569336\n",
      "Avg spk_count per neuron for all 50 time-steps 6.037725448608398\n",
      "Avg spk per neuron per layer [11.205043617491166, 12.945857718639576]\n",
      "Test Accuracy of the model on the test samples: 75.574\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0004\n",
      "Gradient norm for 'tau_m_2': 0.0039\n",
      "Gradient norm for 'tau_m_o': 0.1126\n",
      "Gradient norm for 'f0_f1.weight': 0.1916\n",
      "Gradient norm for 'f1_f2.weight': 0.8356\n",
      "Gradient norm for 'f2_o.weight': 3.5854\n",
      "saving max acc: 75.57420494699646\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [18/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.50164\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.46746\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.47885\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.44773\n",
      "l1_score: 0\n",
      "Time elasped: 3.411008834838867\n",
      "Test Loss: 1.0961953103542328\n",
      "Avg spk_count per neuron for all 50 time-steps 6.034498691558838\n",
      "Avg spk per neuron per layer [11.15698155918728, 12.981013968639576]\n",
      "Test Accuracy of the model on the test samples: 74.426\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0005\n",
      "Gradient norm for 'tau_m_2': 0.0026\n",
      "Gradient norm for 'tau_m_o': 0.1182\n",
      "Gradient norm for 'f0_f1.weight': 0.1398\n",
      "Gradient norm for 'f1_f2.weight': 0.6724\n",
      "Gradient norm for 'f2_o.weight': 2.5530\n",
      "Epoch [19/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.44420\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.41975\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.41861\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.42339\n",
      "l1_score: 0\n",
      "Time elasped: 3.146516799926758\n",
      "Test Loss: 1.0191563665866852\n",
      "Avg spk_count per neuron for all 50 time-steps 6.119452953338623\n",
      "Avg spk per neuron per layer [11.282699315371024, 13.195112356448764]\n",
      "Test Accuracy of the model on the test samples: 75.618\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0004\n",
      "Gradient norm for 'tau_m_2': 0.0027\n",
      "Gradient norm for 'tau_m_o': 0.1308\n",
      "Gradient norm for 'f0_f1.weight': 0.1138\n",
      "Gradient norm for 'f1_f2.weight': 0.6240\n",
      "Gradient norm for 'f2_o.weight': 2.8683\n",
      "saving max acc: 75.61837455830388\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [20/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.39550\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.39004\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.38667\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.38503\n",
      "l1_score: 0\n",
      "Time elasped: 3.0356996059417725\n",
      "Test Loss: 0.9688977599143982\n",
      "Avg spk_count per neuron for all 50 time-steps 6.096986770629883\n",
      "Avg spk per neuron per layer [11.237653213339222, 13.150294003975265]\n",
      "Test Accuracy of the model on the test samples: 77.076\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0003\n",
      "Gradient norm for 'tau_m_2': 0.0021\n",
      "Gradient norm for 'tau_m_o': 0.0789\n",
      "Gradient norm for 'f0_f1.weight': 0.0836\n",
      "Gradient norm for 'f1_f2.weight': 0.4857\n",
      "Gradient norm for 'f2_o.weight': 1.8888\n",
      "saving max acc: 77.07597173144876\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [21/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.33923\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.34913\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.30095\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.38366\n",
      "l1_score: 0\n",
      "Time elasped: 2.934399366378784\n",
      "Test Loss: 1.0298022031784058\n",
      "Avg spk_count per neuron for all 50 time-steps 6.1687798500061035\n",
      "Avg spk per neuron per layer [11.366559463339222, 13.308559242491166]\n",
      "Test Accuracy of the model on the test samples: 76.193\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0005\n",
      "Gradient norm for 'tau_m_2': 0.0021\n",
      "Gradient norm for 'tau_m_o': 0.1256\n",
      "Gradient norm for 'f0_f1.weight': 0.1454\n",
      "Gradient norm for 'f1_f2.weight': 0.5222\n",
      "Gradient norm for 'f2_o.weight': 2.5520\n",
      "Epoch [22/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.32379\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.30713\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.30456\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.33324\n",
      "l1_score: 0\n",
      "Time elasped: 3.0316104888916016\n",
      "Test Loss: 0.9061426222324371\n",
      "Avg spk_count per neuron for all 50 time-steps 6.171583652496338\n",
      "Avg spk per neuron per layer [11.399217369699647, 13.287116276501767]\n",
      "Test Accuracy of the model on the test samples: 78.931\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0003\n",
      "Gradient norm for 'tau_m_2': 0.0021\n",
      "Gradient norm for 'tau_m_o': 0.1016\n",
      "Gradient norm for 'f0_f1.weight': 0.1610\n",
      "Gradient norm for 'f1_f2.weight': 0.4625\n",
      "Gradient norm for 'f2_o.weight': 1.9051\n",
      "saving max acc: 78.93109540636043\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [23/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.30245\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.30994\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.27349\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.27545\n",
      "l1_score: 0\n",
      "Time elasped: 2.9981143474578857\n",
      "Test Loss: 0.8952454030513763\n",
      "Avg spk_count per neuron for all 50 time-steps 6.144176006317139\n",
      "Avg spk per neuron per layer [11.352604626766784, 13.224098663869258]\n",
      "Test Accuracy of the model on the test samples: 79.329\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0005\n",
      "Gradient norm for 'tau_m_2': 0.0028\n",
      "Gradient norm for 'tau_m_o': 0.1142\n",
      "Gradient norm for 'f0_f1.weight': 0.1934\n",
      "Gradient norm for 'f1_f2.weight': 0.7181\n",
      "Gradient norm for 'f2_o.weight': 2.9833\n",
      "saving max acc: 79.3286219081272\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [24/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.24177\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.26490\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.28214\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.25679\n",
      "l1_score: 0\n",
      "Time elasped: 2.9724411964416504\n",
      "Test Loss: 0.88731449842453\n",
      "Avg spk_count per neuron for all 50 time-steps 6.233239650726318\n",
      "Avg spk per neuron per layer [11.522602418286219, 13.410356393551236]\n",
      "Test Accuracy of the model on the test samples: 78.357\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0004\n",
      "Gradient norm for 'tau_m_2': 0.0026\n",
      "Gradient norm for 'tau_m_o': 0.1208\n",
      "Gradient norm for 'f0_f1.weight': 0.1534\n",
      "Gradient norm for 'f1_f2.weight': 0.5880\n",
      "Gradient norm for 'f2_o.weight': 2.3246\n",
      "Epoch [25/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.25855\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.26998\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.20977\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.23058\n",
      "l1_score: 0\n",
      "Time elasped: 3.1724512577056885\n",
      "Test Loss: 0.8913800120353699\n",
      "Avg spk_count per neuron for all 50 time-steps 6.2031145095825195\n",
      "Avg spk per neuron per layer [11.456341099823321, 13.356117491166078]\n",
      "Test Accuracy of the model on the test samples: 79.329\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0005\n",
      "Gradient norm for 'tau_m_2': 0.0041\n",
      "Gradient norm for 'tau_m_o': 0.1189\n",
      "Gradient norm for 'f0_f1.weight': 0.1932\n",
      "Gradient norm for 'f1_f2.weight': 0.9147\n",
      "Gradient norm for 'f2_o.weight': 3.3307\n",
      "saving max acc: 79.3286219081272\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [26/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.22997\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.23166\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.24296\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.21177\n",
      "l1_score: 0\n",
      "Time elasped: 3.122335195541382\n",
      "Test Loss: 0.9189326167106628\n",
      "Avg spk_count per neuron for all 50 time-steps 6.263354301452637\n",
      "Avg spk per neuron per layer [11.559063052120141, 13.494354571554771]\n",
      "Test Accuracy of the model on the test samples: 78.799\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0006\n",
      "Gradient norm for 'tau_m_2': 0.0020\n",
      "Gradient norm for 'tau_m_o': 0.0906\n",
      "Gradient norm for 'f0_f1.weight': 0.1586\n",
      "Gradient norm for 'f1_f2.weight': 0.5147\n",
      "Gradient norm for 'f2_o.weight': 1.6335\n",
      "Epoch [27/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.22622\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.19909\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.22011\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.20807\n",
      "l1_score: 0\n",
      "Time elasped: 3.140695095062256\n",
      "Test Loss: 0.9447902143001556\n",
      "Avg spk_count per neuron for all 50 time-steps 6.176562786102295\n",
      "Avg spk per neuron per layer [11.357007784893993, 13.34924359540636]\n",
      "Test Accuracy of the model on the test samples: 78.534\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0002\n",
      "Gradient norm for 'tau_m_2': 0.0016\n",
      "Gradient norm for 'tau_m_o': 0.0821\n",
      "Gradient norm for 'f0_f1.weight': 0.0893\n",
      "Gradient norm for 'f1_f2.weight': 0.3251\n",
      "Gradient norm for 'f2_o.weight': 1.4235\n",
      "Epoch [28/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.17366\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.15462\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.17416\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.17642\n",
      "l1_score: 0\n",
      "Time elasped: 3.2327961921691895\n",
      "Test Loss: 0.974740207195282\n",
      "Avg spk_count per neuron for all 50 time-steps 6.237421989440918\n",
      "Avg spk per neuron per layer [11.474271201413428, 13.475416850706713]\n",
      "Test Accuracy of the model on the test samples: 77.959\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0003\n",
      "Gradient norm for 'tau_m_2': 0.0021\n",
      "Gradient norm for 'tau_m_o': 0.0932\n",
      "Gradient norm for 'f0_f1.weight': 0.1199\n",
      "Gradient norm for 'f1_f2.weight': 0.5485\n",
      "Gradient norm for 'f2_o.weight': 2.0705\n",
      "Epoch [29/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.15560\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.16842\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.14472\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.17794\n",
      "l1_score: 0\n",
      "Time elasped: 3.1150078773498535\n",
      "Test Loss: 0.8307975828647614\n",
      "Avg spk_count per neuron for all 50 time-steps 6.26531457901001\n",
      "Avg spk per neuron per layer [11.534686947879859, 13.52657078180212]\n",
      "Test Accuracy of the model on the test samples: 80.300\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0002\n",
      "Gradient norm for 'tau_m_2': 0.0018\n",
      "Gradient norm for 'tau_m_o': 0.0895\n",
      "Gradient norm for 'f0_f1.weight': 0.1117\n",
      "Gradient norm for 'f1_f2.weight': 0.4243\n",
      "Gradient norm for 'f2_o.weight': 1.8471\n",
      "saving max acc: 80.30035335689045\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [30/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.15352\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.14098\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.17036\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.18031\n",
      "l1_score: 0\n",
      "Time elasped: 3.0832996368408203\n",
      "Test Loss: 0.9078136384487152\n",
      "Avg spk_count per neuron for all 50 time-steps 6.275954723358154\n",
      "Avg spk per neuron per layer [11.520276612190813, 13.583542678886927]\n",
      "Test Accuracy of the model on the test samples: 78.445\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0003\n",
      "Gradient norm for 'tau_m_2': 0.0022\n",
      "Gradient norm for 'tau_m_o': 0.0985\n",
      "Gradient norm for 'f0_f1.weight': 0.1026\n",
      "Gradient norm for 'f1_f2.weight': 0.4406\n",
      "Gradient norm for 'f2_o.weight': 1.7197\n",
      "Epoch [31/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.15350\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.15859\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.12651\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.14887\n",
      "l1_score: 0\n",
      "Time elasped: 3.127016544342041\n",
      "Test Loss: 0.8649539649486542\n",
      "Avg spk_count per neuron for all 50 time-steps 6.29862642288208\n",
      "Avg spk per neuron per layer [11.581582652385158, 13.612922371908127]\n",
      "Test Accuracy of the model on the test samples: 79.240\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0003\n",
      "Gradient norm for 'tau_m_2': 0.0021\n",
      "Gradient norm for 'tau_m_o': 0.0816\n",
      "Gradient norm for 'f0_f1.weight': 0.0894\n",
      "Gradient norm for 'f1_f2.weight': 0.4710\n",
      "Gradient norm for 'f2_o.weight': 2.2750\n",
      "Epoch [32/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.13719\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.12107\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.12303\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.12349\n",
      "l1_score: 0\n",
      "Time elasped: 3.0355565547943115\n",
      "Test Loss: 0.8318389654159546\n",
      "Avg spk_count per neuron for all 50 time-steps 6.281098365783691\n",
      "Avg spk per neuron per layer [11.5370886704947, 13.587303997349823]\n",
      "Test Accuracy of the model on the test samples: 81.405\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0003\n",
      "Gradient norm for 'tau_m_2': 0.0015\n",
      "Gradient norm for 'tau_m_o': 0.1241\n",
      "Gradient norm for 'f0_f1.weight': 0.1092\n",
      "Gradient norm for 'f1_f2.weight': 0.4203\n",
      "Gradient norm for 'f2_o.weight': 1.7863\n",
      "saving max acc: 81.40459363957598\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [33/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.12298\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.12755\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.12201\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.12530\n",
      "l1_score: 0\n",
      "Time elasped: 2.9375593662261963\n",
      "Test Loss: 0.9649912118911743\n",
      "Avg spk_count per neuron for all 50 time-steps 6.312046051025391\n",
      "Avg spk per neuron per layer [11.561561395759718, 13.686623509275618]\n",
      "Test Accuracy of the model on the test samples: 77.650\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0005\n",
      "Gradient norm for 'tau_m_2': 0.0017\n",
      "Gradient norm for 'tau_m_o': 0.0820\n",
      "Gradient norm for 'f0_f1.weight': 0.1348\n",
      "Gradient norm for 'f1_f2.weight': 0.3928\n",
      "Gradient norm for 'f2_o.weight': 1.4028\n",
      "Epoch [34/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.10659\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.11541\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.12366\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.10343\n",
      "l1_score: 0\n",
      "Time elasped: 3.1194984912872314\n",
      "Test Loss: 0.8417477011680603\n",
      "Avg spk_count per neuron for all 50 time-steps 6.250685214996338\n",
      "Avg spk per neuron per layer [11.478315481448764, 13.52442441475265]\n",
      "Test Accuracy of the model on the test samples: 82.111\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0002\n",
      "Gradient norm for 'tau_m_2': 0.0010\n",
      "Gradient norm for 'tau_m_o': 0.0691\n",
      "Gradient norm for 'f0_f1.weight': 0.0590\n",
      "Gradient norm for 'f1_f2.weight': 0.2333\n",
      "Gradient norm for 'f2_o.weight': 0.9055\n",
      "saving max acc: 82.1113074204947\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [35/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.10870\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.09931\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.11602\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.09911\n",
      "l1_score: 0\n",
      "Time elasped: 3.1401119232177734\n",
      "Test Loss: 0.7896893918514252\n",
      "Avg spk_count per neuron for all 50 time-steps 6.290770530700684\n",
      "Avg spk per neuron per layer [11.546598939929329, 13.616483546819788]\n",
      "Test Accuracy of the model on the test samples: 79.859\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0003\n",
      "Gradient norm for 'tau_m_2': 0.0014\n",
      "Gradient norm for 'tau_m_o': 0.1045\n",
      "Gradient norm for 'f0_f1.weight': 0.0882\n",
      "Gradient norm for 'f1_f2.weight': 0.3773\n",
      "Gradient norm for 'f2_o.weight': 1.8329\n",
      "Epoch [36/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.09459\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.11255\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.09954\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.08819\n",
      "l1_score: 0\n",
      "Time elasped: 2.9954111576080322\n",
      "Test Loss: 0.8228615969419479\n",
      "Avg spk_count per neuron for all 50 time-steps 6.316042423248291\n",
      "Avg spk per neuron per layer [11.604302396201414, 13.659866386925795]\n",
      "Test Accuracy of the model on the test samples: 80.212\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0002\n",
      "Gradient norm for 'tau_m_2': 0.0011\n",
      "Gradient norm for 'tau_m_o': 0.0587\n",
      "Gradient norm for 'f0_f1.weight': 0.0529\n",
      "Gradient norm for 'f1_f2.weight': 0.2604\n",
      "Gradient norm for 'f2_o.weight': 1.1039\n",
      "Epoch [37/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.08511\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.07321\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.08123\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.08804\n",
      "l1_score: 0\n",
      "Time elasped: 3.144782304763794\n",
      "Test Loss: 0.878750741481781\n",
      "Avg spk_count per neuron for all 50 time-steps 6.277252197265625\n",
      "Avg spk per neuron per layer [11.525383723498233, 13.583625496908127]\n",
      "Test Accuracy of the model on the test samples: 79.594\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0002\n",
      "Gradient norm for 'tau_m_2': 0.0012\n",
      "Gradient norm for 'tau_m_o': 0.0674\n",
      "Gradient norm for 'f0_f1.weight': 0.0737\n",
      "Gradient norm for 'f1_f2.weight': 0.2836\n",
      "Gradient norm for 'f2_o.weight': 1.1598\n",
      "Epoch [38/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.07491\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.06539\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.09704\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.08027\n",
      "l1_score: 0\n",
      "Time elasped: 3.0544607639312744\n",
      "Test Loss: 0.8681603074073792\n",
      "Avg spk_count per neuron for all 50 time-steps 6.321059703826904\n",
      "Avg spk per neuron per layer [11.604461130742049, 13.679777219522968]\n",
      "Test Accuracy of the model on the test samples: 80.124\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0003\n",
      "Gradient norm for 'tau_m_2': 0.0010\n",
      "Gradient norm for 'tau_m_o': 0.0645\n",
      "Gradient norm for 'f0_f1.weight': 0.0736\n",
      "Gradient norm for 'f1_f2.weight': 0.2891\n",
      "Gradient norm for 'f2_o.weight': 1.0384\n",
      "Epoch [39/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.07762\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.08988\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.07128\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.07797\n",
      "l1_score: 0\n",
      "Time elasped: 3.030622959136963\n",
      "Test Loss: 0.8884078860282898\n",
      "Avg spk_count per neuron for all 50 time-steps 6.342030048370361\n",
      "Avg spk per neuron per layer [11.670494699646643, 13.697624503091873]\n",
      "Test Accuracy of the model on the test samples: 81.095\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0002\n",
      "Gradient norm for 'tau_m_2': 0.0009\n",
      "Gradient norm for 'tau_m_o': 0.0698\n",
      "Gradient norm for 'f0_f1.weight': 0.0425\n",
      "Gradient norm for 'f1_f2.weight': 0.2071\n",
      "Gradient norm for 'f2_o.weight': 0.9758\n",
      "Epoch [40/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.07669\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.07266\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.06182\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.08757\n",
      "l1_score: 0\n",
      "Time elasped: 3.0652620792388916\n",
      "Test Loss: 0.7548864036798477\n",
      "Avg spk_count per neuron for all 50 time-steps 6.322365760803223\n",
      "Avg spk per neuron per layer [11.649307089222615, 13.640155697879859]\n",
      "Test Accuracy of the model on the test samples: 81.405\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0002\n",
      "Gradient norm for 'tau_m_2': 0.0009\n",
      "Gradient norm for 'tau_m_o': 0.0691\n",
      "Gradient norm for 'f0_f1.weight': 0.0654\n",
      "Gradient norm for 'f1_f2.weight': 0.2632\n",
      "Gradient norm for 'f2_o.weight': 0.9801\n",
      "Epoch [41/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.06918\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.06537\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.05807\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.07902\n",
      "l1_score: 0\n",
      "Time elasped: 2.994515895843506\n",
      "Test Loss: 0.8288100957870483\n",
      "Avg spk_count per neuron for all 50 time-steps 6.343110084533691\n",
      "Avg spk per neuron per layer [11.673117270318022, 13.699322272526501]\n",
      "Test Accuracy of the model on the test samples: 81.625\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0003\n",
      "Gradient norm for 'tau_m_2': 0.0015\n",
      "Gradient norm for 'tau_m_o': 0.0497\n",
      "Gradient norm for 'f0_f1.weight': 0.0884\n",
      "Gradient norm for 'f1_f2.weight': 0.3453\n",
      "Gradient norm for 'f2_o.weight': 1.3363\n",
      "Epoch [42/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.06544\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.05669\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.05705\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.06045\n",
      "l1_score: 0\n",
      "Time elasped: 3.1986753940582275\n",
      "Test Loss: 0.8198243826627731\n",
      "Avg spk_count per neuron for all 50 time-steps 6.33601188659668\n",
      "Avg spk per neuron per layer [11.625897195229681, 13.71814956934629]\n",
      "Test Accuracy of the model on the test samples: 81.625\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0003\n",
      "Gradient norm for 'tau_m_2': 0.0016\n",
      "Gradient norm for 'tau_m_o': 0.0526\n",
      "Gradient norm for 'f0_f1.weight': 0.0928\n",
      "Gradient norm for 'f1_f2.weight': 0.4029\n",
      "Gradient norm for 'f2_o.weight': 1.2048\n",
      "Epoch [43/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.07243\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.05139\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.06147\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.05817\n",
      "l1_score: 0\n",
      "Time elasped: 3.1780014038085938\n",
      "Test Loss: 0.8625817894935608\n",
      "Avg spk_count per neuron for all 50 time-steps 6.296769618988037\n",
      "Avg spk per neuron per layer [11.53657105786219, 13.650507950530036]\n",
      "Test Accuracy of the model on the test samples: 81.449\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0002\n",
      "Gradient norm for 'tau_m_2': 0.0010\n",
      "Gradient norm for 'tau_m_o': 0.0764\n",
      "Gradient norm for 'f0_f1.weight': 0.0474\n",
      "Gradient norm for 'f1_f2.weight': 0.2214\n",
      "Gradient norm for 'f2_o.weight': 0.9477\n",
      "Epoch [44/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.05127\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.04221\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.05400\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.05982\n",
      "l1_score: 0\n",
      "Time elasped: 3.142150640487671\n",
      "Test Loss: 0.9093724191188812\n",
      "Avg spk_count per neuron for all 50 time-steps 6.291752338409424\n",
      "Avg spk per neuron per layer [11.554756515017667, 13.61225292623675]\n",
      "Test Accuracy of the model on the test samples: 80.742\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0002\n",
      "Gradient norm for 'tau_m_2': 0.0009\n",
      "Gradient norm for 'tau_m_o': 0.0558\n",
      "Gradient norm for 'f0_f1.weight': 0.0630\n",
      "Gradient norm for 'f1_f2.weight': 0.2374\n",
      "Gradient norm for 'f2_o.weight': 0.8973\n",
      "Epoch [45/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.04517\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.06484\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.06341\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.06503\n",
      "l1_score: 0\n",
      "Time elasped: 3.064317226409912\n",
      "Test Loss: 0.9532397091388702\n",
      "Avg spk_count per neuron for all 50 time-steps 6.297791004180908\n",
      "Avg spk per neuron per layer [11.55196140680212, 13.639203290636042]\n",
      "Test Accuracy of the model on the test samples: 79.726\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0003\n",
      "Gradient norm for 'tau_m_2': 0.0016\n",
      "Gradient norm for 'tau_m_o': 0.1021\n",
      "Gradient norm for 'f0_f1.weight': 0.0780\n",
      "Gradient norm for 'f1_f2.weight': 0.4323\n",
      "Gradient norm for 'f2_o.weight': 2.2675\n",
      "Epoch [46/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.04902\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.05932\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.04281\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.04219\n",
      "l1_score: 0\n",
      "Time elasped: 3.562983274459839\n",
      "Test Loss: 0.871570497751236\n",
      "Avg spk_count per neuron for all 50 time-steps 6.329179286956787\n",
      "Avg spk per neuron per layer [11.596096510600706, 13.720620306978798]\n",
      "Test Accuracy of the model on the test samples: 81.449\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0001\n",
      "Gradient norm for 'tau_m_2': 0.0006\n",
      "Gradient norm for 'tau_m_o': 0.0497\n",
      "Gradient norm for 'f0_f1.weight': 0.0365\n",
      "Gradient norm for 'f1_f2.weight': 0.1626\n",
      "Gradient norm for 'f2_o.weight': 0.5160\n",
      "Epoch [47/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.03320\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.04084\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.05681\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.04511\n",
      "l1_score: 0\n",
      "Time elasped: 3.2768356800079346\n",
      "Test Loss: 0.8300097286701202\n",
      "Avg spk_count per neuron for all 50 time-steps 6.340306282043457\n",
      "Avg spk per neuron per layer [11.650287102473499, 13.7109375]\n",
      "Test Accuracy of the model on the test samples: 81.758\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0001\n",
      "Gradient norm for 'tau_m_2': 0.0008\n",
      "Gradient norm for 'tau_m_o': 0.0317\n",
      "Gradient norm for 'f0_f1.weight': 0.0409\n",
      "Gradient norm for 'f1_f2.weight': 0.1435\n",
      "Gradient norm for 'f2_o.weight': 0.5640\n",
      "Epoch [48/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.04423\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.04741\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.03519\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.04211\n",
      "l1_score: 0\n",
      "Time elasped: 3.080916166305542\n",
      "Test Loss: 0.7681772410869598\n",
      "Avg spk_count per neuron for all 50 time-steps 6.3546319007873535\n",
      "Avg spk per neuron per layer [11.682109927120141, 13.736417844522968]\n",
      "Test Accuracy of the model on the test samples: 82.155\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0002\n",
      "Gradient norm for 'tau_m_2': 0.0009\n",
      "Gradient norm for 'tau_m_o': 0.0535\n",
      "Gradient norm for 'f0_f1.weight': 0.0414\n",
      "Gradient norm for 'f1_f2.weight': 0.2184\n",
      "Gradient norm for 'f2_o.weight': 0.9511\n",
      "saving max acc: 82.15547703180212\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [49/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.04031\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.03580\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.04056\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.03392\n",
      "l1_score: 0\n",
      "Time elasped: 2.9968292713165283\n",
      "Test Loss: 0.7993442118167877\n",
      "Avg spk_count per neuron for all 50 time-steps 6.349090099334717\n",
      "Avg spk per neuron per layer [11.64824425795053, 13.748115890017667]\n",
      "Test Accuracy of the model on the test samples: 82.553\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0001\n",
      "Gradient norm for 'tau_m_2': 0.0008\n",
      "Gradient norm for 'tau_m_o': 0.0395\n",
      "Gradient norm for 'f0_f1.weight': 0.0452\n",
      "Gradient norm for 'f1_f2.weight': 0.1836\n",
      "Gradient norm for 'f2_o.weight': 0.6869\n",
      "saving max acc: 82.5530035335689\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [50/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.03643\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.03923\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.03197\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.04028\n",
      "l1_score: 0\n",
      "Time elasped: 3.0750224590301514\n",
      "Test Loss: 0.8665751665830612\n",
      "Avg spk_count per neuron for all 50 time-steps 6.3396711349487305\n",
      "Avg spk per neuron per layer [11.62171488515901, 13.736969964664311]\n",
      "Test Accuracy of the model on the test samples: 80.698\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0002\n",
      "Gradient norm for 'tau_m_2': 0.0008\n",
      "Gradient norm for 'tau_m_o': 0.0531\n",
      "Gradient norm for 'f0_f1.weight': 0.0435\n",
      "Gradient norm for 'f1_f2.weight': 0.2204\n",
      "Gradient norm for 'f2_o.weight': 0.8196\n"
     ]
    }
   ],
   "source": [
    "snn.to(device)\n",
    "train(snn, train_loader, test_loader, lr, num_epochs, dropout=0.0, lr_scale_tau=20.0, \n",
    "    test_behavior=tb_save_max_last_acc, ckpt_dir=ckpt_dir, scheduler=(100, 0.95), test_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(3):\n",
    "  plt.subplot(3, 1, i+1)\n",
    "  plot_param(snn.tau_params[i], transform=transform)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Delays: tensor([ 0, 16, 32])\n",
      "\n",
      "[INFO] Delays i: tensor([0])\n",
      "\n",
      "[INFO] Delays h: tensor([ 0, 16, 32])\n",
      "\n",
      "[INFO] Delays o: tensor([0])\n",
      "Delta t: 20.0 ms\n",
      "mean of normal: -0.541324854612918\n",
      "\n",
      "[INFO] Delays: tensor([ 0, 16, 32])\n",
      "\n",
      "[INFO] Delays i: tensor([0])\n",
      "\n",
      "[INFO] Delays h: tensor([ 0, 16, 32])\n",
      "\n",
      "[INFO] Delays o: tensor([0])\n",
      "Delta t: 20.0 ms\n",
      "mean of normal: -0.541324854612918\n",
      "training shd50_SNN_l2_48d16.t7 for 50 epochs...\n",
      "Epoch [1/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 2.99573\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 2.99573\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 2.99573\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 2.99573\n",
      "l1_score: 0\n",
      "Time elasped: 3.2934675216674805\n",
      "Test Loss: 4.493598818778992\n",
      "Avg spk_count per neuron for all 50 time-steps 0.46482130885124207\n",
      "Avg spk per neuron per layer [1.859285280477032, 0.0]\n",
      "Test Accuracy of the model on the test samples: 4.549\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0000\n",
      "Gradient norm for 'tau_m_o': 0.0000\n",
      "Gradient norm for 'f0_f1.weight': 0.0004\n",
      "Gradient norm for 'f1_f2.weight': 0.0031\n",
      "Gradient norm for 'f2_o.weight': 0.0000\n",
      "saving max acc: 4.549469964664311\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [2/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 2.99573\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 2.99565\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 2.99511\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 2.99508\n",
      "l1_score: 0\n",
      "Time elasped: 2.7739410400390625\n",
      "Test Loss: 4.491578459739685\n",
      "Avg spk_count per neuron for all 50 time-steps 1.4894734621047974\n",
      "Avg spk per neuron per layer [5.744616828621908, 0.21327710909893993]\n",
      "Test Accuracy of the model on the test samples: 5.389\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0001\n",
      "Gradient norm for 'tau_m_o': 0.0003\n",
      "Gradient norm for 'f0_f1.weight': 0.0009\n",
      "Gradient norm for 'f1_f2.weight': 0.0121\n",
      "Gradient norm for 'f2_o.weight': 0.0590\n",
      "saving max acc: 5.3886925795053005\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [3/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 2.99318\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 2.98878\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 2.98513\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 2.97367\n",
      "l1_score: 0\n",
      "Time elasped: 2.7759437561035156\n",
      "Test Loss: 4.4527599811553955\n",
      "Avg spk_count per neuron for all 50 time-steps 3.064601421356201\n",
      "Avg spk per neuron per layer [9.7245472614841, 2.5338587676678443]\n",
      "Test Accuracy of the model on the test samples: 4.991\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0003\n",
      "Gradient norm for 'tau_m_o': 0.0051\n",
      "Gradient norm for 'f0_f1.weight': 0.0020\n",
      "Gradient norm for 'f1_f2.weight': 0.0315\n",
      "Gradient norm for 'f2_o.weight': 0.4604\n",
      "Epoch [4/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 2.96447\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 2.95584\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 2.94729\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 2.90935\n",
      "l1_score: 0\n",
      "Time elasped: 2.804525852203369\n",
      "Test Loss: 4.371554970741272\n",
      "Avg spk_count per neuron for all 50 time-steps 4.028308391571045\n",
      "Avg spk per neuron per layer [10.840568407685513, 5.27266453180212]\n",
      "Test Accuracy of the model on the test samples: 4.549\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0006\n",
      "Gradient norm for 'tau_m_o': 0.0191\n",
      "Gradient norm for 'f0_f1.weight': 0.0057\n",
      "Gradient norm for 'f1_f2.weight': 0.0449\n",
      "Gradient norm for 'f2_o.weight': 0.7846\n",
      "Epoch [5/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 2.91421\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 2.89135\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 2.85876\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 2.84933\n",
      "l1_score: 0\n",
      "Time elasped: 2.829313278198242\n",
      "Test Loss: 4.269990086555481\n",
      "Avg spk_count per neuron for all 50 time-steps 4.381121635437012\n",
      "Avg spk per neuron per layer [11.315895538869258, 6.208590989399293]\n",
      "Test Accuracy of the model on the test samples: 6.979\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0008\n",
      "Gradient norm for 'tau_m_o': 0.0210\n",
      "Gradient norm for 'f0_f1.weight': 0.0108\n",
      "Gradient norm for 'f1_f2.weight': 0.0756\n",
      "Gradient norm for 'f2_o.weight': 0.9847\n",
      "saving max acc: 6.978798586572438\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [6/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 2.82765\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 2.79882\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 2.75517\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 2.72544\n",
      "l1_score: 0\n",
      "Time elasped: 2.9017891883850098\n",
      "Test Loss: 4.043602108955383\n",
      "Avg spk_count per neuron for all 50 time-steps 5.073244094848633\n",
      "Avg spk per neuron per layer [12.119603025618375, 8.173372625883392]\n",
      "Test Accuracy of the model on the test samples: 15.239\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0000\n",
      "Gradient norm for 'tau_m_2': 0.0010\n",
      "Gradient norm for 'tau_m_o': 0.0352\n",
      "Gradient norm for 'f0_f1.weight': 0.0116\n",
      "Gradient norm for 'f1_f2.weight': 0.0664\n",
      "Gradient norm for 'f2_o.weight': 0.9413\n",
      "saving max acc: 15.23851590106007\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [7/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 2.66494\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 2.65037\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 2.60847\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 2.57084\n",
      "l1_score: 0\n",
      "Time elasped: 3.195892333984375\n",
      "Test Loss: 3.814817786216736\n",
      "Avg spk_count per neuron for all 50 time-steps 5.358634948730469\n",
      "Avg spk per neuron per layer [12.2909535114841, 9.143585744257951]\n",
      "Test Accuracy of the model on the test samples: 22.041\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0001\n",
      "Gradient norm for 'tau_m_2': 0.0017\n",
      "Gradient norm for 'tau_m_o': 0.0396\n",
      "Gradient norm for 'f0_f1.weight': 0.0629\n",
      "Gradient norm for 'f1_f2.weight': 0.1985\n",
      "Gradient norm for 'f2_o.weight': 1.6781\n",
      "saving max acc: 22.040636042402827\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [8/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 2.52000\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 2.42449\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 2.41413\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 2.36303\n",
      "l1_score: 0\n",
      "Time elasped: 3.443000078201294\n",
      "Test Loss: 3.4757065773010254\n",
      "Avg spk_count per neuron for all 50 time-steps 6.04443359375\n",
      "Avg spk per neuron per layer [12.53803417623675, 11.63970019876325]\n",
      "Test Accuracy of the model on the test samples: 31.095\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0001\n",
      "Gradient norm for 'tau_m_2': 0.0010\n",
      "Gradient norm for 'tau_m_o': 0.0759\n",
      "Gradient norm for 'f0_f1.weight': 0.0812\n",
      "Gradient norm for 'f1_f2.weight': 0.2273\n",
      "Gradient norm for 'f2_o.weight': 1.8311\n",
      "saving max acc: 31.09540636042403\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [9/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 2.23892\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 2.22855\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 2.16514\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 2.10998\n",
      "l1_score: 0\n",
      "Time elasped: 3.8154473304748535\n",
      "Test Loss: 3.1389119625091553\n",
      "Avg spk_count per neuron for all 50 time-steps 6.693086624145508\n",
      "Avg spk per neuron per layer [12.770504361749117, 14.001842700971732]\n",
      "Test Accuracy of the model on the test samples: 33.966\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0001\n",
      "Gradient norm for 'tau_m_2': 0.0012\n",
      "Gradient norm for 'tau_m_o': 0.0859\n",
      "Gradient norm for 'f0_f1.weight': 0.0950\n",
      "Gradient norm for 'f1_f2.weight': 0.2055\n",
      "Gradient norm for 'f2_o.weight': 2.8907\n",
      "saving max acc: 33.966431095406364\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [10/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 1.99557\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 1.95073\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 1.89479\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 1.85158\n",
      "l1_score: 0\n",
      "Time elasped: 3.7397992610931396\n",
      "Test Loss: 2.6517194509506226\n",
      "Avg spk_count per neuron for all 50 time-steps 7.256687641143799\n",
      "Avg spk per neuron per layer [13.6875, 15.339250220848056]\n",
      "Test Accuracy of the model on the test samples: 48.940\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0003\n",
      "Gradient norm for 'tau_m_2': 0.0009\n",
      "Gradient norm for 'tau_m_o': 0.1140\n",
      "Gradient norm for 'f0_f1.weight': 0.0869\n",
      "Gradient norm for 'f1_f2.weight': 0.1688\n",
      "Gradient norm for 'f2_o.weight': 2.5206\n",
      "saving max acc: 48.93992932862191\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [11/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 1.74907\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 1.66129\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 1.70204\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 1.58429\n",
      "l1_score: 0\n",
      "Time elasped: 3.7147111892700195\n",
      "Test Loss: 2.3074980974197388\n",
      "Avg spk_count per neuron for all 50 time-steps 7.458409786224365\n",
      "Avg spk per neuron per layer [13.838711903710248, 15.994927396201414]\n",
      "Test Accuracy of the model on the test samples: 54.417\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0002\n",
      "Gradient norm for 'tau_m_2': 0.0013\n",
      "Gradient norm for 'tau_m_o': 0.1204\n",
      "Gradient norm for 'f0_f1.weight': 0.1398\n",
      "Gradient norm for 'f1_f2.weight': 0.2659\n",
      "Gradient norm for 'f2_o.weight': 3.3006\n",
      "saving max acc: 54.41696113074205\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [12/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 1.55375\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 1.58546\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 1.47011\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 1.41639\n",
      "l1_score: 0\n",
      "Time elasped: 3.6279618740081787\n",
      "Test Loss: 2.044783592224121\n",
      "Avg spk_count per neuron for all 50 time-steps 7.616048812866211\n",
      "Avg spk per neuron per layer [14.02601176015901, 16.43818324867491]\n",
      "Test Accuracy of the model on the test samples: 57.730\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0003\n",
      "Gradient norm for 'tau_m_2': 0.0018\n",
      "Gradient norm for 'tau_m_o': 0.1421\n",
      "Gradient norm for 'f0_f1.weight': 0.2734\n",
      "Gradient norm for 'f1_f2.weight': 0.4503\n",
      "Gradient norm for 'f2_o.weight': 6.3302\n",
      "saving max acc: 57.72968197879859\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [13/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 1.34190\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 1.32202\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 1.25348\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 1.20176\n",
      "l1_score: 0\n",
      "Time elasped: 3.91282057762146\n",
      "Test Loss: 1.812618911266327\n",
      "Avg spk_count per neuron for all 50 time-steps 7.837081432342529\n",
      "Avg spk per neuron per layer [14.434877429328623, 16.913448266342755]\n",
      "Test Accuracy of the model on the test samples: 61.440\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0003\n",
      "Gradient norm for 'tau_m_2': 0.0013\n",
      "Gradient norm for 'tau_m_o': 0.1159\n",
      "Gradient norm for 'f0_f1.weight': 0.1687\n",
      "Gradient norm for 'f1_f2.weight': 0.3927\n",
      "Gradient norm for 'f2_o.weight': 5.1423\n",
      "saving max acc: 61.43992932862191\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [14/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 1.11417\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 1.17333\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 1.02801\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 1.04832\n",
      "l1_score: 0\n",
      "Time elasped: 3.8610289096832275\n",
      "Test Loss: 1.5669233798980713\n",
      "Avg spk_count per neuron for all 50 time-steps 7.740874767303467\n",
      "Avg spk per neuron per layer [14.207679991166078, 16.7558179659894]\n",
      "Test Accuracy of the model on the test samples: 67.403\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0003\n",
      "Gradient norm for 'tau_m_2': 0.0009\n",
      "Gradient norm for 'tau_m_o': 0.1343\n",
      "Gradient norm for 'f0_f1.weight': 0.1417\n",
      "Gradient norm for 'f1_f2.weight': 0.2291\n",
      "Gradient norm for 'f2_o.weight': 4.9136\n",
      "saving max acc: 67.40282685512368\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [15/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.96089\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.99306\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.89283\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.89605\n",
      "l1_score: 0\n",
      "Time elasped: 3.7053840160369873\n",
      "Test Loss: 1.4354709684848785\n",
      "Avg spk_count per neuron for all 50 time-steps 7.77139139175415\n",
      "Avg spk per neuron per layer [14.228474215989399, 16.857090602915193]\n",
      "Test Accuracy of the model on the test samples: 69.744\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0003\n",
      "Gradient norm for 'tau_m_2': 0.0012\n",
      "Gradient norm for 'tau_m_o': 0.1663\n",
      "Gradient norm for 'f0_f1.weight': 0.1301\n",
      "Gradient norm for 'f1_f2.weight': 0.2410\n",
      "Gradient norm for 'f2_o.weight': 4.2982\n",
      "saving max acc: 69.74381625441696\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [16/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.85558\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.82846\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.76647\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.76876\n",
      "l1_score: 0\n",
      "Time elasped: 3.6497936248779297\n",
      "Test Loss: 1.3235849440097809\n",
      "Avg spk_count per neuron for all 50 time-steps 7.855175495147705\n",
      "Avg spk per neuron per layer [14.41916961130742, 17.001532133392224]\n",
      "Test Accuracy of the model on the test samples: 68.772\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0004\n",
      "Gradient norm for 'tau_m_2': 0.0022\n",
      "Gradient norm for 'tau_m_o': 0.1661\n",
      "Gradient norm for 'f0_f1.weight': 0.1514\n",
      "Gradient norm for 'f1_f2.weight': 0.4194\n",
      "Gradient norm for 'f2_o.weight': 7.4161\n",
      "Epoch [17/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.71318\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.72185\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.62544\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.68036\n",
      "l1_score: 0\n",
      "Time elasped: 4.321983098983765\n",
      "Test Loss: 1.2105061709880829\n",
      "Avg spk_count per neuron for all 50 time-steps 7.8112473487854\n",
      "Avg spk per neuron per layer [14.313811285335689, 16.931178224381625]\n",
      "Test Accuracy of the model on the test samples: 73.587\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0002\n",
      "Gradient norm for 'tau_m_2': 0.0014\n",
      "Gradient norm for 'tau_m_o': 0.1907\n",
      "Gradient norm for 'f0_f1.weight': 0.1769\n",
      "Gradient norm for 'f1_f2.weight': 0.3674\n",
      "Gradient norm for 'f2_o.weight': 6.8701\n",
      "saving max acc: 73.58657243816255\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [18/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.64253\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.60693\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.60445\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.55167\n",
      "l1_score: 0\n",
      "Time elasped: 3.8388803005218506\n",
      "Test Loss: 1.190214067697525\n",
      "Avg spk_count per neuron for all 50 time-steps 7.675004959106445\n",
      "Avg spk per neuron per layer [14.119865282685513, 16.580154041519435]\n",
      "Test Accuracy of the model on the test samples: 75.486\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0003\n",
      "Gradient norm for 'tau_m_2': 0.0019\n",
      "Gradient norm for 'tau_m_o': 0.1970\n",
      "Gradient norm for 'f0_f1.weight': 0.2033\n",
      "Gradient norm for 'f1_f2.weight': 0.6442\n",
      "Gradient norm for 'f2_o.weight': 5.6380\n",
      "saving max acc: 75.48586572438163\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [19/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.54119\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.56315\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.52747\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.49372\n",
      "l1_score: 0\n",
      "Time elasped: 3.8198256492614746\n",
      "Test Loss: 1.0922482311725616\n",
      "Avg spk_count per neuron for all 50 time-steps 7.746821880340576\n",
      "Avg spk per neuron per layer [14.447265625, 16.540021808745582]\n",
      "Test Accuracy of the model on the test samples: 76.723\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0004\n",
      "Gradient norm for 'tau_m_2': 0.0018\n",
      "Gradient norm for 'tau_m_o': 0.1402\n",
      "Gradient norm for 'f0_f1.weight': 0.2695\n",
      "Gradient norm for 'f1_f2.weight': 0.5879\n",
      "Gradient norm for 'f2_o.weight': 4.3697\n",
      "saving max acc: 76.7226148409894\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [20/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.48019\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.47438\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.45640\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.42584\n",
      "l1_score: 0\n",
      "Time elasped: 3.758094310760498\n",
      "Test Loss: 1.0294969975948334\n",
      "Avg spk_count per neuron for all 50 time-steps 7.721258640289307\n",
      "Avg spk per neuron per layer [14.367373840547703, 16.517660943021202]\n",
      "Test Accuracy of the model on the test samples: 77.739\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0002\n",
      "Gradient norm for 'tau_m_2': 0.0015\n",
      "Gradient norm for 'tau_m_o': 0.1014\n",
      "Gradient norm for 'f0_f1.weight': 0.1157\n",
      "Gradient norm for 'f1_f2.weight': 0.2849\n",
      "Gradient norm for 'f2_o.weight': 3.1209\n",
      "saving max acc: 77.73851590106007\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [21/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.42588\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.38759\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.42190\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.41422\n",
      "l1_score: 0\n",
      "Time elasped: 3.6866655349731445\n",
      "Test Loss: 1.003097802400589\n",
      "Avg spk_count per neuron for all 50 time-steps 7.714232921600342\n",
      "Avg spk per neuron per layer [14.416415912102474, 16.440515956272083]\n",
      "Test Accuracy of the model on the test samples: 77.871\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0003\n",
      "Gradient norm for 'tau_m_2': 0.0018\n",
      "Gradient norm for 'tau_m_o': 0.1559\n",
      "Gradient norm for 'f0_f1.weight': 0.2557\n",
      "Gradient norm for 'f1_f2.weight': 0.5084\n",
      "Gradient norm for 'f2_o.weight': 5.8520\n",
      "saving max acc: 77.87102473498233\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [22/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.40222\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.41541\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.39579\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.35910\n",
      "l1_score: 0\n",
      "Time elasped: 3.7951643466949463\n",
      "Test Loss: 1.0409285724163055\n",
      "Avg spk_count per neuron for all 50 time-steps 7.704244613647461\n",
      "Avg spk per neuron per layer [14.399072438162545, 16.417906636484098]\n",
      "Test Accuracy of the model on the test samples: 79.638\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0002\n",
      "Gradient norm for 'tau_m_2': 0.0014\n",
      "Gradient norm for 'tau_m_o': 0.1256\n",
      "Gradient norm for 'f0_f1.weight': 0.2424\n",
      "Gradient norm for 'f1_f2.weight': 0.4745\n",
      "Gradient norm for 'f2_o.weight': 4.6581\n",
      "saving max acc: 79.63780918727915\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [23/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.33152\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.31709\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.31822\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.31668\n",
      "l1_score: 0\n",
      "Time elasped: 3.7059693336486816\n",
      "Test Loss: 0.9411217272281647\n",
      "Avg spk_count per neuron for all 50 time-steps 7.757584571838379\n",
      "Avg spk per neuron per layer [14.50937914090106, 16.520959860865723]\n",
      "Test Accuracy of the model on the test samples: 81.625\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0003\n",
      "Gradient norm for 'tau_m_2': 0.0019\n",
      "Gradient norm for 'tau_m_o': 0.1188\n",
      "Gradient norm for 'f0_f1.weight': 0.1645\n",
      "Gradient norm for 'f1_f2.weight': 0.4221\n",
      "Gradient norm for 'f2_o.weight': 3.3297\n",
      "saving max acc: 81.62544169611307\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [24/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.34962\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.30401\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.25065\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.28802\n",
      "l1_score: 0\n",
      "Time elasped: 3.6477134227752686\n",
      "Test Loss: 0.9081162214279175\n",
      "Avg spk_count per neuron for all 50 time-steps 7.806632041931152\n",
      "Avg spk per neuron per layer [14.680619202738516, 16.54590878975265]\n",
      "Test Accuracy of the model on the test samples: 81.537\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0002\n",
      "Gradient norm for 'tau_m_2': 0.0015\n",
      "Gradient norm for 'tau_m_o': 0.1018\n",
      "Gradient norm for 'f0_f1.weight': 0.2128\n",
      "Gradient norm for 'f1_f2.weight': 0.4551\n",
      "Gradient norm for 'f2_o.weight': 3.4841\n",
      "Epoch [25/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.26457\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.26550\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.25097\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.25819\n",
      "l1_score: 0\n",
      "Time elasped: 3.768867254257202\n",
      "Test Loss: 0.9882884919643402\n",
      "Avg spk_count per neuron for all 50 time-steps 7.803944110870361\n",
      "Avg spk per neuron per layer [14.610175574204947, 16.605599878533567]\n",
      "Test Accuracy of the model on the test samples: 80.168\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0002\n",
      "Gradient norm for 'tau_m_2': 0.0013\n",
      "Gradient norm for 'tau_m_o': 0.2407\n",
      "Gradient norm for 'f0_f1.weight': 0.1053\n",
      "Gradient norm for 'f1_f2.weight': 0.4471\n",
      "Gradient norm for 'f2_o.weight': 7.4644\n",
      "Epoch [26/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.24806\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.24992\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.25311\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.22766\n",
      "l1_score: 0\n",
      "Time elasped: 3.849914073944092\n",
      "Test Loss: 0.9230461120605469\n",
      "Avg spk_count per neuron for all 50 time-steps 7.835466384887695\n",
      "Avg spk per neuron per layer [14.732911881625443, 16.608954008392224]\n",
      "Test Accuracy of the model on the test samples: 80.830\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0002\n",
      "Gradient norm for 'tau_m_2': 0.0009\n",
      "Gradient norm for 'tau_m_o': 0.0934\n",
      "Gradient norm for 'f0_f1.weight': 0.0869\n",
      "Gradient norm for 'f1_f2.weight': 0.2616\n",
      "Gradient norm for 'f2_o.weight': 3.4884\n",
      "Epoch [27/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.22267\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.19039\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.22822\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.23194\n",
      "l1_score: 0\n",
      "Time elasped: 3.638364791870117\n",
      "Test Loss: 0.9133747220039368\n",
      "Avg spk_count per neuron for all 50 time-steps 7.768492698669434\n",
      "Avg spk per neuron per layer [14.532961572438163, 16.541008723498233]\n",
      "Test Accuracy of the model on the test samples: 80.080\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0004\n",
      "Gradient norm for 'tau_m_2': 0.0016\n",
      "Gradient norm for 'tau_m_o': 0.1993\n",
      "Gradient norm for 'f0_f1.weight': 0.2269\n",
      "Gradient norm for 'f1_f2.weight': 0.5724\n",
      "Gradient norm for 'f2_o.weight': 7.5146\n",
      "Epoch [28/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.26002\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.18514\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.22607\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.17657\n",
      "l1_score: 0\n",
      "Time elasped: 3.7142751216888428\n",
      "Test Loss: 0.9575541913509369\n",
      "Avg spk_count per neuron for all 50 time-steps 7.842340469360352\n",
      "Avg spk per neuron per layer [14.707597173144876, 16.66176429991166]\n",
      "Test Accuracy of the model on the test samples: 79.814\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0002\n",
      "Gradient norm for 'tau_m_2': 0.0010\n",
      "Gradient norm for 'tau_m_o': 0.1364\n",
      "Gradient norm for 'f0_f1.weight': 0.0825\n",
      "Gradient norm for 'f1_f2.weight': 0.2802\n",
      "Gradient norm for 'f2_o.weight': 3.8313\n",
      "Epoch [29/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.17298\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.16159\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.18196\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.19910\n",
      "l1_score: 0\n",
      "Time elasped: 3.7968218326568604\n",
      "Test Loss: 0.9551455974578857\n",
      "Avg spk_count per neuron for all 50 time-steps 7.840886116027832\n",
      "Avg spk per neuron per layer [14.712000331272085, 16.65154317579505]\n",
      "Test Accuracy of the model on the test samples: 81.140\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0003\n",
      "Gradient norm for 'tau_m_2': 0.0014\n",
      "Gradient norm for 'tau_m_o': 0.1561\n",
      "Gradient norm for 'f0_f1.weight': 0.2039\n",
      "Gradient norm for 'f1_f2.weight': 0.4736\n",
      "Gradient norm for 'f2_o.weight': 4.2984\n",
      "Epoch [30/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.16013\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.16500\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.15831\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.14985\n",
      "l1_score: 0\n",
      "Time elasped: 3.664682626724243\n",
      "Test Loss: 0.9577221274375916\n",
      "Avg spk_count per neuron for all 50 time-steps 7.74375057220459\n",
      "Avg spk per neuron per layer [14.588497957155477, 16.38650480344523]\n",
      "Test Accuracy of the model on the test samples: 81.935\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0001\n",
      "Gradient norm for 'tau_m_2': 0.0009\n",
      "Gradient norm for 'tau_m_o': 0.0696\n",
      "Gradient norm for 'f0_f1.weight': 0.1112\n",
      "Gradient norm for 'f1_f2.weight': 0.2983\n",
      "Gradient norm for 'f2_o.weight': 2.9410\n",
      "saving max acc: 81.93462897526501\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [31/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.16052\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.16586\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.19866\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.14128\n",
      "l1_score: 0\n",
      "Time elasped: 3.8830039501190186\n",
      "Test Loss: 1.1324681043624878\n",
      "Avg spk_count per neuron for all 50 time-steps 7.838244438171387\n",
      "Avg spk per neuron per layer [14.649610755300353, 16.70336655256184]\n",
      "Test Accuracy of the model on the test samples: 78.799\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0004\n",
      "Gradient norm for 'tau_m_2': 0.0018\n",
      "Gradient norm for 'tau_m_o': 0.1035\n",
      "Gradient norm for 'f0_f1.weight': 0.2346\n",
      "Gradient norm for 'f1_f2.weight': 0.5362\n",
      "Gradient norm for 'f2_o.weight': 3.4415\n",
      "Epoch [32/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.15083\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.15787\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.13851\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.14839\n",
      "l1_score: 0\n",
      "Time elasped: 3.7259843349456787\n",
      "Test Loss: 0.9463310837745667\n",
      "Avg spk_count per neuron for all 50 time-steps 7.848470687866211\n",
      "Avg spk per neuron per layer [14.762436506183745, 16.631446002650176]\n",
      "Test Accuracy of the model on the test samples: 80.521\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0002\n",
      "Gradient norm for 'tau_m_2': 0.0013\n",
      "Gradient norm for 'tau_m_o': 0.1079\n",
      "Gradient norm for 'f0_f1.weight': 0.1408\n",
      "Gradient norm for 'f1_f2.weight': 0.4166\n",
      "Gradient norm for 'f2_o.weight': 3.0726\n",
      "Epoch [33/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.13493\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.14883\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.12161\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.15813\n",
      "l1_score: 0\n",
      "Time elasped: 3.8004305362701416\n",
      "Test Loss: 0.8766200840473175\n",
      "Avg spk_count per neuron for all 50 time-steps 7.7854132652282715\n",
      "Avg spk per neuron per layer [14.66625027606007, 16.475403047703182]\n",
      "Test Accuracy of the model on the test samples: 83.348\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0002\n",
      "Gradient norm for 'tau_m_2': 0.0014\n",
      "Gradient norm for 'tau_m_o': 0.0890\n",
      "Gradient norm for 'f0_f1.weight': 0.2117\n",
      "Gradient norm for 'f1_f2.weight': 0.4694\n",
      "Gradient norm for 'f2_o.weight': 3.7727\n",
      "saving max acc: 83.34805653710248\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Epoch [34/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.13466\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.10723\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.13915\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.12079\n",
      "l1_score: 0\n",
      "Time elasped: 3.8220133781433105\n",
      "Test Loss: 0.8922693431377411\n",
      "Avg spk_count per neuron for all 50 time-steps 7.857147693634033\n",
      "Avg spk per neuron per layer [14.780939432420494, 16.647650728798588]\n",
      "Test Accuracy of the model on the test samples: 82.906\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0002\n",
      "Gradient norm for 'tau_m_2': 0.0013\n",
      "Gradient norm for 'tau_m_o': 0.0665\n",
      "Gradient norm for 'f0_f1.weight': 0.1749\n",
      "Gradient norm for 'f1_f2.weight': 0.3616\n",
      "Gradient norm for 'f2_o.weight': 3.2919\n",
      "Epoch [35/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.11166\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.10033\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.10472\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.11778\n",
      "l1_score: 0\n",
      "Time elasped: 3.8235280513763428\n",
      "Test Loss: 0.8738570809364319\n",
      "Avg spk_count per neuron for all 50 time-steps 7.8198466300964355\n",
      "Avg spk per neuron per layer [14.722069622349823, 16.557316972173144]\n",
      "Test Accuracy of the model on the test samples: 82.862\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0002\n",
      "Gradient norm for 'tau_m_2': 0.0010\n",
      "Gradient norm for 'tau_m_o': 0.1249\n",
      "Gradient norm for 'f0_f1.weight': 0.0922\n",
      "Gradient norm for 'f1_f2.weight': 0.3563\n",
      "Gradient norm for 'f2_o.weight': 5.4074\n",
      "Epoch [36/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.10625\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.09113\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.09156\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.12934\n",
      "l1_score: 0\n",
      "Time elasped: 3.74714994430542\n",
      "Test Loss: 0.8892576992511749\n",
      "Avg spk_count per neuron for all 50 time-steps 7.785342693328857\n",
      "Avg spk per neuron per layer [14.653171930212014, 16.488198431978798]\n",
      "Test Accuracy of the model on the test samples: 82.023\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0003\n",
      "Gradient norm for 'tau_m_2': 0.0011\n",
      "Gradient norm for 'tau_m_o': 0.1099\n",
      "Gradient norm for 'f0_f1.weight': 0.1379\n",
      "Gradient norm for 'f1_f2.weight': 0.4120\n",
      "Gradient norm for 'f2_o.weight': 4.1310\n",
      "Epoch [37/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.08513\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.08165\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.09081\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.08325\n",
      "l1_score: 0\n",
      "Time elasped: 3.637333393096924\n",
      "Test Loss: 0.9279497861862183\n",
      "Avg spk_count per neuron for all 50 time-steps 7.82890510559082\n",
      "Avg spk per neuron per layer [14.739965216431095, 16.57565426236749]\n",
      "Test Accuracy of the model on the test samples: 81.405\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0001\n",
      "Gradient norm for 'tau_m_2': 0.0005\n",
      "Gradient norm for 'tau_m_o': 0.0770\n",
      "Gradient norm for 'f0_f1.weight': 0.0655\n",
      "Gradient norm for 'f1_f2.weight': 0.2005\n",
      "Gradient norm for 'f2_o.weight': 2.8379\n",
      "Epoch [38/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.09571\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.07663\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.07995\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.07047\n",
      "l1_score: 0\n",
      "Time elasped: 3.9910268783569336\n",
      "Test Loss: 1.0015223622322083\n",
      "Avg spk_count per neuron for all 50 time-steps 7.820580005645752\n",
      "Avg spk per neuron per layer [14.759793231007068, 16.522526501766784]\n",
      "Test Accuracy of the model on the test samples: 81.405\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0002\n",
      "Gradient norm for 'tau_m_2': 0.0008\n",
      "Gradient norm for 'tau_m_o': 0.0515\n",
      "Gradient norm for 'f0_f1.weight': 0.1290\n",
      "Gradient norm for 'f1_f2.weight': 0.2808\n",
      "Gradient norm for 'f2_o.weight': 1.6139\n",
      "Epoch [39/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.07247\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.07143\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.08060\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.09081\n",
      "l1_score: 0\n",
      "Time elasped: 3.6423065662384033\n",
      "Test Loss: 1.0672131180763245\n",
      "Avg spk_count per neuron for all 50 time-steps 7.832533359527588\n",
      "Avg spk per neuron per layer [14.697721124116608, 16.632412212897528]\n",
      "Test Accuracy of the model on the test samples: 80.830\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0001\n",
      "Gradient norm for 'tau_m_2': 0.0011\n",
      "Gradient norm for 'tau_m_o': 0.1075\n",
      "Gradient norm for 'f0_f1.weight': 0.0967\n",
      "Gradient norm for 'f1_f2.weight': 0.3081\n",
      "Gradient norm for 'f2_o.weight': 3.5898\n",
      "Epoch [40/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.06683\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.09782\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.07618\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.05514\n",
      "l1_score: 0\n",
      "Time elasped: 3.7189745903015137\n",
      "Test Loss: 1.1133398711681366\n",
      "Avg spk_count per neuron for all 50 time-steps 7.866147041320801\n",
      "Avg spk per neuron per layer [14.818814874116608, 16.64577352031802]\n",
      "Test Accuracy of the model on the test samples: 81.670\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0001\n",
      "Gradient norm for 'tau_m_2': 0.0009\n",
      "Gradient norm for 'tau_m_o': 0.0761\n",
      "Gradient norm for 'f0_f1.weight': 0.0895\n",
      "Gradient norm for 'f1_f2.weight': 0.2802\n",
      "Gradient norm for 'f2_o.weight': 3.0597\n",
      "Epoch [41/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.06983\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.07618\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.07386\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.07887\n",
      "l1_score: 0\n",
      "Time elasped: 3.90244460105896\n",
      "Test Loss: 1.0941164791584015\n",
      "Avg spk_count per neuron for all 50 time-steps 7.831132411956787\n",
      "Avg spk per neuron per layer [14.743091596731448, 16.581437720848058]\n",
      "Test Accuracy of the model on the test samples: 81.714\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0002\n",
      "Gradient norm for 'tau_m_2': 0.0010\n",
      "Gradient norm for 'tau_m_o': 0.0927\n",
      "Gradient norm for 'f0_f1.weight': 0.0853\n",
      "Gradient norm for 'f1_f2.weight': 0.2831\n",
      "Gradient norm for 'f2_o.weight': 3.4075\n",
      "Epoch [42/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.08071\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.06369\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.09437\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.08248\n",
      "l1_score: 0\n",
      "Time elasped: 3.727108955383301\n",
      "Test Loss: 0.931871771812439\n",
      "Avg spk_count per neuron for all 50 time-steps 7.800106525421143\n",
      "Avg spk per neuron per layer [14.75603191254417, 16.444394600265017]\n",
      "Test Accuracy of the model on the test samples: 82.995\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0002\n",
      "Gradient norm for 'tau_m_2': 0.0011\n",
      "Gradient norm for 'tau_m_o': 0.0707\n",
      "Gradient norm for 'f0_f1.weight': 0.0945\n",
      "Gradient norm for 'f1_f2.weight': 0.3145\n",
      "Gradient norm for 'f2_o.weight': 3.3255\n",
      "Epoch [43/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.06402\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.05273\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.06764\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.04957\n",
      "l1_score: 0\n",
      "Time elasped: 3.7135870456695557\n",
      "Test Loss: 1.0257115066051483\n",
      "Avg spk_count per neuron for all 50 time-steps 7.89297342300415\n",
      "Avg spk per neuron per layer [14.835516508392226, 16.73637643551237]\n",
      "Test Accuracy of the model on the test samples: 81.360\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0001\n",
      "Gradient norm for 'tau_m_2': 0.0006\n",
      "Gradient norm for 'tau_m_o': 0.0390\n",
      "Gradient norm for 'f0_f1.weight': 0.0526\n",
      "Gradient norm for 'f1_f2.weight': 0.1778\n",
      "Gradient norm for 'f2_o.weight': 1.7811\n",
      "Epoch [44/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.06705\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.06049\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.05275\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.06610\n",
      "l1_score: 0\n",
      "Time elasped: 3.713946580886841\n",
      "Test Loss: 0.9136078059673309\n",
      "Avg spk_count per neuron for all 50 time-steps 7.849103927612305\n",
      "Avg spk per neuron per layer [14.804701303003533, 16.591714056978798]\n",
      "Test Accuracy of the model on the test samples: 82.862\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0002\n",
      "Gradient norm for 'tau_m_2': 0.0010\n",
      "Gradient norm for 'tau_m_o': 0.1144\n",
      "Gradient norm for 'f0_f1.weight': 0.1048\n",
      "Gradient norm for 'f1_f2.weight': 0.2864\n",
      "Gradient norm for 'f2_o.weight': 3.5777\n",
      "Epoch [45/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.05005\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.04857\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.06511\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.03949\n",
      "l1_score: 0\n",
      "Time elasped: 3.7943084239959717\n",
      "Test Loss: 1.0735890865325928\n",
      "Avg spk_count per neuron for all 50 time-steps 7.859185218811035\n",
      "Avg spk per neuron per layer [14.777930377650177, 16.65881045715548]\n",
      "Test Accuracy of the model on the test samples: 81.051\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0001\n",
      "Gradient norm for 'tau_m_2': 0.0004\n",
      "Gradient norm for 'tau_m_o': 0.0211\n",
      "Gradient norm for 'f0_f1.weight': 0.0306\n",
      "Gradient norm for 'f1_f2.weight': 0.1240\n",
      "Gradient norm for 'f2_o.weight': 1.0113\n",
      "Epoch [46/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.05520\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.04439\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.04780\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.03734\n",
      "l1_score: 0\n",
      "Time elasped: 3.725011110305786\n",
      "Test Loss: 0.9607333838939667\n",
      "Avg spk_count per neuron for all 50 time-steps 7.778604984283447\n",
      "Avg spk per neuron per layer [14.681999503091873, 16.432420494699645]\n",
      "Test Accuracy of the model on the test samples: 82.332\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0001\n",
      "Gradient norm for 'tau_m_2': 0.0005\n",
      "Gradient norm for 'tau_m_o': 0.0358\n",
      "Gradient norm for 'f0_f1.weight': 0.0518\n",
      "Gradient norm for 'f1_f2.weight': 0.1454\n",
      "Gradient norm for 'f2_o.weight': 1.4093\n",
      "Epoch [47/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.04745\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.04331\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.03839\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.04625\n",
      "l1_score: 0\n",
      "Time elasped: 3.593693494796753\n",
      "Test Loss: 1.1462963223457336\n",
      "Avg spk_count per neuron for all 50 time-steps 7.85506010055542\n",
      "Avg spk per neuron per layer [14.810457155477032, 16.60978218860424]\n",
      "Test Accuracy of the model on the test samples: 80.919\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0001\n",
      "Gradient norm for 'tau_m_2': 0.0008\n",
      "Gradient norm for 'tau_m_o': 0.0762\n",
      "Gradient norm for 'f0_f1.weight': 0.0939\n",
      "Gradient norm for 'f1_f2.weight': 0.2452\n",
      "Gradient norm for 'f2_o.weight': 1.8606\n",
      "Epoch [48/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.03779\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.05767\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.05168\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.05475\n",
      "l1_score: 0\n",
      "Time elasped: 3.6649389266967773\n",
      "Test Loss: 1.1271354854106903\n",
      "Avg spk_count per neuron for all 50 time-steps 7.823318004608154\n",
      "Avg spk per neuron per layer [14.739185346731448, 16.55408706934629]\n",
      "Test Accuracy of the model on the test samples: 81.140\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0002\n",
      "Gradient norm for 'tau_m_2': 0.0008\n",
      "Gradient norm for 'tau_m_o': 0.0669\n",
      "Gradient norm for 'f0_f1.weight': 0.0720\n",
      "Gradient norm for 'f1_f2.weight': 0.2403\n",
      "Gradient norm for 'f2_o.weight': 2.6424\n",
      "Epoch [49/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.03339\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.03647\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.03585\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.04170\n",
      "l1_score: 0\n",
      "Time elasped: 3.7173054218292236\n",
      "Test Loss: 1.2085058093070984\n",
      "Avg spk_count per neuron for all 50 time-steps 7.840499401092529\n",
      "Avg spk per neuron per layer [14.75671516121908, 16.605282409452297]\n",
      "Test Accuracy of the model on the test samples: 79.947\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0001\n",
      "Gradient norm for 'tau_m_2': 0.0008\n",
      "Gradient norm for 'tau_m_o': 0.0334\n",
      "Gradient norm for 'f0_f1.weight': 0.0476\n",
      "Gradient norm for 'f1_f2.weight': 0.1317\n",
      "Gradient norm for 'f2_o.weight': 1.3006\n",
      "Epoch [50/50], learning_rates 0.000500, 0.010000\n",
      "Step [2/7], Loss: 0.03968\n",
      "l1_score: 0\n",
      "Step [4/7], Loss: 0.03691\n",
      "l1_score: 0\n",
      "Step [6/7], Loss: 0.03236\n",
      "l1_score: 0\n",
      "Step [8/7], Loss: 0.03367\n",
      "l1_score: 0\n",
      "Time elasped: 3.6242737770080566\n",
      "Test Loss: 1.0023051500320435\n",
      "Avg spk_count per neuron for all 50 time-steps 7.797390937805176\n",
      "Avg spk per neuron per layer [14.71844633392226, 16.471117215106005]\n",
      "Test Accuracy of the model on the test samples: 82.376\n",
      "\n",
      "Model saved in  C:\\Users\\Alberto\\OneDrive - UNIVERSIDAD DE SEVILLA\\PythonData\\Checkpoints\\exp3_shd50\n",
      "Gradient norm for 'tau_m_1': 0.0001\n",
      "Gradient norm for 'tau_m_2': 0.0006\n",
      "Gradient norm for 'tau_m_o': 0.0303\n",
      "Gradient norm for 'f0_f1.weight': 0.0713\n",
      "Gradient norm for 'f1_f2.weight': 0.1878\n",
      "Gradient norm for 'f2_o.weight': 1.8390\n"
     ]
    }
   ],
   "source": [
    "from snn_delays.utils.hw_aware_utils import scale_weights\n",
    "from snn_delays.utils.train_utils import copy_snn\n",
    "\n",
    "snn = SNN(dataset_dict=dataset_dict, structure=(64, 2), connection_type='f',\n",
    "    delay=delay, delay_type='h', tau_m = tau_m,\n",
    "    win=total_time, loss_fn='mem_sum', batch_size=batch_size, device=device,\n",
    "    debug=False)\n",
    "\n",
    "snn.input2spike_th = None\n",
    "\n",
    "snn2 = copy_snn(snn)\n",
    "\n",
    "scaling_factor = 0.1\n",
    "\n",
    "snn2.f0_f1.weight.data = scaling_factor*snn2.f0_f1.weight.data\n",
    "snn2.f1_f2.weight.data = scaling_factor*snn2.f1_f2.weight.data\n",
    "snn2.f2_o.weight.data = scaling_factor*snn2.f2_o.weight.data\n",
    "\n",
    "snn2.input2spike_th = None\n",
    "\n",
    "# print('AFTER WEIGHT SCALING')\n",
    "# scale_weights(snn2.f0_f1, scaling_factor)\n",
    "# scale_weights(snn2.f1_f2, scaling_factor)\n",
    "# scale_weights(snn2.f2_o, scaling_factor)\n",
    "\n",
    "snn2.to(device)\n",
    "train(snn2, train_loader, test_loader, lr, num_epochs, dropout=0.0, lr_scale_tau=20.0, \n",
    "    test_behavior=tb_save_max_last_acc, ckpt_dir=ckpt_dir, scheduler=(100, 0.95), test_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepsnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
